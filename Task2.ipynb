{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "080dcd7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import dog_dataset, cub_dataset, food_dataset, cub_and_dogs\n",
    "from models.models_to_finetune import deit_small_patch16_224, myresnetv2_task1, myresnetv2_task2, myresnetv2_for_c_loss\n",
    "import PIL\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from torchvision import transforms\n",
    "import config\n",
    "import sys\n",
    "import math\n",
    "from loss import CenterLoss\n",
    "from run_center_loss import train_model_with_closs\n",
    "from vit.vit_pytorch.nest import NesT\n",
    "import timm\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from models import bilinear_model\n",
    "from run import train_model\n",
    "from loss import GBLoss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a45a9eba",
   "metadata": {},
   "source": [
    "All of the models can be trained using the two **main.py** files in the submission folder. These notebook contain sufficient code to run inference on the selected models for the sake of clarity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f2d87c81",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 50\n",
    "batch_size = 32\n",
    "mean = (0.485, 0.456, 0.406)\n",
    "std = (0.229, 0.224, 0.225)\n",
    "test_transform=transforms.Compose([\n",
    "                    transforms.Resize((448, 448)),\n",
    "                    transforms.ToTensor(),\n",
    "                    transforms.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225))\n",
    "                ])\n",
    "\n",
    "data_transform4 = transforms.Compose([  #\n",
    "\n",
    "        transforms.Resize((448, 448)),\n",
    "        transforms.RandomRotation(20),\n",
    "        transforms.GaussianBlur(3, sigma=(0.1, 2.0)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=mean, std=std)\n",
    "    ])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecc833dc",
   "metadata": {},
   "source": [
    "*In task1 resnetv2-448 gave the best results for CNN-based model, while cait_xxs_24_384 gave the best results for transformer-based model on CUB-dataset. In this task we will try use these models as baseline and run different experiments by changing the loss functions as well as the architecture.* Training longer increased accuracy for each experiment setting; for a fair comparison we will compare accuracy achieved within 30 epochs. \\\n",
    "**Kindly check the excel sheet provided in the submission to look through all the experiments done for task 2.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0c4d6d8",
   "metadata": {},
   "source": [
    "## Cait_xxs_24_384 \n",
    "Batch size = 24 during training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c3cff02c",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_transform=transforms.Compose([\n",
    "                    transforms.Resize((384, 384)),\n",
    "                    transforms.ToTensor(),\n",
    "                    transforms.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225))\n",
    "                ])\n",
    "\n",
    "data_transform = transforms.Compose([  #\n",
    "\n",
    "       transforms.Resize((384, 384)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=mean, std=std)\n",
    "    ])\n",
    "\n",
    "# Load Data\n",
    "train_loader, val_loader,test_loader = cub_and_dogs(bs=batch_size, data_transform=data_transform, test_transform=test_transform)\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "model = timm.create_model(\"cait_xxs24_384\", pretrained=True)\n",
    "model.head = torch.nn.Linear(in_features=model.head.in_features, out_features=320)  # dogs dataset has 120 classes\n",
    "model.head.apply(model._init_weights)\n",
    "model.to(device)\n",
    "path = \"/home/hashmat.malik/Fall 2021/CV703 Lab/Week5/datasets/modelcait_xxs24_384_task2exp7_for_nb_best.pth.tar\"\n",
    "checkpoint = torch.load(path)\n",
    "model.load_state_dict(checkpoint['state_dict'])\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001, betas=(0.5, 0.999))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "11c92d55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test: [ 0/57]\tTime  1.164 ( 1.164)\tLoss 4.2061e-01 (4.2061e-01)\tAcc@1  84.38 ( 84.38)\tAcc@5 100.00 (100.00)\n",
      "Test: [ 5/57]\tTime  0.346 ( 0.491)\tLoss 9.1943e-01 (6.3828e-01)\tAcc@1  71.88 ( 82.29)\tAcc@5  96.88 ( 96.35)\n",
      "Test: [10/57]\tTime  0.344 ( 0.426)\tLoss 5.3010e-01 (6.9046e-01)\tAcc@1  90.62 ( 82.10)\tAcc@5  96.88 ( 96.02)\n",
      "Test: [15/57]\tTime  0.383 ( 0.405)\tLoss 4.4733e-01 (6.5309e-01)\tAcc@1  87.50 ( 83.01)\tAcc@5 100.00 ( 96.88)\n",
      "Test: [20/57]\tTime  0.384 ( 0.400)\tLoss 7.2690e-01 (6.5689e-01)\tAcc@1  84.38 ( 83.04)\tAcc@5  93.75 ( 97.02)\n",
      "Test: [25/57]\tTime  0.345 ( 0.394)\tLoss 8.8095e-01 (6.5660e-01)\tAcc@1  84.38 ( 82.93)\tAcc@5  93.75 ( 96.88)\n",
      "Test: [30/57]\tTime  0.384 ( 0.391)\tLoss 7.4438e-01 (6.5257e-01)\tAcc@1  84.38 ( 83.27)\tAcc@5  93.75 ( 96.67)\n",
      "Test: [35/57]\tTime  0.387 ( 0.390)\tLoss 6.2901e-01 (6.5474e-01)\tAcc@1  81.25 ( 82.81)\tAcc@5 100.00 ( 96.79)\n",
      "Test: [40/57]\tTime  0.347 ( 0.389)\tLoss 3.8881e-01 (6.3285e-01)\tAcc@1  90.62 ( 83.31)\tAcc@5 100.00 ( 96.95)\n",
      "Test: [45/57]\tTime  0.346 ( 0.386)\tLoss 3.9334e-01 (6.3542e-01)\tAcc@1  90.62 ( 83.36)\tAcc@5  96.88 ( 97.15)\n",
      "Test: [50/57]\tTime  0.349 ( 0.384)\tLoss 7.3014e-01 (6.4114e-01)\tAcc@1  84.38 ( 82.90)\tAcc@5  96.88 ( 97.18)\n",
      "Test: [55/57]\tTime  0.375 ( 0.383)\tLoss 7.3624e-01 (6.4373e-01)\tAcc@1  75.00 ( 82.70)\tAcc@5  96.88 ( 97.27)\n",
      " * Acc@1 82.667 Acc@5 97.278\n",
      "Test: [  0/450]\tTime  0.755 ( 0.755)\tLoss 3.5557e-01 (3.5557e-01)\tAcc@1  87.50 ( 87.50)\tAcc@5 100.00 (100.00)\n",
      "Test: [  5/450]\tTime  0.346 ( 0.436)\tLoss 3.4493e-01 (3.7595e-01)\tAcc@1  87.50 ( 87.50)\tAcc@5 100.00 ( 99.48)\n",
      "Test: [ 10/450]\tTime  0.370 ( 0.408)\tLoss 6.4158e-01 (4.3271e-01)\tAcc@1  84.38 ( 87.50)\tAcc@5 100.00 ( 99.15)\n",
      "Test: [ 15/450]\tTime  0.386 ( 0.399)\tLoss 1.5476e-01 (4.6443e-01)\tAcc@1  93.75 ( 85.94)\tAcc@5 100.00 ( 98.63)\n",
      "Test: [ 20/450]\tTime  0.364 ( 0.392)\tLoss 3.7254e-01 (4.0590e-01)\tAcc@1  87.50 ( 87.95)\tAcc@5 100.00 ( 98.81)\n",
      "Test: [ 25/450]\tTime  0.353 ( 0.385)\tLoss 4.9535e-02 (4.2157e-01)\tAcc@1 100.00 ( 87.98)\tAcc@5 100.00 ( 98.80)\n",
      "Test: [ 30/450]\tTime  0.365 ( 0.381)\tLoss 3.3287e-01 (3.9845e-01)\tAcc@1  90.62 ( 88.81)\tAcc@5 100.00 ( 98.79)\n",
      "Test: [ 35/450]\tTime  0.371 ( 0.379)\tLoss 8.0359e-01 (4.3153e-01)\tAcc@1  84.38 ( 87.85)\tAcc@5  93.75 ( 98.78)\n",
      "Test: [ 40/450]\tTime  0.368 ( 0.378)\tLoss 5.9556e-01 (4.2811e-01)\tAcc@1  84.38 ( 87.80)\tAcc@5 100.00 ( 98.70)\n",
      "Test: [ 45/450]\tTime  0.372 ( 0.377)\tLoss 1.8879e-01 (4.4086e-01)\tAcc@1  96.88 ( 86.75)\tAcc@5 100.00 ( 98.78)\n",
      "Test: [ 50/450]\tTime  0.377 ( 0.377)\tLoss 7.3728e-01 (4.4595e-01)\tAcc@1  78.12 ( 86.52)\tAcc@5 100.00 ( 98.77)\n",
      "Test: [ 55/450]\tTime  0.351 ( 0.376)\tLoss 7.1629e-01 (4.5469e-01)\tAcc@1  78.12 ( 86.44)\tAcc@5  96.88 ( 98.72)\n",
      "Test: [ 60/450]\tTime  0.389 ( 0.375)\tLoss 1.1835e-01 (4.2721e-01)\tAcc@1  96.88 ( 87.40)\tAcc@5 100.00 ( 98.77)\n",
      "Test: [ 65/450]\tTime  0.354 ( 0.375)\tLoss 2.1738e-01 (4.1148e-01)\tAcc@1 100.00 ( 88.07)\tAcc@5 100.00 ( 98.86)\n",
      "Test: [ 70/450]\tTime  0.372 ( 0.375)\tLoss 3.9296e-01 (4.0845e-01)\tAcc@1  84.38 ( 87.98)\tAcc@5 100.00 ( 98.90)\n",
      "Test: [ 75/450]\tTime  0.357 ( 0.374)\tLoss 7.9347e-01 (4.2269e-01)\tAcc@1  68.75 ( 87.42)\tAcc@5 100.00 ( 98.85)\n",
      "Test: [ 80/450]\tTime  0.392 ( 0.375)\tLoss 4.6854e-01 (4.0970e-01)\tAcc@1  93.75 ( 88.04)\tAcc@5  96.88 ( 98.88)\n",
      "Test: [ 85/450]\tTime  0.378 ( 0.376)\tLoss 4.1005e-01 (4.0757e-01)\tAcc@1  90.62 ( 88.19)\tAcc@5 100.00 ( 98.87)\n",
      "Test: [ 90/450]\tTime  0.393 ( 0.376)\tLoss 5.2549e-01 (4.1814e-01)\tAcc@1  87.50 ( 88.02)\tAcc@5  96.88 ( 98.80)\n",
      "Test: [ 95/450]\tTime  0.361 ( 0.377)\tLoss 6.3668e-01 (4.2969e-01)\tAcc@1  78.12 ( 87.60)\tAcc@5 100.00 ( 98.80)\n",
      "Test: [100/450]\tTime  0.391 ( 0.376)\tLoss 3.3110e-01 (4.2660e-01)\tAcc@1  90.62 ( 87.75)\tAcc@5 100.00 ( 98.86)\n",
      "Test: [105/450]\tTime  0.393 ( 0.377)\tLoss 4.1139e-01 (4.3601e-01)\tAcc@1  87.50 ( 87.38)\tAcc@5 100.00 ( 98.85)\n",
      "Test: [110/450]\tTime  0.355 ( 0.378)\tLoss 1.5487e-01 (4.3883e-01)\tAcc@1  93.75 ( 87.27)\tAcc@5 100.00 ( 98.87)\n",
      "Test: [115/450]\tTime  0.388 ( 0.377)\tLoss 5.7756e-01 (4.3449e-01)\tAcc@1  81.25 ( 87.42)\tAcc@5 100.00 ( 98.87)\n",
      "Test: [120/450]\tTime  0.393 ( 0.378)\tLoss 8.9107e-01 (4.4726e-01)\tAcc@1  75.00 ( 86.93)\tAcc@5 100.00 ( 98.89)\n",
      "Test: [125/450]\tTime  0.367 ( 0.378)\tLoss 5.1478e-01 (4.5884e-01)\tAcc@1  78.12 ( 86.68)\tAcc@5 100.00 ( 98.81)\n",
      "Test: [130/450]\tTime  0.368 ( 0.378)\tLoss 2.2797e-01 (4.6550e-01)\tAcc@1  93.75 ( 86.38)\tAcc@5 100.00 ( 98.76)\n",
      "Test: [135/450]\tTime  0.395 ( 0.378)\tLoss 3.9473e-01 (4.6964e-01)\tAcc@1  87.50 ( 86.10)\tAcc@5 100.00 ( 98.81)\n",
      "Test: [140/450]\tTime  0.394 ( 0.379)\tLoss 2.2421e-01 (4.6562e-01)\tAcc@1  96.88 ( 86.33)\tAcc@5 100.00 ( 98.76)\n",
      "Test: [145/450]\tTime  0.395 ( 0.379)\tLoss 3.8158e-01 (4.6028e-01)\tAcc@1  87.50 ( 86.49)\tAcc@5 100.00 ( 98.76)\n",
      "Test: [150/450]\tTime  0.393 ( 0.380)\tLoss 9.4330e-02 (4.5544e-01)\tAcc@1 100.00 ( 86.61)\tAcc@5 100.00 ( 98.80)\n",
      "Test: [155/450]\tTime  0.352 ( 0.379)\tLoss 3.1911e-01 (4.5134e-01)\tAcc@1  87.50 ( 86.78)\tAcc@5 100.00 ( 98.80)\n",
      "Test: [160/450]\tTime  0.395 ( 0.379)\tLoss 7.1820e-01 (4.5107e-01)\tAcc@1  78.12 ( 86.80)\tAcc@5  96.88 ( 98.82)\n",
      "Test: [165/450]\tTime  0.383 ( 0.379)\tLoss 4.1238e-01 (4.4659e-01)\tAcc@1  84.38 ( 86.95)\tAcc@5 100.00 ( 98.83)\n",
      "Test: [170/450]\tTime  0.395 ( 0.379)\tLoss 2.2412e-01 (4.3897e-01)\tAcc@1  93.75 ( 87.23)\tAcc@5 100.00 ( 98.87)\n",
      "Test: [175/450]\tTime  0.352 ( 0.379)\tLoss 4.5499e-02 (4.3704e-01)\tAcc@1 100.00 ( 87.32)\tAcc@5 100.00 ( 98.88)\n",
      "Test: [180/450]\tTime  0.362 ( 0.379)\tLoss 7.6692e-01 (4.4076e-01)\tAcc@1  65.62 ( 87.14)\tAcc@5  96.88 ( 98.90)\n",
      "Test: [185/450]\tTime  0.393 ( 0.379)\tLoss 4.1209e-01 (4.4145e-01)\tAcc@1  87.50 ( 87.13)\tAcc@5 100.00 ( 98.87)\n",
      "Test: [190/450]\tTime  0.352 ( 0.378)\tLoss 4.6223e-01 (4.4354e-01)\tAcc@1  84.38 ( 87.04)\tAcc@5  96.88 ( 98.87)\n",
      "Test: [195/450]\tTime  0.372 ( 0.378)\tLoss 2.8036e-01 (4.4338e-01)\tAcc@1  90.62 ( 86.97)\tAcc@5 100.00 ( 98.90)\n",
      "Test: [200/450]\tTime  0.354 ( 0.378)\tLoss 5.7708e-01 (4.4499e-01)\tAcc@1  84.38 ( 86.91)\tAcc@5  96.88 ( 98.90)\n",
      "Test: [205/450]\tTime  0.395 ( 0.379)\tLoss 7.7819e-01 (4.4707e-01)\tAcc@1  68.75 ( 86.82)\tAcc@5 100.00 ( 98.89)\n",
      "Test: [210/450]\tTime  0.395 ( 0.379)\tLoss 7.2895e-01 (4.4573e-01)\tAcc@1  75.00 ( 86.88)\tAcc@5 100.00 ( 98.90)\n",
      "Test: [215/450]\tTime  0.352 ( 0.378)\tLoss 7.6922e-01 (4.5243e-01)\tAcc@1  68.75 ( 86.62)\tAcc@5 100.00 ( 98.91)\n",
      "Test: [220/450]\tTime  0.396 ( 0.379)\tLoss 2.3573e-01 (4.6155e-01)\tAcc@1  93.75 ( 85.92)\tAcc@5 100.00 ( 98.91)\n",
      "Test: [225/450]\tTime  0.392 ( 0.379)\tLoss 1.2738e-01 (4.5556e-01)\tAcc@1  96.88 ( 86.16)\tAcc@5 100.00 ( 98.92)\n",
      "Test: [230/450]\tTime  0.394 ( 0.379)\tLoss 1.2014e-01 (4.4879e-01)\tAcc@1  96.88 ( 86.39)\tAcc@5 100.00 ( 98.94)\n",
      "Test: [235/450]\tTime  0.398 ( 0.379)\tLoss 6.2989e-01 (4.5156e-01)\tAcc@1  78.12 ( 86.33)\tAcc@5 100.00 ( 98.95)\n",
      "Test: [240/450]\tTime  0.398 ( 0.380)\tLoss 9.4835e-02 (4.4785e-01)\tAcc@1 100.00 ( 86.46)\tAcc@5 100.00 ( 98.98)\n",
      "Test: [245/450]\tTime  0.396 ( 0.380)\tLoss 5.5256e-02 (4.4412e-01)\tAcc@1 100.00 ( 86.62)\tAcc@5 100.00 ( 98.98)\n",
      "Test: [250/450]\tTime  0.389 ( 0.380)\tLoss 3.7465e-01 (4.3865e-01)\tAcc@1  93.75 ( 86.83)\tAcc@5 100.00 ( 99.00)\n",
      "Test: [255/450]\tTime  0.367 ( 0.380)\tLoss 2.9498e-01 (4.3853e-01)\tAcc@1  93.75 ( 86.87)\tAcc@5 100.00 ( 99.01)\n",
      "Test: [260/450]\tTime  0.387 ( 0.380)\tLoss 3.2990e-01 (4.4503e-01)\tAcc@1  93.75 ( 86.61)\tAcc@5 100.00 ( 99.01)\n",
      "Test: [265/450]\tTime  0.378 ( 0.380)\tLoss 1.9132e-01 (4.4321e-01)\tAcc@1  96.88 ( 86.72)\tAcc@5 100.00 ( 99.01)\n",
      "Test: [270/450]\tTime  0.360 ( 0.380)\tLoss 8.2609e-01 (4.4561e-01)\tAcc@1  81.25 ( 86.73)\tAcc@5 100.00 ( 98.97)\n",
      "Test: [275/450]\tTime  0.388 ( 0.380)\tLoss 1.1030e+00 (4.5352e-01)\tAcc@1  71.88 ( 86.63)\tAcc@5  93.75 ( 98.92)\n",
      "Test: [280/450]\tTime  0.357 ( 0.380)\tLoss 7.6734e-01 (4.6072e-01)\tAcc@1  90.62 ( 86.59)\tAcc@5  93.75 ( 98.81)\n",
      "Test: [285/450]\tTime  0.363 ( 0.380)\tLoss 9.9842e-01 (4.6693e-01)\tAcc@1  68.75 ( 86.54)\tAcc@5  96.88 ( 98.80)\n",
      "Test: [290/450]\tTime  0.357 ( 0.379)\tLoss 1.2161e+00 (4.7911e-01)\tAcc@1  65.62 ( 86.18)\tAcc@5  96.88 ( 98.75)\n",
      "Test: [295/450]\tTime  0.353 ( 0.379)\tLoss 1.4231e+00 (4.9135e-01)\tAcc@1  68.75 ( 85.90)\tAcc@5  93.75 ( 98.70)\n",
      "Test: [300/450]\tTime  0.389 ( 0.379)\tLoss 1.8199e+00 (5.0012e-01)\tAcc@1  53.12 ( 85.70)\tAcc@5  87.50 ( 98.66)\n",
      "Test: [305/450]\tTime  0.382 ( 0.379)\tLoss 8.8304e-01 (5.1581e-01)\tAcc@1  75.00 ( 85.27)\tAcc@5 100.00 ( 98.50)\n",
      "Test: [310/450]\tTime  0.380 ( 0.379)\tLoss 1.9601e+00 (5.2116e-01)\tAcc@1  34.38 ( 85.21)\tAcc@5  81.25 ( 98.44)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test: [315/450]\tTime  0.384 ( 0.379)\tLoss 6.4210e-01 (5.2206e-01)\tAcc@1  90.62 ( 85.28)\tAcc@5  93.75 ( 98.45)\n",
      "Test: [320/450]\tTime  0.391 ( 0.380)\tLoss 1.3081e+00 (5.2988e-01)\tAcc@1  65.62 ( 85.11)\tAcc@5  93.75 ( 98.41)\n",
      "Test: [325/450]\tTime  0.389 ( 0.379)\tLoss 1.3119e+00 (5.4028e-01)\tAcc@1  68.75 ( 84.79)\tAcc@5  96.88 ( 98.32)\n",
      "Test: [330/450]\tTime  0.354 ( 0.379)\tLoss 1.7280e+00 (5.4660e-01)\tAcc@1  56.25 ( 84.61)\tAcc@5  81.25 ( 98.29)\n",
      "Test: [335/450]\tTime  0.379 ( 0.379)\tLoss 5.8474e-01 (5.4679e-01)\tAcc@1  90.62 ( 84.67)\tAcc@5 100.00 ( 98.29)\n",
      "Test: [340/450]\tTime  0.354 ( 0.379)\tLoss 1.2122e+00 (5.5225e-01)\tAcc@1  62.50 ( 84.59)\tAcc@5  93.75 ( 98.23)\n",
      "Test: [345/450]\tTime  0.354 ( 0.379)\tLoss 7.0318e-01 (5.5431e-01)\tAcc@1  81.25 ( 84.63)\tAcc@5  93.75 ( 98.21)\n",
      "Test: [350/450]\tTime  0.353 ( 0.379)\tLoss 5.1256e-01 (5.6059e-01)\tAcc@1  96.88 ( 84.60)\tAcc@5 100.00 ( 98.11)\n",
      "Test: [355/450]\tTime  0.355 ( 0.379)\tLoss 1.1747e+00 (5.6739e-01)\tAcc@1  87.50 ( 84.55)\tAcc@5  90.62 ( 98.02)\n",
      "Test: [360/450]\tTime  0.372 ( 0.378)\tLoss 1.4885e+00 (5.7474e-01)\tAcc@1  71.88 ( 84.44)\tAcc@5  93.75 ( 97.97)\n",
      "Test: [365/450]\tTime  0.362 ( 0.378)\tLoss 6.4494e-01 (5.8013e-01)\tAcc@1  87.50 ( 84.33)\tAcc@5  96.88 ( 97.93)\n",
      "Test: [370/450]\tTime  0.392 ( 0.378)\tLoss 1.8362e+00 (5.8969e-01)\tAcc@1  46.88 ( 84.05)\tAcc@5  84.38 ( 97.86)\n",
      "Test: [375/450]\tTime  0.397 ( 0.378)\tLoss 1.6045e+00 (6.0514e-01)\tAcc@1  59.38 ( 83.71)\tAcc@5  87.50 ( 97.70)\n",
      "Test: [380/450]\tTime  0.356 ( 0.379)\tLoss 1.5745e+00 (6.1367e-01)\tAcc@1  68.75 ( 83.55)\tAcc@5  84.38 ( 97.62)\n",
      "Test: [385/450]\tTime  0.396 ( 0.379)\tLoss 1.3881e+00 (6.2551e-01)\tAcc@1  65.62 ( 83.35)\tAcc@5  90.62 ( 97.51)\n",
      "Test: [390/450]\tTime  0.398 ( 0.379)\tLoss 1.4780e+00 (6.3245e-01)\tAcc@1  68.75 ( 83.22)\tAcc@5  93.75 ( 97.45)\n",
      "Test: [395/450]\tTime  0.398 ( 0.379)\tLoss 1.9903e+00 (6.3819e-01)\tAcc@1  62.50 ( 83.14)\tAcc@5  81.25 ( 97.40)\n",
      "Test: [400/450]\tTime  0.378 ( 0.379)\tLoss 5.8349e-01 (6.4452e-01)\tAcc@1  93.75 ( 82.96)\tAcc@5 100.00 ( 97.40)\n",
      "Test: [405/450]\tTime  0.398 ( 0.379)\tLoss 1.2379e+00 (6.4929e-01)\tAcc@1  71.88 ( 82.91)\tAcc@5 100.00 ( 97.38)\n",
      "Test: [410/450]\tTime  0.399 ( 0.379)\tLoss 5.3537e-01 (6.5704e-01)\tAcc@1  96.88 ( 82.79)\tAcc@5 100.00 ( 97.32)\n",
      "Test: [415/450]\tTime  0.386 ( 0.379)\tLoss 7.0007e-01 (6.6086e-01)\tAcc@1  84.38 ( 82.76)\tAcc@5 100.00 ( 97.31)\n",
      "Test: [420/450]\tTime  0.398 ( 0.380)\tLoss 7.4736e-01 (6.6391e-01)\tAcc@1  87.50 ( 82.74)\tAcc@5 100.00 ( 97.28)\n",
      "Test: [425/450]\tTime  0.399 ( 0.380)\tLoss 1.8593e+00 (6.7331e-01)\tAcc@1  59.38 ( 82.56)\tAcc@5  84.38 ( 97.18)\n",
      "Test: [430/450]\tTime  0.398 ( 0.380)\tLoss 9.6429e-01 (6.7811e-01)\tAcc@1  81.25 ( 82.50)\tAcc@5  96.88 ( 97.17)\n",
      "Test: [435/450]\tTime  0.359 ( 0.380)\tLoss 5.6237e-01 (6.7940e-01)\tAcc@1  93.75 ( 82.53)\tAcc@5 100.00 ( 97.18)\n",
      "Test: [440/450]\tTime  0.362 ( 0.380)\tLoss 3.0900e-01 (6.7774e-01)\tAcc@1  96.88 ( 82.64)\tAcc@5  96.88 ( 97.19)\n",
      "Test: [445/450]\tTime  0.398 ( 0.380)\tLoss 1.5638e+00 (6.8371e-01)\tAcc@1  71.88 ( 82.55)\tAcc@5  93.75 ( 97.16)\n",
      " * Acc@1 82.587 Acc@5 97.162\n"
     ]
    }
   ],
   "source": [
    "train_model(epochs, train_loader, val_loader, test_loader, optimizer, criterion, model, 'cait', is_train=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0357ef74",
   "metadata": {},
   "source": [
    "Reached top1 validation accuracy of 82.667% and top1 test accuracy of 82.587%. However, when we keep the same batch size (i.e same number of updates) for both resnetv2 and cait, cait's performance decreases. Please check the submitted for excel sheet for detailed results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ce8fb29",
   "metadata": {},
   "source": [
    "## Resnetv2-448\n",
    "Batch size = 96 during training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a3d5ff9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test: [ 0/75]\tTime  0.704 ( 0.704)\tLoss 6.3873e-01 (6.3873e-01)\tAcc@1  87.50 ( 87.50)\tAcc@5 100.00 (100.00)\n",
      "Test: [ 5/75]\tTime  0.508 ( 0.553)\tLoss 1.0646e+00 (8.0182e-01)\tAcc@1  66.67 ( 78.47)\tAcc@5  91.67 ( 96.53)\n",
      "Test: [10/75]\tTime  0.517 ( 0.536)\tLoss 6.9550e-01 (7.5518e-01)\tAcc@1  79.17 ( 76.89)\tAcc@5 100.00 ( 96.59)\n",
      "Test: [15/75]\tTime  0.493 ( 0.527)\tLoss 4.8774e-01 (7.2447e-01)\tAcc@1  87.50 ( 77.60)\tAcc@5 100.00 ( 97.14)\n",
      "Test: [20/75]\tTime  0.503 ( 0.522)\tLoss 6.4719e-01 (6.9613e-01)\tAcc@1  83.33 ( 78.57)\tAcc@5  91.67 ( 97.02)\n",
      "Test: [25/75]\tTime  0.554 ( 0.523)\tLoss 6.5845e-01 (6.6821e-01)\tAcc@1  75.00 ( 79.49)\tAcc@5  95.83 ( 96.96)\n",
      "Test: [30/75]\tTime  0.510 ( 0.520)\tLoss 7.1005e-01 (6.4506e-01)\tAcc@1  83.33 ( 80.11)\tAcc@5 100.00 ( 97.45)\n",
      "Test: [35/75]\tTime  0.483 ( 0.519)\tLoss 3.8224e-01 (6.2733e-01)\tAcc@1  87.50 ( 81.48)\tAcc@5 100.00 ( 97.34)\n",
      "Test: [40/75]\tTime  0.496 ( 0.518)\tLoss 4.1304e-01 (6.3160e-01)\tAcc@1  87.50 ( 81.50)\tAcc@5 100.00 ( 97.36)\n",
      "Test: [45/75]\tTime  0.484 ( 0.516)\tLoss 6.4326e-01 (6.2168e-01)\tAcc@1  75.00 ( 81.88)\tAcc@5 100.00 ( 97.28)\n",
      "Test: [50/75]\tTime  0.526 ( 0.517)\tLoss 3.4536e-01 (6.0592e-01)\tAcc@1  87.50 ( 82.27)\tAcc@5 100.00 ( 97.47)\n",
      "Test: [55/75]\tTime  0.506 ( 0.519)\tLoss 7.9170e-01 (6.1444e-01)\tAcc@1  83.33 ( 82.22)\tAcc@5  91.67 ( 97.32)\n",
      "Test: [60/75]\tTime  0.541 ( 0.519)\tLoss 2.8013e-01 (6.0658e-01)\tAcc@1  95.83 ( 82.17)\tAcc@5 100.00 ( 97.47)\n",
      "Test: [65/75]\tTime  0.494 ( 0.519)\tLoss 3.2174e-01 (6.1021e-01)\tAcc@1  95.83 ( 82.01)\tAcc@5 100.00 ( 97.47)\n",
      "Test: [70/75]\tTime  0.524 ( 0.518)\tLoss 6.3763e-01 (6.0870e-01)\tAcc@1  79.17 ( 81.92)\tAcc@5 100.00 ( 97.65)\n",
      " * Acc@1 82.278 Acc@5 97.667\n",
      "Test: [  0/599]\tTime  0.475 ( 0.475)\tLoss 5.0696e-01 (5.0696e-01)\tAcc@1  83.33 ( 83.33)\tAcc@5  95.83 ( 95.83)\n",
      "Test: [  5/599]\tTime  0.225 ( 0.280)\tLoss 1.4614e-01 (5.1779e-01)\tAcc@1  95.83 ( 85.42)\tAcc@5 100.00 ( 98.61)\n",
      "Test: [ 10/599]\tTime  0.215 ( 0.254)\tLoss 5.4769e-01 (4.5683e-01)\tAcc@1  87.50 ( 87.12)\tAcc@5  95.83 ( 98.86)\n",
      "Test: [ 15/599]\tTime  0.240 ( 0.245)\tLoss 5.0544e-01 (4.7449e-01)\tAcc@1  87.50 ( 87.50)\tAcc@5 100.00 ( 99.22)\n",
      "Test: [ 20/599]\tTime  0.217 ( 0.241)\tLoss 1.1328e-01 (4.7018e-01)\tAcc@1 100.00 ( 87.50)\tAcc@5 100.00 ( 99.01)\n",
      "Test: [ 25/599]\tTime  0.232 ( 0.238)\tLoss 1.5219e-01 (4.1062e-01)\tAcc@1  91.67 ( 89.26)\tAcc@5 100.00 ( 99.20)\n",
      "Test: [ 30/599]\tTime  0.252 ( 0.237)\tLoss 1.5278e+00 (4.7102e-01)\tAcc@1  45.83 ( 86.56)\tAcc@5  95.83 ( 99.06)\n",
      "Test: [ 35/599]\tTime  0.236 ( 0.235)\tLoss 8.9365e-02 (4.8775e-01)\tAcc@1 100.00 ( 86.23)\tAcc@5 100.00 ( 98.50)\n",
      "Test: [ 40/599]\tTime  0.228 ( 0.243)\tLoss 2.3099e-01 (4.6849e-01)\tAcc@1  95.83 ( 86.79)\tAcc@5 100.00 ( 98.58)\n",
      "Test: [ 45/599]\tTime  0.213 ( 0.242)\tLoss 1.7122e-01 (4.7508e-01)\tAcc@1  95.83 ( 86.41)\tAcc@5 100.00 ( 98.64)\n",
      "Test: [ 50/599]\tTime  0.217 ( 0.241)\tLoss 5.2445e-01 (4.6945e-01)\tAcc@1  83.33 ( 86.52)\tAcc@5  95.83 ( 98.61)\n",
      "Test: [ 55/599]\tTime  0.199 ( 0.239)\tLoss 6.7806e-01 (4.6947e-01)\tAcc@1  70.83 ( 86.16)\tAcc@5  95.83 ( 98.66)\n",
      "Test: [ 60/599]\tTime  0.237 ( 0.238)\tLoss 4.6150e-01 (5.1826e-01)\tAcc@1  87.50 ( 83.95)\tAcc@5 100.00 ( 98.77)\n",
      "Test: [ 65/599]\tTime  0.220 ( 0.237)\tLoss 5.0563e-01 (5.2415e-01)\tAcc@1  87.50 ( 83.71)\tAcc@5 100.00 ( 98.67)\n",
      "Test: [ 70/599]\tTime  0.212 ( 0.236)\tLoss 2.9795e-01 (5.2668e-01)\tAcc@1 100.00 ( 83.63)\tAcc@5 100.00 ( 98.71)\n",
      "Test: [ 75/599]\tTime  0.230 ( 0.236)\tLoss 2.4147e-01 (5.3123e-01)\tAcc@1  91.67 ( 83.61)\tAcc@5 100.00 ( 98.63)\n",
      "Test: [ 80/599]\tTime  0.218 ( 0.235)\tLoss 2.3773e-01 (5.1866e-01)\tAcc@1  95.83 ( 84.31)\tAcc@5 100.00 ( 98.66)\n",
      "Test: [ 85/599]\tTime  0.226 ( 0.234)\tLoss 5.6188e-01 (5.1336e-01)\tAcc@1  79.17 ( 84.54)\tAcc@5 100.00 ( 98.74)\n",
      "Test: [ 90/599]\tTime  0.231 ( 0.233)\tLoss 1.4636e-01 (5.0449e-01)\tAcc@1 100.00 ( 85.03)\tAcc@5 100.00 ( 98.67)\n",
      "Test: [ 95/599]\tTime  0.222 ( 0.233)\tLoss 3.5350e-01 (5.0113e-01)\tAcc@1  95.83 ( 85.20)\tAcc@5 100.00 ( 98.70)\n",
      "Test: [100/599]\tTime  0.225 ( 0.233)\tLoss 1.1234e+00 (5.2518e-01)\tAcc@1  58.33 ( 84.61)\tAcc@5 100.00 ( 98.47)\n",
      "Test: [105/599]\tTime  0.210 ( 0.234)\tLoss 1.8094e-01 (5.1931e-01)\tAcc@1  95.83 ( 84.75)\tAcc@5 100.00 ( 98.43)\n",
      "Test: [110/599]\tTime  0.195 ( 0.233)\tLoss 8.3821e-01 (5.2807e-01)\tAcc@1  79.17 ( 84.68)\tAcc@5  95.83 ( 98.35)\n",
      "Test: [115/599]\tTime  0.213 ( 0.233)\tLoss 1.1275e+00 (5.3869e-01)\tAcc@1  66.67 ( 84.55)\tAcc@5  91.67 ( 98.17)\n",
      "Test: [120/599]\tTime  0.212 ( 0.232)\tLoss 7.3965e-01 (5.5334e-01)\tAcc@1  75.00 ( 84.16)\tAcc@5 100.00 ( 98.14)\n",
      "Test: [125/599]\tTime  0.230 ( 0.232)\tLoss 1.0994e+00 (5.7058e-01)\tAcc@1  83.33 ( 83.56)\tAcc@5  95.83 ( 98.08)\n",
      "Test: [130/599]\tTime  0.216 ( 0.233)\tLoss 8.3439e-01 (5.9346e-01)\tAcc@1  83.33 ( 82.92)\tAcc@5  91.67 ( 97.90)\n",
      "Test: [135/599]\tTime  0.225 ( 0.232)\tLoss 3.7200e-01 (5.8438e-01)\tAcc@1  91.67 ( 83.30)\tAcc@5 100.00 ( 97.92)\n",
      "Test: [140/599]\tTime  0.222 ( 0.232)\tLoss 1.0053e+00 (5.8627e-01)\tAcc@1  75.00 ( 83.36)\tAcc@5  87.50 ( 97.84)\n",
      "Test: [145/599]\tTime  0.220 ( 0.232)\tLoss 6.7721e-01 (5.9003e-01)\tAcc@1  70.83 ( 83.11)\tAcc@5 100.00 ( 97.89)\n",
      "Test: [150/599]\tTime  0.226 ( 0.232)\tLoss 2.2911e-01 (5.8599e-01)\tAcc@1  95.83 ( 83.28)\tAcc@5 100.00 ( 97.90)\n",
      "Test: [155/599]\tTime  0.222 ( 0.231)\tLoss 8.1528e-01 (5.8353e-01)\tAcc@1  75.00 ( 83.36)\tAcc@5 100.00 ( 97.94)\n",
      "Test: [160/599]\tTime  0.210 ( 0.231)\tLoss 8.8627e-01 (5.9144e-01)\tAcc@1  70.83 ( 83.02)\tAcc@5  95.83 ( 97.93)\n",
      "Test: [165/599]\tTime  0.230 ( 0.231)\tLoss 1.3383e+00 (6.0045e-01)\tAcc@1  75.00 ( 82.91)\tAcc@5  91.67 ( 97.87)\n",
      "Test: [170/599]\tTime  0.234 ( 0.231)\tLoss 1.1268e+00 (6.0664e-01)\tAcc@1  62.50 ( 82.58)\tAcc@5  95.83 ( 97.86)\n",
      "Test: [175/599]\tTime  0.225 ( 0.231)\tLoss 3.9398e-01 (6.1172e-01)\tAcc@1  91.67 ( 82.48)\tAcc@5 100.00 ( 97.73)\n",
      "Test: [180/599]\tTime  0.239 ( 0.232)\tLoss 3.7022e-01 (6.1686e-01)\tAcc@1  91.67 ( 82.14)\tAcc@5 100.00 ( 97.79)\n",
      "Test: [185/599]\tTime  0.280 ( 0.232)\tLoss 5.5858e-01 (6.1240e-01)\tAcc@1  87.50 ( 82.28)\tAcc@5 100.00 ( 97.80)\n",
      "Test: [190/599]\tTime  0.229 ( 0.232)\tLoss 6.0989e-01 (6.1353e-01)\tAcc@1  83.33 ( 82.20)\tAcc@5  95.83 ( 97.73)\n",
      "Test: [195/599]\tTime  0.228 ( 0.232)\tLoss 6.1866e-01 (6.1183e-01)\tAcc@1  79.17 ( 82.33)\tAcc@5 100.00 ( 97.77)\n",
      "Test: [200/599]\tTime  0.205 ( 0.232)\tLoss 1.0730e-01 (6.0219e-01)\tAcc@1  95.83 ( 82.63)\tAcc@5 100.00 ( 97.82)\n",
      "Test: [205/599]\tTime  0.217 ( 0.232)\tLoss 2.5562e-01 (5.9878e-01)\tAcc@1  91.67 ( 82.69)\tAcc@5 100.00 ( 97.88)\n",
      "Test: [210/599]\tTime  0.233 ( 0.232)\tLoss 3.1849e-01 (5.9095e-01)\tAcc@1  91.67 ( 82.96)\tAcc@5 100.00 ( 97.93)\n",
      "Test: [215/599]\tTime  0.261 ( 0.232)\tLoss 2.4079e-01 (5.8857e-01)\tAcc@1  95.83 ( 83.04)\tAcc@5 100.00 ( 97.96)\n",
      "Test: [220/599]\tTime  0.217 ( 0.232)\tLoss 9.9457e-01 (5.9220e-01)\tAcc@1  62.50 ( 82.81)\tAcc@5  91.67 ( 97.94)\n",
      "Test: [225/599]\tTime  0.222 ( 0.232)\tLoss 2.0166e-01 (5.8468e-01)\tAcc@1  91.67 ( 83.02)\tAcc@5 100.00 ( 97.99)\n",
      "Test: [230/599]\tTime  0.227 ( 0.232)\tLoss 8.2584e-01 (5.8296e-01)\tAcc@1  66.67 ( 83.04)\tAcc@5 100.00 ( 98.03)\n",
      "Test: [235/599]\tTime  0.221 ( 0.232)\tLoss 1.9173e-01 (5.7846e-01)\tAcc@1  95.83 ( 83.19)\tAcc@5 100.00 ( 98.04)\n",
      "Test: [240/599]\tTime  0.223 ( 0.232)\tLoss 9.9618e-01 (5.8503e-01)\tAcc@1  62.50 ( 82.85)\tAcc@5  95.83 ( 97.99)\n",
      "Test: [245/599]\tTime  0.234 ( 0.232)\tLoss 8.5204e-01 (5.8619e-01)\tAcc@1  83.33 ( 82.81)\tAcc@5  95.83 ( 98.02)\n",
      "Test: [250/599]\tTime  0.227 ( 0.233)\tLoss 3.7850e-01 (5.8655e-01)\tAcc@1  79.17 ( 82.72)\tAcc@5 100.00 ( 98.01)\n",
      "Test: [255/599]\tTime  0.238 ( 0.233)\tLoss 6.7358e-01 (5.8751e-01)\tAcc@1  75.00 ( 82.63)\tAcc@5 100.00 ( 98.03)\n",
      "Test: [260/599]\tTime  0.230 ( 0.233)\tLoss 3.5913e-01 (5.8791e-01)\tAcc@1  87.50 ( 82.58)\tAcc@5 100.00 ( 98.07)\n",
      "Test: [265/599]\tTime  0.237 ( 0.233)\tLoss 5.3042e-01 (5.8702e-01)\tAcc@1  87.50 ( 82.57)\tAcc@5 100.00 ( 98.09)\n",
      "Test: [270/599]\tTime  0.247 ( 0.233)\tLoss 7.3866e-01 (5.9014e-01)\tAcc@1  70.83 ( 82.38)\tAcc@5 100.00 ( 98.08)\n",
      "Test: [275/599]\tTime  0.264 ( 0.233)\tLoss 4.4881e-01 (5.9021e-01)\tAcc@1  83.33 ( 82.37)\tAcc@5 100.00 ( 98.11)\n",
      "Test: [280/599]\tTime  0.220 ( 0.234)\tLoss 6.8538e-01 (5.8681e-01)\tAcc@1  83.33 ( 82.55)\tAcc@5 100.00 ( 98.12)\n",
      "Test: [285/599]\tTime  0.232 ( 0.234)\tLoss 9.8010e-01 (5.8816e-01)\tAcc@1  66.67 ( 82.55)\tAcc@5 100.00 ( 98.15)\n",
      "Test: [290/599]\tTime  0.224 ( 0.233)\tLoss 1.2424e+00 (5.9530e-01)\tAcc@1  41.67 ( 82.12)\tAcc@5 100.00 ( 98.17)\n",
      "Test: [295/599]\tTime  0.284 ( 0.233)\tLoss 5.6160e-01 (6.0235e-01)\tAcc@1  79.17 ( 81.83)\tAcc@5  95.83 ( 98.14)\n",
      "Test: [300/599]\tTime  0.237 ( 0.234)\tLoss 4.3673e-01 (5.9981e-01)\tAcc@1  87.50 ( 81.98)\tAcc@5  95.83 ( 98.13)\n",
      "Test: [305/599]\tTime  0.229 ( 0.234)\tLoss 9.7199e-02 (5.9339e-01)\tAcc@1 100.00 ( 82.19)\tAcc@5 100.00 ( 98.16)\n",
      "Test: [310/599]\tTime  0.226 ( 0.234)\tLoss 7.5690e-01 (5.9150e-01)\tAcc@1  75.00 ( 82.27)\tAcc@5 100.00 ( 98.19)\n",
      "Test: [315/599]\tTime  0.228 ( 0.234)\tLoss 3.9365e-01 (5.8857e-01)\tAcc@1  91.67 ( 82.42)\tAcc@5 100.00 ( 98.19)\n",
      "Test: [320/599]\tTime  0.247 ( 0.234)\tLoss 6.6386e-02 (5.8288e-01)\tAcc@1 100.00 ( 82.62)\tAcc@5 100.00 ( 98.22)\n",
      "Test: [325/599]\tTime  0.220 ( 0.234)\tLoss 2.1073e-01 (5.7773e-01)\tAcc@1  95.83 ( 82.78)\tAcc@5 100.00 ( 98.22)\n",
      "Test: [330/599]\tTime  0.225 ( 0.234)\tLoss 1.2436e-01 (5.7414e-01)\tAcc@1 100.00 ( 82.92)\tAcc@5 100.00 ( 98.24)\n",
      "Test: [335/599]\tTime  0.254 ( 0.234)\tLoss 3.0599e-01 (5.7001e-01)\tAcc@1  91.67 ( 83.04)\tAcc@5 100.00 ( 98.25)\n",
      "Test: [340/599]\tTime  0.240 ( 0.234)\tLoss 4.5504e-01 (5.7032e-01)\tAcc@1  79.17 ( 82.92)\tAcc@5 100.00 ( 98.28)\n",
      "Test: [345/599]\tTime  0.241 ( 0.234)\tLoss 9.3437e-01 (5.8068e-01)\tAcc@1  66.67 ( 82.51)\tAcc@5  95.83 ( 98.23)\n",
      "Test: [350/599]\tTime  0.212 ( 0.234)\tLoss 1.2542e+00 (5.8276e-01)\tAcc@1  70.83 ( 82.42)\tAcc@5  87.50 ( 98.22)\n",
      "Test: [355/599]\tTime  0.221 ( 0.234)\tLoss 1.1580e-01 (5.7796e-01)\tAcc@1  95.83 ( 82.60)\tAcc@5 100.00 ( 98.22)\n",
      "Test: [360/599]\tTime  0.248 ( 0.234)\tLoss 3.9460e-01 (5.7751e-01)\tAcc@1  91.67 ( 82.64)\tAcc@5 100.00 ( 98.22)\n",
      "Test: [365/599]\tTime  0.250 ( 0.234)\tLoss 1.1422e+00 (5.7675e-01)\tAcc@1  70.83 ( 82.74)\tAcc@5 100.00 ( 98.24)\n",
      "Test: [370/599]\tTime  0.249 ( 0.234)\tLoss 1.2347e-01 (5.7804e-01)\tAcc@1 100.00 ( 82.73)\tAcc@5 100.00 ( 98.18)\n",
      "Test: [375/599]\tTime  0.263 ( 0.235)\tLoss 1.5954e-01 (5.7646e-01)\tAcc@1 100.00 ( 82.85)\tAcc@5 100.00 ( 98.18)\n",
      "Test: [380/599]\tTime  0.249 ( 0.235)\tLoss 6.7322e-01 (5.7436e-01)\tAcc@1  83.33 ( 82.97)\tAcc@5 100.00 ( 98.20)\n",
      "Test: [385/599]\tTime  0.241 ( 0.235)\tLoss 6.6581e-01 (5.7956e-01)\tAcc@1  83.33 ( 82.84)\tAcc@5  95.83 ( 98.19)\n",
      "Test: [390/599]\tTime  0.245 ( 0.235)\tLoss 7.0924e-01 (5.8756e-01)\tAcc@1  83.33 ( 82.53)\tAcc@5 100.00 ( 98.20)\n",
      "Test: [395/599]\tTime  0.281 ( 0.236)\tLoss 1.8929e-01 (5.8633e-01)\tAcc@1 100.00 ( 82.66)\tAcc@5 100.00 ( 98.21)\n",
      "Test: [400/599]\tTime  0.300 ( 0.236)\tLoss 1.3581e+00 (5.9011e-01)\tAcc@1  70.83 ( 82.53)\tAcc@5  87.50 ( 98.17)\n",
      "Test: [405/599]\tTime  0.254 ( 0.236)\tLoss 1.5899e+00 (5.9574e-01)\tAcc@1  70.83 ( 82.50)\tAcc@5  87.50 ( 98.09)\n",
      "Test: [410/599]\tTime  0.261 ( 0.236)\tLoss 4.7356e-01 (5.9522e-01)\tAcc@1  87.50 ( 82.57)\tAcc@5  95.83 ( 98.09)\n",
      "Test: [415/599]\tTime  0.247 ( 0.237)\tLoss 1.1012e+00 (5.9704e-01)\tAcc@1  66.67 ( 82.55)\tAcc@5  95.83 ( 98.08)\n",
      "Test: [420/599]\tTime  0.263 ( 0.237)\tLoss 6.4680e-01 (5.9562e-01)\tAcc@1  83.33 ( 82.65)\tAcc@5  95.83 ( 98.09)\n",
      "Test: [425/599]\tTime  0.246 ( 0.237)\tLoss 8.4814e-01 (5.9428e-01)\tAcc@1  75.00 ( 82.74)\tAcc@5  95.83 ( 98.09)\n",
      "Test: [430/599]\tTime  0.233 ( 0.237)\tLoss 4.4626e-01 (6.0065e-01)\tAcc@1  87.50 ( 82.50)\tAcc@5 100.00 ( 98.07)\n",
      "Test: [435/599]\tTime  0.251 ( 0.237)\tLoss 7.4723e-01 (6.0629e-01)\tAcc@1  83.33 ( 82.32)\tAcc@5 100.00 ( 98.06)\n",
      "Test: [440/599]\tTime  0.220 ( 0.237)\tLoss 1.1653e+00 (6.0814e-01)\tAcc@1  58.33 ( 82.24)\tAcc@5  95.83 ( 98.03)\n",
      "Test: [445/599]\tTime  0.253 ( 0.238)\tLoss 1.5457e-01 (6.0695e-01)\tAcc@1 100.00 ( 82.33)\tAcc@5 100.00 ( 98.03)\n",
      "Test: [450/599]\tTime  0.262 ( 0.238)\tLoss 7.7539e-01 (6.0616e-01)\tAcc@1  91.67 ( 82.45)\tAcc@5  95.83 ( 98.02)\n",
      "Test: [455/599]\tTime  0.259 ( 0.238)\tLoss 1.3304e-01 (6.0441e-01)\tAcc@1 100.00 ( 82.58)\tAcc@5 100.00 ( 98.03)\n",
      "Test: [460/599]\tTime  0.265 ( 0.238)\tLoss 4.1964e-01 (6.0282e-01)\tAcc@1  91.67 ( 82.68)\tAcc@5  95.83 ( 98.03)\n",
      "Test: [465/599]\tTime  0.273 ( 0.238)\tLoss 1.0557e+00 (6.0336e-01)\tAcc@1  87.50 ( 82.73)\tAcc@5  95.83 ( 98.01)\n",
      "Test: [470/599]\tTime  0.342 ( 0.239)\tLoss 8.6336e-01 (6.0112e-01)\tAcc@1  75.00 ( 82.83)\tAcc@5  95.83 ( 98.02)\n",
      "Test: [475/599]\tTime  0.260 ( 0.239)\tLoss 5.9450e-01 (6.0367e-01)\tAcc@1  91.67 ( 82.83)\tAcc@5  95.83 ( 97.96)\n",
      "Test: [480/599]\tTime  0.252 ( 0.239)\tLoss 7.0955e-01 (6.0684e-01)\tAcc@1  79.17 ( 82.67)\tAcc@5 100.00 ( 97.96)\n",
      "Test: [485/599]\tTime  0.231 ( 0.240)\tLoss 7.6464e-01 (6.0861e-01)\tAcc@1  87.50 ( 82.59)\tAcc@5  95.83 ( 97.96)\n",
      "Test: [490/599]\tTime  0.243 ( 0.240)\tLoss 4.5479e-01 (6.0812e-01)\tAcc@1  87.50 ( 82.62)\tAcc@5 100.00 ( 97.96)\n",
      "Test: [495/599]\tTime  0.261 ( 0.240)\tLoss 1.0577e+00 (6.1079e-01)\tAcc@1  83.33 ( 82.65)\tAcc@5  91.67 ( 97.95)\n",
      "Test: [500/599]\tTime  0.265 ( 0.240)\tLoss 1.5249e+00 (6.1772e-01)\tAcc@1  62.50 ( 82.49)\tAcc@5  87.50 ( 97.90)\n",
      "Test: [505/599]\tTime  0.256 ( 0.240)\tLoss 3.7977e-01 (6.1913e-01)\tAcc@1 100.00 ( 82.50)\tAcc@5 100.00 ( 97.89)\n",
      "Test: [510/599]\tTime  0.254 ( 0.240)\tLoss 7.0582e-01 (6.2156e-01)\tAcc@1  87.50 ( 82.50)\tAcc@5  95.83 ( 97.86)\n",
      "Test: [515/599]\tTime  0.254 ( 0.241)\tLoss 3.0996e-01 (6.2301e-01)\tAcc@1  95.83 ( 82.50)\tAcc@5 100.00 ( 97.84)\n",
      "Test: [520/599]\tTime  0.255 ( 0.241)\tLoss 7.2167e-01 (6.2306e-01)\tAcc@1  79.17 ( 82.53)\tAcc@5 100.00 ( 97.83)\n",
      "Test: [525/599]\tTime  0.256 ( 0.241)\tLoss 3.9997e-01 (6.2267e-01)\tAcc@1  91.67 ( 82.57)\tAcc@5 100.00 ( 97.81)\n",
      "Test: [530/599]\tTime  0.259 ( 0.241)\tLoss 1.0239e+00 (6.2892e-01)\tAcc@1  54.17 ( 82.31)\tAcc@5 100.00 ( 97.80)\n",
      "Test: [535/599]\tTime  0.254 ( 0.241)\tLoss 3.1897e-01 (6.2998e-01)\tAcc@1  95.83 ( 82.25)\tAcc@5 100.00 ( 97.80)\n",
      "Test: [540/599]\tTime  0.243 ( 0.242)\tLoss 6.7877e-01 (6.2943e-01)\tAcc@1  95.83 ( 82.33)\tAcc@5 100.00 ( 97.80)\n",
      "Test: [545/599]\tTime  0.266 ( 0.242)\tLoss 1.2287e+00 (6.3125e-01)\tAcc@1  79.17 ( 82.29)\tAcc@5  91.67 ( 97.80)\n",
      "Test: [550/599]\tTime  0.291 ( 0.242)\tLoss 8.0297e-01 (6.3026e-01)\tAcc@1  87.50 ( 82.39)\tAcc@5 100.00 ( 97.81)\n",
      "Test: [555/599]\tTime  0.291 ( 0.242)\tLoss 7.5418e-01 (6.3085e-01)\tAcc@1  87.50 ( 82.46)\tAcc@5 100.00 ( 97.82)\n",
      "Test: [560/599]\tTime  0.289 ( 0.242)\tLoss 4.7937e-01 (6.3191e-01)\tAcc@1  95.83 ( 82.48)\tAcc@5 100.00 ( 97.80)\n",
      "Test: [565/599]\tTime  0.252 ( 0.243)\tLoss 1.0656e+00 (6.3268e-01)\tAcc@1  70.83 ( 82.52)\tAcc@5  95.83 ( 97.80)\n",
      "Test: [570/599]\tTime  0.303 ( 0.243)\tLoss 1.3537e-01 (6.3278e-01)\tAcc@1 100.00 ( 82.57)\tAcc@5 100.00 ( 97.79)\n",
      "Test: [575/599]\tTime  0.260 ( 0.243)\tLoss 6.8262e-01 (6.3483e-01)\tAcc@1  91.67 ( 82.55)\tAcc@5  95.83 ( 97.74)\n",
      "Test: [580/599]\tTime  0.275 ( 0.243)\tLoss 3.4483e-01 (6.3391e-01)\tAcc@1  91.67 ( 82.59)\tAcc@5 100.00 ( 97.76)\n",
      "Test: [585/599]\tTime  0.249 ( 0.243)\tLoss 3.3833e-01 (6.3089e-01)\tAcc@1  95.83 ( 82.71)\tAcc@5 100.00 ( 97.77)\n",
      "Test: [590/599]\tTime  0.276 ( 0.244)\tLoss 1.0260e+00 (6.3078e-01)\tAcc@1  79.17 ( 82.73)\tAcc@5  91.67 ( 97.78)\n",
      "Test: [595/599]\tTime  0.269 ( 0.244)\tLoss 7.7857e-01 (6.3183e-01)\tAcc@1  87.50 ( 82.77)\tAcc@5  91.67 ( 97.76)\n",
      " * Acc@1 82.816 Acc@5 97.767\n"
     ]
    }
   ],
   "source": [
    "epochs = 50\n",
    "batch_size = 24\n",
    "import torch.nn as nn\n",
    "\n",
    "test_transform=transforms.Compose([\n",
    "                    transforms.Resize((448, 448)),\n",
    "                    transforms.ToTensor(),\n",
    "                    transforms.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225))\n",
    "                ])\n",
    "\n",
    "transform = transforms.Compose([ \n",
    "\n",
    "        transforms.CenterCrop(384),\n",
    "        transforms.RandomRotation(20),\n",
    "        transforms.RandomHorizontalFlip(p=0.5),\n",
    "        transforms.GaussianBlur(3, sigma=(0.1, 2.0)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=mean, std=std)\n",
    "    ])\n",
    "\n",
    "# Load Data\n",
    "train_loader, val_loader,test_loader = cub_and_dogs(bs=batch_size, data_transform = transform, test_transform=test_transform)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "model = myresnetv2_task2(num_classes=320)\n",
    "\n",
    "model = model.to(device)\n",
    "\n",
    "path = \"/home/hashmat.malik/Fall 2021/CV703 Lab/Week5/datasets/modelresnetv2448_submission_task2_exp2_best.pth.tar\"\n",
    "checkpoint = torch.load(path)\n",
    "\n",
    "model.load_state_dict(checkpoint['state_dict'])\n",
    "\n",
    "\n",
    "\n",
    "optimizer = model.parameters([\n",
    "                {'params': 0.99, 'lr': 0.0001, 'betas': (0.5, 0.999)},\n",
    "                {'params': 0.99, 'lr': 0.00001, 'betas': (0.5, 0.999)}])\n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "train_model(30, train_loader, val_loader, test_loader, optimizer, criterion, model, f'resnetv2_fusion_{1}', is_train=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "220f03e5",
   "metadata": {},
   "source": [
    "Reached top1 validation accuracy of 82.278% and top1 test accuracy of 82.816%"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e168dfe0",
   "metadata": {},
   "source": [
    "## Center Loss\n",
    "In addition to cross entropy loss used for classification, we also tried to incorporate center loss into the objective function. The reasoning behind this was as there is less inter-class variation among the classes, center-loss would try to separate the classes in the feature space for easier classification. **The implementation of the loss function is in loss.py file.**\n",
    "Here we are showing the results of center loss on resnetv2-448 using cub and dogs dataset. For comparison , we are only showing models trained without any data augmentation (just resize and normalisation) for the sake of clarity. Best Top1 val accuracy on resnetv2-448 with cross-entropy loss was 82.28 and best top1 test accuracy with cross entropy loss was 82.816%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fdbe3831",
   "metadata": {},
   "outputs": [],
   "source": [
    "# implementation of dataloaders is done in dataset.py file.\n",
    "data_transform = transforms.Compose([  #\n",
    "\n",
    "        transforms.Resize((448, 448)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=mean, std=std)\n",
    "    ])\n",
    "train_loader, val_loader, test_loader = cub_and_dogs(bs=batch_size, data_transform=data_transform, test_transform=test_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "27f1fdc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test: [ 0/57]\tTime  0.670 ( 0.670)\tent_Loss 4.6718e-01 (4.6718e-01)\tcenter_loss 2.7889e+03 (2.7889e+03)\tloss 8.8340e+00 (8.8340e+00)\tAcc@1  90.62 ( 90.62)\tAcc@5  96.88 ( 96.88)\n",
      "Test: [ 5/57]\tTime  0.307 ( 0.392)\tent_Loss 6.0692e-01 (5.8485e-01)\tcenter_loss 2.6108e+03 (2.6260e+03)\tloss 8.4393e+00 (8.4629e+00)\tAcc@1  87.50 ( 85.94)\tAcc@5  96.88 ( 96.35)\n",
      "Test: [10/57]\tTime  0.344 ( 0.371)\tent_Loss 8.7803e-01 (6.5627e-01)\tcenter_loss 2.6980e+03 (2.6443e+03)\tloss 8.9719e+00 (8.5892e+00)\tAcc@1  71.88 ( 83.81)\tAcc@5 100.00 ( 97.16)\n",
      "Test: [15/57]\tTime  0.351 ( 0.369)\tent_Loss 5.8840e-01 (6.5883e-01)\tcenter_loss 2.7748e+03 (2.6576e+03)\tloss 8.9129e+00 (8.6316e+00)\tAcc@1  84.38 ( 83.01)\tAcc@5  93.75 ( 97.27)\n",
      "Test: [20/57]\tTime  0.341 ( 0.362)\tent_Loss 7.4801e-01 (6.5629e-01)\tcenter_loss 2.5609e+03 (2.6474e+03)\tloss 8.4308e+00 (8.5986e+00)\tAcc@1  68.75 ( 82.59)\tAcc@5  96.88 ( 97.32)\n",
      "Test: [25/57]\tTime  0.318 ( 0.355)\tent_Loss 7.6398e-01 (6.8024e-01)\tcenter_loss 2.5907e+03 (2.6607e+03)\tloss 8.5360e+00 (8.6623e+00)\tAcc@1  84.38 ( 81.49)\tAcc@5 100.00 ( 97.36)\n",
      "Test: [30/57]\tTime  0.328 ( 0.354)\tent_Loss 7.6714e-01 (6.5922e-01)\tcenter_loss 2.4952e+03 (2.6592e+03)\tloss 8.2528e+00 (8.6369e+00)\tAcc@1  78.12 ( 81.85)\tAcc@5  96.88 ( 97.38)\n",
      "Test: [35/57]\tTime  0.337 ( 0.353)\tent_Loss 9.2787e-01 (6.6197e-01)\tcenter_loss 2.6663e+03 (2.6586e+03)\tloss 8.9267e+00 (8.6377e+00)\tAcc@1  71.88 ( 81.86)\tAcc@5  90.62 ( 97.22)\n",
      "Test: [40/57]\tTime  0.364 ( 0.351)\tent_Loss 5.0169e-01 (6.5641e-01)\tcenter_loss 2.6391e+03 (2.6556e+03)\tloss 8.4191e+00 (8.6232e+00)\tAcc@1  90.62 ( 82.24)\tAcc@5 100.00 ( 96.95)\n",
      "Test: [45/57]\tTime  0.335 ( 0.350)\tent_Loss 8.4493e-01 (6.6591e-01)\tcenter_loss 2.7402e+03 (2.6554e+03)\tloss 9.0654e+00 (8.6320e+00)\tAcc@1  81.25 ( 82.13)\tAcc@5  93.75 ( 96.60)\n",
      "Test: [50/57]\tTime  0.324 ( 0.349)\tent_Loss 5.3696e-01 (6.5971e-01)\tcenter_loss 2.6893e+03 (2.6575e+03)\tloss 8.6048e+00 (8.6322e+00)\tAcc@1  84.38 ( 82.23)\tAcc@5 100.00 ( 96.69)\n",
      "Test: [55/57]\tTime  0.307 ( 0.347)\tent_Loss 5.2990e-01 (6.5396e-01)\tcenter_loss 2.7004e+03 (2.6634e+03)\tloss 8.6312e+00 (8.6441e+00)\tAcc@1  84.38 ( 82.03)\tAcc@5 100.00 ( 96.93)\n",
      " * Acc@1 82.056 Acc@5 96.944\n",
      "Test: [  0/450]\tTime  0.620 ( 0.620)\tent_Loss 1.2051e+00 (1.2051e+00)\tcenter_loss 2.2961e+03 (2.2961e+03)\tloss 8.0933e+00 (8.0933e+00)\tAcc@1  68.75 ( 68.75)\tAcc@5  87.50 ( 87.50)\n",
      "Test: [  5/450]\tTime  0.253 ( 0.333)\tent_Loss 5.3597e-01 (7.7657e-01)\tcenter_loss 2.5884e+03 (2.5444e+03)\tloss 8.3011e+00 (8.4098e+00)\tAcc@1  81.25 ( 80.21)\tAcc@5 100.00 ( 93.75)\n",
      "Test: [ 10/450]\tTime  0.284 ( 0.297)\tent_Loss 1.2767e+00 (8.2466e-01)\tcenter_loss 2.4929e+03 (2.5492e+03)\tloss 8.7554e+00 (8.4723e+00)\tAcc@1  68.75 ( 78.98)\tAcc@5  93.75 ( 94.32)\n",
      "Test: [ 15/450]\tTime  0.239 ( 0.282)\tent_Loss 3.6212e-01 (8.7309e-01)\tcenter_loss 2.3979e+03 (2.5211e+03)\tloss 7.5557e+00 (8.4365e+00)\tAcc@1  81.25 ( 75.00)\tAcc@5 100.00 ( 94.73)\n",
      "Test: [ 20/450]\tTime  0.245 ( 0.276)\tent_Loss 9.1711e-01 (7.5920e-01)\tcenter_loss 2.5176e+03 (2.4976e+03)\tloss 8.4700e+00 (8.2520e+00)\tAcc@1  78.12 ( 79.02)\tAcc@5  96.88 ( 95.68)\n",
      "Test: [ 25/450]\tTime  0.270 ( 0.275)\tent_Loss 2.0427e-01 (7.9513e-01)\tcenter_loss 2.1836e+03 (2.4755e+03)\tloss 6.7552e+00 (8.2215e+00)\tAcc@1  96.88 ( 78.85)\tAcc@5 100.00 ( 95.07)\n",
      "Test: [ 30/450]\tTime  0.302 ( 0.278)\tent_Loss 6.1619e-01 (7.7721e-01)\tcenter_loss 2.3286e+03 (2.4353e+03)\tloss 7.6019e+00 (8.0830e+00)\tAcc@1  68.75 ( 79.23)\tAcc@5  96.88 ( 95.06)\n",
      "Test: [ 35/450]\tTime  0.325 ( 0.278)\tent_Loss 1.0398e+00 (7.7928e-01)\tcenter_loss 2.2433e+03 (2.4068e+03)\tloss 7.7698e+00 (7.9998e+00)\tAcc@1  68.75 ( 78.30)\tAcc@5  90.62 ( 95.49)\n",
      "Test: [ 40/450]\tTime  0.258 ( 0.277)\tent_Loss 4.8300e-01 (7.8922e-01)\tcenter_loss 2.2878e+03 (2.3960e+03)\tloss 7.3464e+00 (7.9771e+00)\tAcc@1  90.62 ( 78.73)\tAcc@5 100.00 ( 95.50)\n",
      "Test: [ 45/450]\tTime  0.261 ( 0.276)\tent_Loss 4.9482e-01 (8.1068e-01)\tcenter_loss 2.3777e+03 (2.3880e+03)\tloss 7.6279e+00 (7.9748e+00)\tAcc@1  87.50 ( 77.38)\tAcc@5  96.88 ( 95.58)\n",
      "Test: [ 50/450]\tTime  0.240 ( 0.274)\tent_Loss 8.9540e-01 (7.8609e-01)\tcenter_loss 2.2180e+03 (2.3720e+03)\tloss 7.5495e+00 (7.9021e+00)\tAcc@1  71.88 ( 77.51)\tAcc@5  96.88 ( 95.89)\n",
      "Test: [ 55/450]\tTime  0.270 ( 0.273)\tent_Loss 5.4128e-01 (7.9994e-01)\tcenter_loss 2.5212e+03 (2.3803e+03)\tloss 8.1048e+00 (7.9409e+00)\tAcc@1  87.50 ( 77.62)\tAcc@5  96.88 ( 95.76)\n",
      "Test: [ 60/450]\tTime  0.276 ( 0.272)\tent_Loss 2.0193e-01 (7.6499e-01)\tcenter_loss 2.5367e+03 (2.3836e+03)\tloss 7.8120e+00 (7.9158e+00)\tAcc@1  93.75 ( 78.53)\tAcc@5 100.00 ( 96.06)\n",
      "Test: [ 65/450]\tTime  0.275 ( 0.271)\tent_Loss 5.6050e-01 (7.3959e-01)\tcenter_loss 2.2377e+03 (2.3772e+03)\tloss 7.2735e+00 (7.8712e+00)\tAcc@1  81.25 ( 79.21)\tAcc@5  96.88 ( 96.21)\n",
      "Test: [ 70/450]\tTime  0.282 ( 0.271)\tent_Loss 1.3970e+00 (7.4918e-01)\tcenter_loss 2.3258e+03 (2.3720e+03)\tloss 8.3745e+00 (7.8652e+00)\tAcc@1  71.88 ( 79.09)\tAcc@5  90.62 ( 96.08)\n",
      "Test: [ 75/450]\tTime  0.256 ( 0.270)\tent_Loss 1.6007e+00 (7.7484e-01)\tcenter_loss 2.3545e+03 (2.3796e+03)\tloss 8.6642e+00 (7.9135e+00)\tAcc@1  56.25 ( 78.37)\tAcc@5  93.75 ( 95.97)\n",
      "Test: [ 80/450]\tTime  0.256 ( 0.271)\tent_Loss 8.3531e-01 (7.4876e-01)\tcenter_loss 2.4058e+03 (2.3825e+03)\tloss 8.0526e+00 (7.8962e+00)\tAcc@1  81.25 ( 79.13)\tAcc@5  93.75 ( 96.14)\n",
      "Test: [ 85/450]\tTime  0.249 ( 0.271)\tent_Loss 6.7516e-01 (7.3849e-01)\tcenter_loss 2.3440e+03 (2.3885e+03)\tloss 7.7072e+00 (7.9040e+00)\tAcc@1  81.25 ( 79.54)\tAcc@5 100.00 ( 96.18)\n",
      "Test: [ 90/450]\tTime  0.246 ( 0.269)\tent_Loss 7.8896e-01 (7.5295e-01)\tcenter_loss 2.4853e+03 (2.3928e+03)\tloss 8.2449e+00 (7.9313e+00)\tAcc@1  68.75 ( 79.22)\tAcc@5 100.00 ( 96.15)\n",
      "Test: [ 95/450]\tTime  0.264 ( 0.268)\tent_Loss 1.3651e+00 (7.6884e-01)\tcenter_loss 2.5139e+03 (2.3974e+03)\tloss 8.9067e+00 (7.9610e+00)\tAcc@1  65.62 ( 78.74)\tAcc@5  93.75 ( 96.26)\n",
      "Test: [100/450]\tTime  0.260 ( 0.267)\tent_Loss 6.2243e-01 (7.7104e-01)\tcenter_loss 2.5066e+03 (2.4035e+03)\tloss 8.1423e+00 (7.9816e+00)\tAcc@1  84.38 ( 78.81)\tAcc@5  93.75 ( 96.13)\n",
      "Test: [105/450]\tTime  0.266 ( 0.267)\tent_Loss 9.7741e-01 (7.6989e-01)\tcenter_loss 2.3448e+03 (2.4024e+03)\tloss 8.0119e+00 (7.9772e+00)\tAcc@1  71.88 ( 78.69)\tAcc@5  93.75 ( 96.14)\n",
      "Test: [110/450]\tTime  0.247 ( 0.266)\tent_Loss 4.2806e-01 (7.6377e-01)\tcenter_loss 2.3719e+03 (2.4062e+03)\tloss 7.5437e+00 (7.9823e+00)\tAcc@1  90.62 ( 78.91)\tAcc@5  96.88 ( 96.20)\n",
      "Test: [115/450]\tTime  0.261 ( 0.265)\tent_Loss 1.1335e+00 (7.5661e-01)\tcenter_loss 2.4685e+03 (2.4092e+03)\tloss 8.5389e+00 (7.9843e+00)\tAcc@1  68.75 ( 79.09)\tAcc@5  90.62 ( 96.23)\n",
      "Test: [120/450]\tTime  0.245 ( 0.265)\tent_Loss 1.1558e+00 (7.6399e-01)\tcenter_loss 2.2859e+03 (2.4073e+03)\tloss 8.0134e+00 (7.9859e+00)\tAcc@1  71.88 ( 78.82)\tAcc@5  93.75 ( 96.28)\n",
      "Test: [125/450]\tTime  0.295 ( 0.265)\tent_Loss 1.5050e+00 (7.8033e-01)\tcenter_loss 2.3706e+03 (2.4029e+03)\tloss 8.6167e+00 (7.9892e+00)\tAcc@1  53.12 ( 78.55)\tAcc@5  87.50 ( 96.08)\n",
      "Test: [130/450]\tTime  0.232 ( 0.264)\tent_Loss 2.9490e-01 (7.9205e-01)\tcenter_loss 2.4600e+03 (2.4019e+03)\tloss 7.6748e+00 (7.9978e+00)\tAcc@1  93.75 ( 78.17)\tAcc@5  96.88 ( 96.09)\n",
      "Test: [135/450]\tTime  0.264 ( 0.264)\tent_Loss 5.4498e-01 (7.8562e-01)\tcenter_loss 2.0787e+03 (2.4003e+03)\tloss 6.7810e+00 (7.9865e+00)\tAcc@1  90.62 ( 78.26)\tAcc@5 100.00 ( 96.19)\n",
      "Test: [140/450]\tTime  0.258 ( 0.264)\tent_Loss 4.0269e-01 (7.7757e-01)\tcenter_loss 2.0974e+03 (2.3941e+03)\tloss 6.6950e+00 (7.9598e+00)\tAcc@1  90.62 ( 78.48)\tAcc@5 100.00 ( 96.19)\n",
      "Test: [145/450]\tTime  0.314 ( 0.264)\tent_Loss 3.1159e-01 (7.7263e-01)\tcenter_loss 2.6592e+03 (2.3913e+03)\tloss 8.2891e+00 (7.9466e+00)\tAcc@1  84.38 ( 78.60)\tAcc@5 100.00 ( 96.23)\n",
      "Test: [150/450]\tTime  0.219 ( 0.263)\tent_Loss 7.1368e-02 (7.6254e-01)\tcenter_loss 2.3139e+03 (2.3931e+03)\tloss 7.0130e+00 (7.9418e+00)\tAcc@1 100.00 ( 78.93)\tAcc@5 100.00 ( 96.30)\n",
      "Test: [155/450]\tTime  0.240 ( 0.263)\tent_Loss 2.5432e-01 (7.5021e-01)\tcenter_loss 2.3123e+03 (2.3924e+03)\tloss 7.1913e+00 (7.9273e+00)\tAcc@1  90.62 ( 79.23)\tAcc@5 100.00 ( 96.33)\n",
      "Test: [160/450]\tTime  0.241 ( 0.263)\tent_Loss 1.0439e+00 (7.4857e-01)\tcenter_loss 2.3179e+03 (2.3934e+03)\tloss 7.9976e+00 (7.9287e+00)\tAcc@1  65.62 ( 79.29)\tAcc@5  87.50 ( 96.33)\n",
      "Test: [165/450]\tTime  0.248 ( 0.264)\tent_Loss 6.6740e-01 (7.4261e-01)\tcenter_loss 2.4480e+03 (2.3907e+03)\tloss 8.0115e+00 (7.9148e+00)\tAcc@1  78.12 ( 79.44)\tAcc@5  96.88 ( 96.39)\n",
      "Test: [170/450]\tTime  0.248 ( 0.263)\tent_Loss 4.7232e-01 (7.3439e-01)\tcenter_loss 2.3768e+03 (2.3916e+03)\tloss 7.6028e+00 (7.9092e+00)\tAcc@1  81.25 ( 79.61)\tAcc@5 100.00 ( 96.45)\n",
      "Test: [175/450]\tTime  0.260 ( 0.263)\tent_Loss 2.1642e-01 (7.3039e-01)\tcenter_loss 2.0155e+03 (2.3846e+03)\tloss 6.2629e+00 (7.8841e+00)\tAcc@1  93.75 ( 79.72)\tAcc@5 100.00 ( 96.47)\n",
      "Test: [180/450]\tTime  0.253 ( 0.264)\tent_Loss 1.1116e+00 (7.3373e-01)\tcenter_loss 2.3581e+03 (2.3814e+03)\tloss 8.1859e+00 (7.8779e+00)\tAcc@1  65.62 ( 79.49)\tAcc@5  93.75 ( 96.50)\n",
      "Test: [185/450]\tTime  0.261 ( 0.264)\tent_Loss 6.2038e-01 (7.3389e-01)\tcenter_loss 2.3651e+03 (2.3823e+03)\tloss 7.7157e+00 (7.8808e+00)\tAcc@1  75.00 ( 79.42)\tAcc@5 100.00 ( 96.52)\n",
      "Test: [190/450]\tTime  0.249 ( 0.264)\tent_Loss 8.7020e-01 (7.3582e-01)\tcenter_loss 2.2315e+03 (2.3791e+03)\tloss 7.5648e+00 (7.8731e+00)\tAcc@1  68.75 ( 79.32)\tAcc@5 100.00 ( 96.55)\n",
      "Test: [195/450]\tTime  0.254 ( 0.264)\tent_Loss 2.4061e-01 (7.3138e-01)\tcenter_loss 2.5247e+03 (2.3819e+03)\tloss 7.8146e+00 (7.8772e+00)\tAcc@1  90.62 ( 79.37)\tAcc@5 100.00 ( 96.64)\n",
      "Test: [200/450]\tTime  0.248 ( 0.264)\tent_Loss 7.9039e-01 (7.3293e-01)\tcenter_loss 2.4925e+03 (2.3830e+03)\tloss 8.2680e+00 (7.8819e+00)\tAcc@1  84.38 ( 79.34)\tAcc@5  96.88 ( 96.67)\n",
      "Test: [205/450]\tTime  0.302 ( 0.264)\tent_Loss 1.4803e+00 (7.3321e-01)\tcenter_loss 2.2863e+03 (2.3836e+03)\tloss 8.3392e+00 (7.8841e+00)\tAcc@1  68.75 ( 79.37)\tAcc@5  90.62 ( 96.66)\n",
      "Test: [210/450]\tTime  0.272 ( 0.265)\tent_Loss 7.9358e-01 (7.3175e-01)\tcenter_loss 2.3143e+03 (2.3831e+03)\tloss 7.7366e+00 (7.8810e+00)\tAcc@1  78.12 ( 79.40)\tAcc@5  96.88 ( 96.67)\n",
      "Test: [215/450]\tTime  0.263 ( 0.264)\tent_Loss 9.5230e-01 (7.4083e-01)\tcenter_loss 2.8122e+03 (2.3866e+03)\tloss 9.3890e+00 (7.9006e+00)\tAcc@1  68.75 ( 79.08)\tAcc@5 100.00 ( 96.73)\n",
      "Test: [220/450]\tTime  0.226 ( 0.264)\tent_Loss 6.8908e-01 (7.5204e-01)\tcenter_loss 2.5069e+03 (2.3928e+03)\tloss 8.2098e+00 (7.9306e+00)\tAcc@1  71.88 ( 78.69)\tAcc@5  96.88 ( 96.72)\n",
      "Test: [225/450]\tTime  0.270 ( 0.264)\tent_Loss 7.4296e-01 (7.4493e-01)\tcenter_loss 2.5642e+03 (2.3924e+03)\tloss 8.4355e+00 (7.9222e+00)\tAcc@1  78.12 ( 78.87)\tAcc@5  96.88 ( 96.78)\n",
      "Test: [230/450]\tTime  0.243 ( 0.264)\tent_Loss 1.2891e-01 (7.3459e-01)\tcenter_loss 2.1845e+03 (2.3910e+03)\tloss 6.6823e+00 (7.9076e+00)\tAcc@1  96.88 ( 79.18)\tAcc@5 100.00 ( 96.83)\n",
      "Test: [235/450]\tTime  0.256 ( 0.264)\tent_Loss 1.2983e+00 (7.3658e-01)\tcenter_loss 2.2911e+03 (2.3895e+03)\tloss 8.1717e+00 (7.9050e+00)\tAcc@1  62.50 ( 79.13)\tAcc@5  96.88 ( 96.81)\n",
      "Test: [240/450]\tTime  0.246 ( 0.264)\tent_Loss 1.4372e-01 (7.3026e-01)\tcenter_loss 2.3647e+03 (2.3881e+03)\tloss 7.2379e+00 (7.8945e+00)\tAcc@1  93.75 ( 79.24)\tAcc@5 100.00 ( 96.86)\n",
      "Test: [245/450]\tTime  0.262 ( 0.264)\tent_Loss 1.9612e-01 (7.2067e-01)\tcenter_loss 2.5032e+03 (2.3899e+03)\tloss 7.7056e+00 (7.8903e+00)\tAcc@1  93.75 ( 79.51)\tAcc@5 100.00 ( 96.91)\n",
      "Test: [250/450]\tTime  0.251 ( 0.263)\tent_Loss 8.4732e-01 (7.1259e-01)\tcenter_loss 2.4520e+03 (2.3924e+03)\tloss 8.2032e+00 (7.8898e+00)\tAcc@1  84.38 ( 79.78)\tAcc@5  93.75 ( 96.94)\n",
      "Test: [255/450]\tTime  0.260 ( 0.263)\tent_Loss 5.3646e-01 (7.1271e-01)\tcenter_loss 2.5353e+03 (2.3946e+03)\tloss 8.1424e+00 (7.8965e+00)\tAcc@1  78.12 ( 79.77)\tAcc@5 100.00 ( 96.96)\n",
      "Test: [260/450]\tTime  0.247 ( 0.263)\tent_Loss 5.9850e-01 (7.2753e-01)\tcenter_loss 2.1907e+03 (2.3930e+03)\tloss 7.1707e+00 (7.9065e+00)\tAcc@1  71.88 ( 79.32)\tAcc@5 100.00 ( 96.89)\n",
      "Test: [265/450]\tTime  0.259 ( 0.263)\tent_Loss 2.8639e-01 (7.2580e-01)\tcenter_loss 2.6194e+03 (2.3945e+03)\tloss 8.1445e+00 (7.9093e+00)\tAcc@1  93.75 ( 79.38)\tAcc@5 100.00 ( 96.89)\n",
      "Test: [270/450]\tTime  0.296 ( 0.263)\tent_Loss 2.8677e-01 (7.1923e-01)\tcenter_loss 2.9479e+03 (2.4011e+03)\tloss 9.1306e+00 (7.9226e+00)\tAcc@1  90.62 ( 79.58)\tAcc@5 100.00 ( 96.91)\n",
      "Test: [275/450]\tTime  0.294 ( 0.263)\tent_Loss 9.8427e-01 (7.1775e-01)\tcenter_loss 3.1745e+03 (2.4187e+03)\tloss 1.0508e+01 (7.9737e+00)\tAcc@1  81.25 ( 79.65)\tAcc@5  84.38 ( 96.90)\n",
      "Test: [280/450]\tTime  0.318 ( 0.264)\tent_Loss 5.7097e-01 (7.1434e-01)\tcenter_loss 3.3571e+03 (2.4351e+03)\tloss 1.0642e+01 (8.0196e+00)\tAcc@1  87.50 ( 79.79)\tAcc@5  93.75 ( 96.89)\n",
      "Test: [285/450]\tTime  0.298 ( 0.265)\tent_Loss 9.6701e-01 (7.0841e-01)\tcenter_loss 3.1743e+03 (2.4503e+03)\tloss 1.0490e+01 (8.0592e+00)\tAcc@1  65.62 ( 79.97)\tAcc@5 100.00 ( 96.94)\n",
      "Test: [290/450]\tTime  0.315 ( 0.265)\tent_Loss 1.0888e+00 (7.1336e-01)\tcenter_loss 3.4921e+03 (2.4667e+03)\tloss 1.1565e+01 (8.1135e+00)\tAcc@1  78.12 ( 79.86)\tAcc@5  90.62 ( 96.91)\n",
      "Test: [295/450]\tTime  0.317 ( 0.266)\tent_Loss 4.3602e-01 (7.1601e-01)\tcenter_loss 3.2653e+03 (2.4823e+03)\tloss 1.0232e+01 (8.1628e+00)\tAcc@1  96.88 ( 79.78)\tAcc@5 100.00 ( 96.92)\n",
      "Test: [300/450]\tTime  0.301 ( 0.266)\tent_Loss 1.5509e+00 (7.1631e-01)\tcenter_loss 3.6163e+03 (2.4975e+03)\tloss 1.2400e+01 (8.2090e+00)\tAcc@1  59.38 ( 79.73)\tAcc@5  87.50 ( 96.91)\n",
      "Test: [305/450]\tTime  0.275 ( 0.267)\tent_Loss 5.9966e-01 (7.2026e-01)\tcenter_loss 3.4702e+03 (2.5153e+03)\tloss 1.1010e+01 (8.2660e+00)\tAcc@1  87.50 ( 79.65)\tAcc@5  96.88 ( 96.86)\n",
      "Test: [310/450]\tTime  0.289 ( 0.267)\tent_Loss 1.0080e+00 (7.1544e-01)\tcenter_loss 3.2994e+03 (2.5298e+03)\tloss 1.0906e+01 (8.3048e+00)\tAcc@1  62.50 ( 79.76)\tAcc@5  96.88 ( 96.90)\n",
      "Test: [315/450]\tTime  0.316 ( 0.268)\tent_Loss 2.7433e-01 (7.1011e-01)\tcenter_loss 3.2685e+03 (2.5421e+03)\tloss 1.0080e+01 (8.3364e+00)\tAcc@1  90.62 ( 79.91)\tAcc@5  96.88 ( 96.93)\n",
      "Test: [320/450]\tTime  0.308 ( 0.268)\tent_Loss 1.2231e+00 (7.1219e-01)\tcenter_loss 3.4066e+03 (2.5540e+03)\tloss 1.1443e+01 (8.3742e+00)\tAcc@1  59.38 ( 79.80)\tAcc@5  93.75 ( 96.93)\n",
      "Test: [325/450]\tTime  0.286 ( 0.268)\tent_Loss 9.8873e-01 (7.1670e-01)\tcenter_loss 3.6374e+03 (2.5686e+03)\tloss 1.1901e+01 (8.4225e+00)\tAcc@1  62.50 ( 79.62)\tAcc@5 100.00 ( 96.87)\n",
      "Test: [330/450]\tTime  0.262 ( 0.269)\tent_Loss 1.5461e+00 (7.1948e-01)\tcenter_loss 3.4686e+03 (2.5809e+03)\tloss 1.1952e+01 (8.4621e+00)\tAcc@1  56.25 ( 79.53)\tAcc@5  87.50 ( 96.85)\n",
      "Test: [335/450]\tTime  0.302 ( 0.269)\tent_Loss 2.4554e-01 (7.1498e-01)\tcenter_loss 3.3811e+03 (2.5900e+03)\tloss 1.0389e+01 (8.4851e+00)\tAcc@1  93.75 ( 79.70)\tAcc@5 100.00 ( 96.86)\n",
      "Test: [340/450]\tTime  0.311 ( 0.270)\tent_Loss 6.8356e-01 (7.1075e-01)\tcenter_loss 3.3601e+03 (2.6017e+03)\tloss 1.0764e+01 (8.5159e+00)\tAcc@1  84.38 ( 79.87)\tAcc@5 100.00 ( 96.89)\n",
      "Test: [345/450]\tTime  0.306 ( 0.270)\tent_Loss 2.4465e-01 (7.0508e-01)\tcenter_loss 3.1792e+03 (2.6107e+03)\tloss 9.7823e+00 (8.5371e+00)\tAcc@1  93.75 ( 80.05)\tAcc@5 100.00 ( 96.92)\n",
      "Test: [350/450]\tTime  0.318 ( 0.271)\tent_Loss 4.4560e-02 (6.9977e-01)\tcenter_loss 3.3521e+03 (2.6208e+03)\tloss 1.0101e+01 (8.5621e+00)\tAcc@1 100.00 ( 80.21)\tAcc@5 100.00 ( 96.95)\n",
      "Test: [355/450]\tTime  0.308 ( 0.271)\tent_Loss 6.7022e-01 (6.9836e-01)\tcenter_loss 3.5827e+03 (2.6310e+03)\tloss 1.1418e+01 (8.5913e+00)\tAcc@1  84.38 ( 80.31)\tAcc@5  93.75 ( 96.91)\n",
      "Test: [360/450]\tTime  0.295 ( 0.272)\tent_Loss 1.0392e+00 (6.9854e-01)\tcenter_loss 3.8167e+03 (2.6435e+03)\tloss 1.2489e+01 (8.6292e+00)\tAcc@1  68.75 ( 80.30)\tAcc@5  96.88 ( 96.91)\n",
      "Test: [365/450]\tTime  0.304 ( 0.272)\tent_Loss 3.0397e-01 (6.9869e-01)\tcenter_loss 3.3122e+03 (2.6523e+03)\tloss 1.0241e+01 (8.6555e+00)\tAcc@1  93.75 ( 80.25)\tAcc@5  96.88 ( 96.91)\n",
      "Test: [370/450]\tTime  0.294 ( 0.272)\tent_Loss 1.0337e+00 (6.9863e-01)\tcenter_loss 3.5046e+03 (2.6634e+03)\tloss 1.1548e+01 (8.6889e+00)\tAcc@1  78.12 ( 80.27)\tAcc@5  90.62 ( 96.90)\n",
      "Test: [375/450]\tTime  0.311 ( 0.273)\tent_Loss 1.5149e+00 (7.0373e-01)\tcenter_loss 3.6524e+03 (2.6772e+03)\tloss 1.2472e+01 (8.7354e+00)\tAcc@1  56.25 ( 80.15)\tAcc@5  84.38 ( 96.83)\n",
      "Test: [380/450]\tTime  0.294 ( 0.273)\tent_Loss 1.1228e+00 (7.0509e-01)\tcenter_loss 3.9730e+03 (2.6953e+03)\tloss 1.3042e+01 (8.7910e+00)\tAcc@1  71.88 ( 80.10)\tAcc@5  96.88 ( 96.85)\n",
      "Test: [385/450]\tTime  0.310 ( 0.273)\tent_Loss 8.1084e-01 (7.1032e-01)\tcenter_loss 3.5019e+03 (2.7082e+03)\tloss 1.1317e+01 (8.8350e+00)\tAcc@1  81.25 ( 79.98)\tAcc@5  96.88 ( 96.79)\n",
      "Test: [390/450]\tTime  0.299 ( 0.274)\tent_Loss 6.9471e-01 (7.0949e-01)\tcenter_loss 3.2128e+03 (2.7172e+03)\tloss 1.0333e+01 (8.8612e+00)\tAcc@1  81.25 ( 80.02)\tAcc@5  96.88 ( 96.76)\n",
      "Test: [395/450]\tTime  0.306 ( 0.274)\tent_Loss 1.2769e+00 (7.0908e-01)\tcenter_loss 3.6221e+03 (2.7262e+03)\tloss 1.2143e+01 (8.8876e+00)\tAcc@1  65.62 ( 80.06)\tAcc@5  93.75 ( 96.76)\n",
      "Test: [400/450]\tTime  0.284 ( 0.274)\tent_Loss 2.6336e-01 (7.1310e-01)\tcenter_loss 3.6607e+03 (2.7380e+03)\tloss 1.1245e+01 (8.9270e+00)\tAcc@1  90.62 ( 79.90)\tAcc@5 100.00 ( 96.76)\n",
      "Test: [405/450]\tTime  0.295 ( 0.275)\tent_Loss 6.1409e-01 (7.0981e-01)\tcenter_loss 3.8956e+03 (2.7496e+03)\tloss 1.2301e+01 (8.9585e+00)\tAcc@1  81.25 ( 80.02)\tAcc@5 100.00 ( 96.77)\n",
      "Test: [410/450]\tTime  0.271 ( 0.275)\tent_Loss 7.1481e-02 (7.0846e-01)\tcenter_loss 3.3494e+03 (2.7605e+03)\tloss 1.0120e+01 (8.9900e+00)\tAcc@1 100.00 ( 80.05)\tAcc@5 100.00 ( 96.79)\n",
      "Test: [415/450]\tTime  0.250 ( 0.275)\tent_Loss 4.5042e-01 (7.0464e-01)\tcenter_loss 3.3429e+03 (2.7712e+03)\tloss 1.0479e+01 (9.0182e+00)\tAcc@1  84.38 ( 80.21)\tAcc@5  96.88 ( 96.81)\n",
      "Test: [420/450]\tTime  0.306 ( 0.275)\tent_Loss 3.4262e-01 (7.0257e-01)\tcenter_loss 3.7493e+03 (2.7848e+03)\tloss 1.1590e+01 (9.0570e+00)\tAcc@1  90.62 ( 80.31)\tAcc@5 100.00 ( 96.79)\n",
      "Test: [425/450]\tTime  0.312 ( 0.276)\tent_Loss 9.1621e-01 (7.0454e-01)\tcenter_loss 3.9368e+03 (2.7957e+03)\tloss 1.2727e+01 (9.0916e+00)\tAcc@1  78.12 ( 80.28)\tAcc@5  93.75 ( 96.76)\n",
      "Test: [430/450]\tTime  0.300 ( 0.276)\tent_Loss 4.4064e-01 (7.0296e-01)\tcenter_loss 3.6870e+03 (2.8073e+03)\tloss 1.1502e+01 (9.1249e+00)\tAcc@1  84.38 ( 80.32)\tAcc@5  96.88 ( 96.77)\n",
      "Test: [435/450]\tTime  0.306 ( 0.276)\tent_Loss 2.7327e-01 (6.9962e-01)\tcenter_loss 3.3389e+03 (2.8170e+03)\tloss 1.0290e+01 (9.1506e+00)\tAcc@1  87.50 ( 80.40)\tAcc@5 100.00 ( 96.80)\n",
      "Test: [440/450]\tTime  0.302 ( 0.277)\tent_Loss 1.5938e-01 (6.9447e-01)\tcenter_loss 3.5664e+03 (2.8250e+03)\tloss 1.0859e+01 (9.1694e+00)\tAcc@1  93.75 ( 80.54)\tAcc@5 100.00 ( 96.83)\n",
      "Test: [445/450]\tTime  0.307 ( 0.277)\tent_Loss 1.0954e+00 (6.9477e-01)\tcenter_loss 3.5009e+03 (2.8333e+03)\tloss 1.1598e+01 (9.1945e+00)\tAcc@1  71.88 ( 80.55)\tAcc@5  93.75 ( 96.83)\n",
      " * Acc@1 80.562 Acc@5 96.800\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "model = myresnetv2_for_c_loss(num_classes=320)\n",
    "model = model.to(device)\n",
    "\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "my_list = ['head.1.weight', 'head.1.bias','head.3.weight', 'head.3.bias']\n",
    "params = list(filter(lambda kv: kv[0] in my_list, model.named_parameters()))\n",
    "base_params = list(filter(lambda kv: kv[0] not in my_list, model.named_parameters()))\n",
    "\n",
    "crit_entr = torch.nn.CrossEntropyLoss()\n",
    "crit_closs = CenterLoss(num_classes=320, feat_dim=512)\n",
    "path = \"/home/hashmat.malik/Fall 2021/CV703 Lab/Week5/datasets/Task2:cub_and_dogs/Exp1/model_best_resnet_v2_cubs_dogs_0.pth.tar\"\n",
    "checkpoint = torch.load(path)\n",
    "model.load_state_dict(checkpoint['state_dict'])\n",
    "optimizer = optim.Adam([{'params':  [i[1]for i in params], 'lr': 0.0001, 'betas': (0.5, 0.999)},\n",
    "                {'params':  [i[1]for i in base_params], 'lr': 0.00001, 'betas': (0.5, 0.999)},\n",
    "                {'params': crit_closs.parameters(), 'lr': 0.01, 'betas': (0.5, 0.999)}\n",
    "                        ])\n",
    "\n",
    "scheduler = ReduceLROnPlateau(optimizer, 'max')\n",
    "train_model_with_closs(30, train_loader, val_loader, test_loader, optimizer, scheduler, crit_entr, crit_closs, model, f'resnet_v2_closs_new_lr_{0.01}', is_train=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f0595af",
   "metadata": {},
   "source": [
    "Reached top1 validation accuracy of $82.06\\%$ and top1 test accuracy of $80.562\\%$. This is still less than test accuracy of resnetv2-448 (82.09%) only trained using the cross-entropy loss. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57cefe6d",
   "metadata": {},
   "source": [
    "## Gradient-Boost Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8ff24033",
   "metadata": {},
   "outputs": [],
   "source": [
    "# resnetv2-448\n",
    "# batch_size = 48 used during training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8929287f",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_transform=transforms.Compose([\n",
    "                    transforms.Resize((448, 448)),\n",
    "                    transforms.ToTensor(),\n",
    "                    transforms.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225))\n",
    "                ])\n",
    "data_transform = transforms.Compose([  #\n",
    "\n",
    "        transforms.Resize((448, 448)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=mean, std=std)\n",
    "    ])\n",
    "train_loader, val_loader, test_loader = cub_and_dogs(bs=batch_size, data_transform=data_transform, test_transform=test_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "83f82b44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test: [ 0/57]\tTime  0.989 ( 0.989)\tLoss 6.3179e-01 (6.3179e-01)\tAcc@1  87.50 ( 87.50)\tAcc@5 100.00 (100.00)\n",
      "Test: [ 5/57]\tTime  0.328 ( 0.393)\tLoss 6.5120e-01 (5.3780e-01)\tAcc@1  78.12 ( 85.94)\tAcc@5 100.00 ( 97.92)\n",
      "Test: [10/57]\tTime  0.365 ( 0.366)\tLoss 4.1819e-01 (5.5087e-01)\tAcc@1  87.50 ( 84.94)\tAcc@5  96.88 ( 97.73)\n",
      "Test: [15/57]\tTime  0.320 ( 0.351)\tLoss 5.7923e-01 (5.5709e-01)\tAcc@1  84.38 ( 85.35)\tAcc@5 100.00 ( 97.85)\n",
      "Test: [20/57]\tTime  0.395 ( 0.348)\tLoss 3.7972e-01 (5.2617e-01)\tAcc@1  90.62 ( 86.16)\tAcc@5  96.88 ( 97.32)\n",
      "Test: [25/57]\tTime  0.329 ( 0.349)\tLoss 6.2498e-01 (5.2313e-01)\tAcc@1  87.50 ( 86.30)\tAcc@5  96.88 ( 97.72)\n",
      "Test: [30/57]\tTime  0.377 ( 0.349)\tLoss 7.4364e-01 (5.3379e-01)\tAcc@1  84.38 ( 85.89)\tAcc@5  90.62 ( 97.48)\n",
      "Test: [35/57]\tTime  0.326 ( 0.348)\tLoss 2.9191e-01 (5.3602e-01)\tAcc@1  93.75 ( 85.50)\tAcc@5 100.00 ( 97.66)\n",
      "Test: [40/57]\tTime  0.308 ( 0.345)\tLoss 6.2744e-01 (5.4051e-01)\tAcc@1  81.25 ( 84.98)\tAcc@5  96.88 ( 97.71)\n",
      "Test: [45/57]\tTime  0.309 ( 0.343)\tLoss 2.9776e-01 (5.3695e-01)\tAcc@1  93.75 ( 84.71)\tAcc@5 100.00 ( 97.76)\n",
      "Test: [50/57]\tTime  0.311 ( 0.341)\tLoss 6.4112e-01 (5.4588e-01)\tAcc@1  81.25 ( 84.38)\tAcc@5  96.88 ( 97.73)\n",
      "Test: [55/57]\tTime  0.347 ( 0.339)\tLoss 6.6176e-01 (5.5225e-01)\tAcc@1  84.38 ( 84.15)\tAcc@5  96.88 ( 97.77)\n",
      " * Acc@1 84.167 Acc@5 97.778\n",
      "Test: [  0/450]\tTime  0.622 ( 0.622)\tLoss 4.3117e-01 (4.3117e-01)\tAcc@1  87.50 ( 87.50)\tAcc@5  96.88 ( 96.88)\n",
      "Test: [  5/450]\tTime  0.325 ( 0.381)\tLoss 5.1417e-01 (5.5076e-01)\tAcc@1  78.12 ( 83.85)\tAcc@5  96.88 ( 96.88)\n",
      "Test: [ 10/450]\tTime  0.315 ( 0.354)\tLoss 4.4944e-01 (5.9754e-01)\tAcc@1  84.38 ( 82.67)\tAcc@5 100.00 ( 97.16)\n",
      "Test: [ 15/450]\tTime  0.287 ( 0.343)\tLoss 2.7739e-01 (6.2063e-01)\tAcc@1  93.75 ( 81.64)\tAcc@5 100.00 ( 96.88)\n",
      "Test: [ 20/450]\tTime  0.299 ( 0.334)\tLoss 4.8092e-01 (5.2586e-01)\tAcc@1  84.38 ( 84.38)\tAcc@5 100.00 ( 97.62)\n",
      "Test: [ 25/450]\tTime  0.322 ( 0.330)\tLoss 9.0615e-02 (5.6563e-01)\tAcc@1  96.88 ( 83.53)\tAcc@5 100.00 ( 97.48)\n",
      "Test: [ 30/450]\tTime  0.373 ( 0.331)\tLoss 4.5938e-01 (5.3436e-01)\tAcc@1  87.50 ( 84.27)\tAcc@5 100.00 ( 97.78)\n",
      "Test: [ 35/450]\tTime  0.307 ( 0.328)\tLoss 7.1938e-01 (5.2940e-01)\tAcc@1  75.00 ( 83.94)\tAcc@5  96.88 ( 98.00)\n",
      "Test: [ 40/450]\tTime  0.283 ( 0.326)\tLoss 5.0131e-01 (5.2988e-01)\tAcc@1  81.25 ( 83.99)\tAcc@5 100.00 ( 98.09)\n",
      "Test: [ 45/450]\tTime  0.304 ( 0.324)\tLoss 6.3962e-01 (5.5783e-01)\tAcc@1  81.25 ( 82.74)\tAcc@5  96.88 ( 98.23)\n",
      "Test: [ 50/450]\tTime  0.303 ( 0.322)\tLoss 9.2297e-01 (5.6885e-01)\tAcc@1  75.00 ( 82.41)\tAcc@5  96.88 ( 98.10)\n",
      "Test: [ 55/450]\tTime  0.302 ( 0.322)\tLoss 4.8230e-01 (5.7828e-01)\tAcc@1  81.25 ( 82.09)\tAcc@5 100.00 ( 97.88)\n",
      "Test: [ 60/450]\tTime  0.300 ( 0.320)\tLoss 1.4594e-01 (5.5501e-01)\tAcc@1  96.88 ( 82.94)\tAcc@5 100.00 ( 98.00)\n",
      "Test: [ 65/450]\tTime  0.301 ( 0.319)\tLoss 3.0774e-01 (5.3254e-01)\tAcc@1  93.75 ( 83.71)\tAcc@5 100.00 ( 98.06)\n",
      "Test: [ 70/450]\tTime  0.309 ( 0.319)\tLoss 8.0599e-01 (5.3284e-01)\tAcc@1  78.12 ( 83.80)\tAcc@5  93.75 ( 97.93)\n",
      "Test: [ 75/450]\tTime  0.355 ( 0.319)\tLoss 1.0879e+00 (5.5389e-01)\tAcc@1  68.75 ( 83.51)\tAcc@5  96.88 ( 97.78)\n",
      "Test: [ 80/450]\tTime  0.353 ( 0.321)\tLoss 4.6791e-01 (5.3598e-01)\tAcc@1  90.62 ( 83.99)\tAcc@5  96.88 ( 97.88)\n",
      "Test: [ 85/450]\tTime  0.287 ( 0.320)\tLoss 8.3155e-01 (5.3930e-01)\tAcc@1  78.12 ( 83.98)\tAcc@5 100.00 ( 97.82)\n",
      "Test: [ 90/450]\tTime  0.284 ( 0.319)\tLoss 1.1525e+00 (5.6244e-01)\tAcc@1  71.88 ( 83.62)\tAcc@5 100.00 ( 97.77)\n",
      "Test: [ 95/450]\tTime  0.297 ( 0.318)\tLoss 8.2130e-01 (5.7345e-01)\tAcc@1  75.00 ( 83.27)\tAcc@5  93.75 ( 97.79)\n",
      "Test: [100/450]\tTime  0.317 ( 0.317)\tLoss 4.4523e-01 (5.7236e-01)\tAcc@1  93.75 ( 83.29)\tAcc@5  96.88 ( 97.77)\n",
      "Test: [105/450]\tTime  0.309 ( 0.317)\tLoss 6.0124e-01 (5.6729e-01)\tAcc@1  84.38 ( 83.43)\tAcc@5 100.00 ( 97.82)\n",
      "Test: [110/450]\tTime  0.296 ( 0.316)\tLoss 1.5617e-01 (5.7040e-01)\tAcc@1  96.88 ( 83.39)\tAcc@5 100.00 ( 97.83)\n",
      "Test: [115/450]\tTime  0.304 ( 0.316)\tLoss 9.4144e-01 (5.6651e-01)\tAcc@1  75.00 ( 83.59)\tAcc@5  93.75 ( 97.82)\n",
      "Test: [120/450]\tTime  0.308 ( 0.315)\tLoss 8.6102e-01 (5.7704e-01)\tAcc@1  78.12 ( 83.45)\tAcc@5  96.88 ( 97.78)\n",
      "Test: [125/450]\tTime  0.349 ( 0.315)\tLoss 1.0195e+00 (5.9485e-01)\tAcc@1  65.62 ( 83.11)\tAcc@5  96.88 ( 97.62)\n",
      "Test: [130/450]\tTime  0.293 ( 0.315)\tLoss 2.5577e-01 (6.0805e-01)\tAcc@1  93.75 ( 82.78)\tAcc@5 100.00 ( 97.50)\n",
      "Test: [135/450]\tTime  0.279 ( 0.316)\tLoss 4.4470e-01 (6.0300e-01)\tAcc@1  84.38 ( 82.81)\tAcc@5  96.88 ( 97.56)\n",
      "Test: [140/450]\tTime  0.298 ( 0.315)\tLoss 2.3320e-01 (5.9573e-01)\tAcc@1  93.75 ( 83.07)\tAcc@5 100.00 ( 97.56)\n",
      "Test: [145/450]\tTime  0.348 ( 0.315)\tLoss 3.5179e-01 (5.8940e-01)\tAcc@1  87.50 ( 83.11)\tAcc@5 100.00 ( 97.60)\n",
      "Test: [150/450]\tTime  0.280 ( 0.314)\tLoss 6.1871e-02 (5.7843e-01)\tAcc@1 100.00 ( 83.38)\tAcc@5 100.00 ( 97.68)\n",
      "Test: [155/450]\tTime  0.291 ( 0.313)\tLoss 2.2483e-01 (5.6954e-01)\tAcc@1  90.62 ( 83.61)\tAcc@5 100.00 ( 97.74)\n",
      "Test: [160/450]\tTime  0.307 ( 0.313)\tLoss 7.6866e-01 (5.6695e-01)\tAcc@1  78.12 ( 83.66)\tAcc@5  93.75 ( 97.73)\n",
      "Test: [165/450]\tTime  0.303 ( 0.314)\tLoss 5.9102e-01 (5.6550e-01)\tAcc@1  78.12 ( 83.68)\tAcc@5  96.88 ( 97.72)\n",
      "Test: [170/450]\tTime  0.332 ( 0.314)\tLoss 2.9714e-01 (5.5746e-01)\tAcc@1  96.88 ( 84.01)\tAcc@5 100.00 ( 97.79)\n",
      "Test: [175/450]\tTime  0.330 ( 0.315)\tLoss 2.0217e-01 (5.5654e-01)\tAcc@1  93.75 ( 84.06)\tAcc@5 100.00 ( 97.80)\n",
      "Test: [180/450]\tTime  0.297 ( 0.315)\tLoss 9.1124e-01 (5.6034e-01)\tAcc@1  68.75 ( 83.91)\tAcc@5  96.88 ( 97.82)\n",
      "Test: [185/450]\tTime  0.319 ( 0.316)\tLoss 4.8236e-01 (5.6056e-01)\tAcc@1  81.25 ( 83.87)\tAcc@5 100.00 ( 97.85)\n",
      "Test: [190/450]\tTime  0.303 ( 0.316)\tLoss 4.2310e-01 (5.6214e-01)\tAcc@1  84.38 ( 83.82)\tAcc@5  93.75 ( 97.79)\n",
      "Test: [195/450]\tTime  0.301 ( 0.316)\tLoss 2.3750e-01 (5.5803e-01)\tAcc@1  93.75 ( 83.88)\tAcc@5 100.00 ( 97.85)\n",
      "Test: [200/450]\tTime  0.286 ( 0.316)\tLoss 6.6358e-01 (5.6126e-01)\tAcc@1  78.12 ( 83.69)\tAcc@5  93.75 ( 97.81)\n",
      "Test: [205/450]\tTime  0.344 ( 0.316)\tLoss 9.8722e-01 (5.6306e-01)\tAcc@1  68.75 ( 83.60)\tAcc@5  93.75 ( 97.82)\n",
      "Test: [210/450]\tTime  0.316 ( 0.317)\tLoss 4.7248e-01 (5.5843e-01)\tAcc@1  84.38 ( 83.75)\tAcc@5 100.00 ( 97.84)\n",
      "Test: [215/450]\tTime  0.296 ( 0.317)\tLoss 9.6342e-01 (5.7043e-01)\tAcc@1  62.50 ( 83.39)\tAcc@5 100.00 ( 97.84)\n",
      "Test: [220/450]\tTime  0.288 ( 0.317)\tLoss 5.6992e-01 (5.8145e-01)\tAcc@1  84.38 ( 82.93)\tAcc@5 100.00 ( 97.86)\n",
      "Test: [225/450]\tTime  0.310 ( 0.317)\tLoss 2.4589e-01 (5.7467e-01)\tAcc@1  93.75 ( 83.13)\tAcc@5 100.00 ( 97.91)\n",
      "Test: [230/450]\tTime  0.322 ( 0.317)\tLoss 1.2404e-01 (5.6535e-01)\tAcc@1 100.00 ( 83.44)\tAcc@5 100.00 ( 97.94)\n",
      "Test: [235/450]\tTime  0.305 ( 0.316)\tLoss 6.0831e-01 (5.6386e-01)\tAcc@1  81.25 ( 83.50)\tAcc@5  96.88 ( 97.96)\n",
      "Test: [240/450]\tTime  0.295 ( 0.316)\tLoss 1.2503e-01 (5.5701e-01)\tAcc@1  93.75 ( 83.70)\tAcc@5 100.00 ( 98.00)\n",
      "Test: [245/450]\tTime  0.313 ( 0.316)\tLoss 5.2466e-01 (5.5102e-01)\tAcc@1  84.38 ( 83.84)\tAcc@5  96.88 ( 98.02)\n",
      "Test: [250/450]\tTime  0.293 ( 0.316)\tLoss 6.3035e-01 (5.4475e-01)\tAcc@1  90.62 ( 84.06)\tAcc@5  93.75 ( 98.03)\n",
      "Test: [255/450]\tTime  0.289 ( 0.316)\tLoss 7.9114e-01 (5.4593e-01)\tAcc@1  81.25 ( 83.98)\tAcc@5  90.62 ( 98.03)\n",
      "Test: [260/450]\tTime  0.309 ( 0.316)\tLoss 5.8392e-01 (5.5721e-01)\tAcc@1  78.12 ( 83.62)\tAcc@5  96.88 ( 98.00)\n",
      "Test: [265/450]\tTime  0.326 ( 0.315)\tLoss 4.2650e-01 (5.5460e-01)\tAcc@1  90.62 ( 83.76)\tAcc@5  96.88 ( 97.97)\n",
      "Test: [270/450]\tTime  0.346 ( 0.316)\tLoss 4.1588e-01 (5.5036e-01)\tAcc@1  87.50 ( 83.91)\tAcc@5 100.00 ( 97.98)\n",
      "Test: [275/450]\tTime  0.367 ( 0.316)\tLoss 7.2443e-01 (5.5081e-01)\tAcc@1  84.38 ( 83.92)\tAcc@5  87.50 ( 97.92)\n",
      "Test: [280/450]\tTime  0.379 ( 0.317)\tLoss 3.9070e-01 (5.4869e-01)\tAcc@1  93.75 ( 84.07)\tAcc@5  96.88 ( 97.90)\n",
      "Test: [285/450]\tTime  0.337 ( 0.318)\tLoss 6.2888e-01 (5.4419e-01)\tAcc@1  78.12 ( 84.24)\tAcc@5 100.00 ( 97.92)\n",
      "Test: [290/450]\tTime  0.375 ( 0.318)\tLoss 5.2406e-01 (5.4910e-01)\tAcc@1  87.50 ( 84.09)\tAcc@5 100.00 ( 97.92)\n",
      "Test: [295/450]\tTime  0.389 ( 0.319)\tLoss 5.4996e-01 (5.5508e-01)\tAcc@1  87.50 ( 83.83)\tAcc@5 100.00 ( 97.91)\n",
      "Test: [300/450]\tTime  0.341 ( 0.319)\tLoss 1.6585e+00 (5.5967e-01)\tAcc@1  53.12 ( 83.68)\tAcc@5  90.62 ( 97.89)\n",
      "Test: [305/450]\tTime  0.354 ( 0.320)\tLoss 5.5574e-01 (5.6490e-01)\tAcc@1  90.62 ( 83.64)\tAcc@5 100.00 ( 97.87)\n",
      "Test: [310/450]\tTime  0.348 ( 0.320)\tLoss 1.4074e+00 (5.6439e-01)\tAcc@1  62.50 ( 83.68)\tAcc@5  81.25 ( 97.83)\n",
      "Test: [315/450]\tTime  0.350 ( 0.321)\tLoss 3.5851e-01 (5.6179e-01)\tAcc@1  87.50 ( 83.79)\tAcc@5 100.00 ( 97.86)\n",
      "Test: [320/450]\tTime  0.334 ( 0.321)\tLoss 1.2212e+00 (5.6594e-01)\tAcc@1  62.50 ( 83.68)\tAcc@5  96.88 ( 97.85)\n",
      "Test: [325/450]\tTime  0.371 ( 0.321)\tLoss 1.0535e+00 (5.7279e-01)\tAcc@1  65.62 ( 83.42)\tAcc@5 100.00 ( 97.82)\n",
      "Test: [330/450]\tTime  0.299 ( 0.322)\tLoss 1.4032e+00 (5.7679e-01)\tAcc@1  53.12 ( 83.30)\tAcc@5  96.88 ( 97.85)\n",
      "Test: [335/450]\tTime  0.342 ( 0.322)\tLoss 2.0778e-01 (5.7318e-01)\tAcc@1 100.00 ( 83.43)\tAcc@5 100.00 ( 97.85)\n",
      "Test: [340/450]\tTime  0.326 ( 0.322)\tLoss 4.5422e-01 (5.7177e-01)\tAcc@1  87.50 ( 83.53)\tAcc@5 100.00 ( 97.87)\n",
      "Test: [345/450]\tTime  0.371 ( 0.323)\tLoss 2.7104e-01 (5.6819e-01)\tAcc@1  93.75 ( 83.66)\tAcc@5  96.88 ( 97.89)\n",
      "Test: [350/450]\tTime  0.362 ( 0.323)\tLoss 1.0317e-01 (5.6683e-01)\tAcc@1 100.00 ( 83.73)\tAcc@5 100.00 ( 97.86)\n",
      "Test: [355/450]\tTime  0.321 ( 0.323)\tLoss 6.3598e-01 (5.6688e-01)\tAcc@1  90.62 ( 83.80)\tAcc@5  90.62 ( 97.81)\n",
      "Test: [360/450]\tTime  0.336 ( 0.324)\tLoss 6.2299e-01 (5.6964e-01)\tAcc@1  81.25 ( 83.67)\tAcc@5  96.88 ( 97.79)\n",
      "Test: [365/450]\tTime  0.354 ( 0.324)\tLoss 2.3094e-01 (5.6999e-01)\tAcc@1  96.88 ( 83.68)\tAcc@5  96.88 ( 97.78)\n",
      "Test: [370/450]\tTime  0.345 ( 0.324)\tLoss 1.0865e+00 (5.7253e-01)\tAcc@1  65.62 ( 83.61)\tAcc@5  93.75 ( 97.76)\n",
      "Test: [375/450]\tTime  0.351 ( 0.324)\tLoss 1.2734e+00 (5.7850e-01)\tAcc@1  65.62 ( 83.47)\tAcc@5  84.38 ( 97.68)\n",
      "Test: [380/450]\tTime  0.337 ( 0.325)\tLoss 1.0400e+00 (5.8045e-01)\tAcc@1  78.12 ( 83.46)\tAcc@5  96.88 ( 97.70)\n",
      "Test: [385/450]\tTime  0.355 ( 0.325)\tLoss 4.4550e-01 (5.8384e-01)\tAcc@1  96.88 ( 83.41)\tAcc@5  96.88 ( 97.64)\n",
      "Test: [390/450]\tTime  0.341 ( 0.325)\tLoss 7.6002e-01 (5.8310e-01)\tAcc@1  78.12 ( 83.46)\tAcc@5 100.00 ( 97.63)\n",
      "Test: [395/450]\tTime  0.327 ( 0.325)\tLoss 1.3958e+00 (5.8537e-01)\tAcc@1  65.62 ( 83.43)\tAcc@5  90.62 ( 97.62)\n",
      "Test: [400/450]\tTime  0.330 ( 0.325)\tLoss 4.0256e-01 (5.9096e-01)\tAcc@1  90.62 ( 83.22)\tAcc@5  96.88 ( 97.62)\n",
      "Test: [405/450]\tTime  0.347 ( 0.326)\tLoss 5.9386e-01 (5.8869e-01)\tAcc@1  90.62 ( 83.37)\tAcc@5 100.00 ( 97.64)\n",
      "Test: [410/450]\tTime  0.323 ( 0.326)\tLoss 2.7099e-01 (5.8931e-01)\tAcc@1  96.88 ( 83.36)\tAcc@5 100.00 ( 97.64)\n",
      "Test: [415/450]\tTime  0.308 ( 0.326)\tLoss 3.2717e-01 (5.8714e-01)\tAcc@1  90.62 ( 83.46)\tAcc@5 100.00 ( 97.66)\n",
      "Test: [420/450]\tTime  0.365 ( 0.326)\tLoss 3.9638e-01 (5.8693e-01)\tAcc@1  90.62 ( 83.48)\tAcc@5  96.88 ( 97.62)\n",
      "Test: [425/450]\tTime  0.339 ( 0.326)\tLoss 1.0209e+00 (5.8970e-01)\tAcc@1  81.25 ( 83.50)\tAcc@5  90.62 ( 97.60)\n",
      "Test: [430/450]\tTime  0.356 ( 0.327)\tLoss 6.0456e-01 (5.9066e-01)\tAcc@1  84.38 ( 83.51)\tAcc@5  90.62 ( 97.58)\n",
      "Test: [435/450]\tTime  0.369 ( 0.327)\tLoss 2.1149e-01 (5.8816e-01)\tAcc@1  96.88 ( 83.62)\tAcc@5 100.00 ( 97.58)\n",
      "Test: [440/450]\tTime  0.355 ( 0.327)\tLoss 1.3213e-01 (5.8452e-01)\tAcc@1  96.88 ( 83.77)\tAcc@5 100.00 ( 97.60)\n",
      "Test: [445/450]\tTime  0.380 ( 0.327)\tLoss 9.6705e-01 (5.8557e-01)\tAcc@1  78.12 ( 83.79)\tAcc@5  93.75 ( 97.60)\n",
      " * Acc@1 83.832 Acc@5 97.600\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "model = myresnetv2_task2(num_classes=320)\n",
    "\n",
    "model = model.to(device)\n",
    "\n",
    "path = \"/home/hashmat.malik/Fall 2021/CV703 Lab/Week5/datasets/modelresnetv2448_gbloss_for_nb_best.pth.tar\"\n",
    "checkpoint = torch.load(path)\n",
    "model.load_state_dict(checkpoint['state_dict'])\n",
    "\n",
    "\n",
    "\n",
    "optimizer = model.parameters([\n",
    "                {'params': 0.99, 'lr': 0.0001, 'betas': (0.5, 0.999)},\n",
    "                {'params': 0.99, 'lr': 0.00001, 'betas': (0.5, 0.999)}])\n",
    "\n",
    "criterion = GBLoss()\n",
    "train_model(30, train_loader, val_loader, test_loader, optimizer, criterion, model, f'resnetv2_gbloss_{1}', is_train=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8ebd1e1",
   "metadata": {},
   "source": [
    "**Best Top1 val accuracy of resnetv2-448 increased with gradient-boosting loss from  82.28% 84.17% to and best top1 test accuracy increased with gradient-boosting loss from 82.81% to 83.83%!!!** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1f6b12f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#cait_xxs24_384\n",
    "# batch size = 24 used during training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d2cacf3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_transform=transforms.Compose([\n",
    "                    transforms.Resize((384, 384)),\n",
    "                    transforms.ToTensor(),\n",
    "                    transforms.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225))\n",
    "                ])\n",
    "\n",
    "data_transform = transforms.Compose([  #\n",
    "\n",
    "       transforms.Resize((384, 384)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=mean, std=std)\n",
    "    ])\n",
    "\n",
    "# Load Data\n",
    "train_loader, val_loader,test_loader = cub_and_dogs(bs=batch_size, data_transform=data_transform, test_transform=test_transform)\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "model = timm.create_model(\"cait_xxs24_384\", pretrained=True)\n",
    "model.head = torch.nn.Linear(in_features=model.head.in_features, out_features=320)  # dogs dataset has 120 classes\n",
    "model.head.apply(model._init_weights)\n",
    "model.to(device)\n",
    "path = \"/home/hashmat.malik/Fall 2021/CV703 Lab/Week5/datasets/modelcait_xxs24_384_task2exp7withGBloss_for_nb_best.pth.tar\"\n",
    "checkpoint = torch.load(path)\n",
    "model.load_state_dict(checkpoint['state_dict'])\n",
    "criterion = GBLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001, betas=(0.5, 0.999))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7b51f48f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test: [ 0/57]\tTime  0.786 ( 0.786)\tLoss 3.3675e-01 (3.3675e-01)\tAcc@1  90.62 ( 90.62)\tAcc@5 100.00 (100.00)\n",
      "Test: [ 5/57]\tTime  0.344 ( 0.427)\tLoss 8.1966e-01 (5.6247e-01)\tAcc@1  68.75 ( 84.38)\tAcc@5  96.88 ( 96.88)\n",
      "Test: [10/57]\tTime  0.343 ( 0.391)\tLoss 4.3987e-01 (6.0817e-01)\tAcc@1  87.50 ( 82.95)\tAcc@5 100.00 ( 97.16)\n",
      "Test: [15/57]\tTime  0.352 ( 0.384)\tLoss 3.8316e-01 (5.8015e-01)\tAcc@1  87.50 ( 84.18)\tAcc@5 100.00 ( 97.85)\n",
      "Test: [20/57]\tTime  0.347 ( 0.377)\tLoss 5.6676e-01 (5.7327e-01)\tAcc@1  81.25 ( 83.78)\tAcc@5  93.75 ( 97.77)\n",
      "Test: [25/57]\tTime  0.382 ( 0.374)\tLoss 7.0334e-01 (5.7251e-01)\tAcc@1  75.00 ( 83.41)\tAcc@5  93.75 ( 97.48)\n",
      "Test: [30/57]\tTime  0.378 ( 0.372)\tLoss 6.1085e-01 (5.6795e-01)\tAcc@1  81.25 ( 83.67)\tAcc@5  93.75 ( 97.28)\n",
      "Test: [35/57]\tTime  0.367 ( 0.370)\tLoss 4.9316e-01 (5.6904e-01)\tAcc@1  84.38 ( 83.25)\tAcc@5 100.00 ( 97.57)\n",
      "Test: [40/57]\tTime  0.386 ( 0.372)\tLoss 2.9173e-01 (5.4908e-01)\tAcc@1  96.88 ( 84.07)\tAcc@5 100.00 ( 97.64)\n",
      "Test: [45/57]\tTime  0.385 ( 0.373)\tLoss 3.0713e-01 (5.5303e-01)\tAcc@1  93.75 ( 84.17)\tAcc@5 100.00 ( 97.83)\n",
      "Test: [50/57]\tTime  0.387 ( 0.375)\tLoss 6.6122e-01 (5.5929e-01)\tAcc@1  87.50 ( 84.01)\tAcc@5  96.88 ( 97.86)\n",
      "Test: [55/57]\tTime  0.385 ( 0.376)\tLoss 6.7347e-01 (5.6287e-01)\tAcc@1  78.12 ( 83.87)\tAcc@5  96.88 ( 97.82)\n",
      " * Acc@1 83.833 Acc@5 97.833\n",
      "Test: [  0/450]\tTime  0.829 ( 0.829)\tLoss 4.1165e-01 (4.1165e-01)\tAcc@1  90.62 ( 90.62)\tAcc@5  96.88 ( 96.88)\n",
      "Test: [  5/450]\tTime  0.388 ( 0.462)\tLoss 2.4142e-01 (3.7378e-01)\tAcc@1  96.88 ( 90.62)\tAcc@5 100.00 ( 98.96)\n",
      "Test: [ 10/450]\tTime  0.385 ( 0.428)\tLoss 5.3308e-01 (3.9942e-01)\tAcc@1  90.62 ( 90.06)\tAcc@5 100.00 ( 98.86)\n",
      "Test: [ 15/450]\tTime  0.389 ( 0.415)\tLoss 1.2388e-01 (4.2575e-01)\tAcc@1  93.75 ( 88.48)\tAcc@5 100.00 ( 98.24)\n",
      "Test: [ 20/450]\tTime  0.356 ( 0.406)\tLoss 3.2441e-01 (3.7361e-01)\tAcc@1  90.62 ( 89.73)\tAcc@5 100.00 ( 98.66)\n",
      "Test: [ 25/450]\tTime  0.349 ( 0.397)\tLoss 5.1754e-02 (3.9039e-01)\tAcc@1  96.88 ( 89.06)\tAcc@5 100.00 ( 98.68)\n",
      "Test: [ 30/450]\tTime  0.391 ( 0.394)\tLoss 2.8486e-01 (3.6423e-01)\tAcc@1  93.75 ( 89.92)\tAcc@5  96.88 ( 98.49)\n",
      "Test: [ 35/450]\tTime  0.390 ( 0.394)\tLoss 7.2183e-01 (3.8943e-01)\tAcc@1  81.25 ( 89.06)\tAcc@5  93.75 ( 98.52)\n",
      "Test: [ 40/450]\tTime  0.379 ( 0.393)\tLoss 5.5126e-01 (3.8768e-01)\tAcc@1  87.50 ( 89.10)\tAcc@5 100.00 ( 98.48)\n",
      "Test: [ 45/450]\tTime  0.370 ( 0.390)\tLoss 1.5838e-01 (4.0484e-01)\tAcc@1  96.88 ( 87.98)\tAcc@5 100.00 ( 98.57)\n",
      "Test: [ 50/450]\tTime  0.351 ( 0.388)\tLoss 7.3608e-01 (4.1181e-01)\tAcc@1  71.88 ( 87.62)\tAcc@5  96.88 ( 98.53)\n",
      "Test: [ 55/450]\tTime  0.381 ( 0.386)\tLoss 5.9348e-01 (4.1851e-01)\tAcc@1  78.12 ( 87.61)\tAcc@5 100.00 ( 98.49)\n",
      "Test: [ 60/450]\tTime  0.361 ( 0.385)\tLoss 1.2511e-01 (3.9420e-01)\tAcc@1  96.88 ( 88.47)\tAcc@5 100.00 ( 98.57)\n",
      "Test: [ 65/450]\tTime  0.351 ( 0.382)\tLoss 2.0510e-01 (3.7946e-01)\tAcc@1  93.75 ( 88.97)\tAcc@5 100.00 ( 98.67)\n",
      "Test: [ 70/450]\tTime  0.351 ( 0.381)\tLoss 3.7607e-01 (3.7832e-01)\tAcc@1  87.50 ( 88.91)\tAcc@5 100.00 ( 98.72)\n",
      "Test: [ 75/450]\tTime  0.393 ( 0.381)\tLoss 7.8505e-01 (3.9169e-01)\tAcc@1  62.50 ( 87.99)\tAcc@5 100.00 ( 98.73)\n",
      "Test: [ 80/450]\tTime  0.378 ( 0.381)\tLoss 4.4816e-01 (3.8073e-01)\tAcc@1  93.75 ( 88.50)\tAcc@5  96.88 ( 98.77)\n",
      "Test: [ 85/450]\tTime  0.393 ( 0.382)\tLoss 4.5754e-01 (3.7892e-01)\tAcc@1  87.50 ( 88.63)\tAcc@5 100.00 ( 98.76)\n",
      "Test: [ 90/450]\tTime  0.393 ( 0.382)\tLoss 4.9197e-01 (3.8772e-01)\tAcc@1  90.62 ( 88.56)\tAcc@5  96.88 ( 98.70)\n",
      "Test: [ 95/450]\tTime  0.393 ( 0.383)\tLoss 5.6189e-01 (3.9952e-01)\tAcc@1  81.25 ( 88.25)\tAcc@5 100.00 ( 98.70)\n",
      "Test: [100/450]\tTime  0.395 ( 0.383)\tLoss 2.6478e-01 (3.9561e-01)\tAcc@1  93.75 ( 88.37)\tAcc@5 100.00 ( 98.76)\n",
      "Test: [105/450]\tTime  0.395 ( 0.384)\tLoss 4.8343e-01 (4.0129e-01)\tAcc@1  84.38 ( 88.24)\tAcc@5  96.88 ( 98.73)\n",
      "Test: [110/450]\tTime  0.394 ( 0.384)\tLoss 1.8024e-01 (4.0423e-01)\tAcc@1  93.75 ( 88.20)\tAcc@5  96.88 ( 98.73)\n",
      "Test: [115/450]\tTime  0.391 ( 0.385)\tLoss 5.9798e-01 (4.0026e-01)\tAcc@1  81.25 ( 88.36)\tAcc@5 100.00 ( 98.76)\n",
      "Test: [120/450]\tTime  0.352 ( 0.384)\tLoss 8.8972e-01 (4.1190e-01)\tAcc@1  84.38 ( 88.09)\tAcc@5 100.00 ( 98.79)\n",
      "Test: [125/450]\tTime  0.353 ( 0.384)\tLoss 5.5163e-01 (4.2318e-01)\tAcc@1  78.12 ( 87.80)\tAcc@5 100.00 ( 98.74)\n",
      "Test: [130/450]\tTime  0.390 ( 0.383)\tLoss 1.7120e-01 (4.2786e-01)\tAcc@1  96.88 ( 87.55)\tAcc@5 100.00 ( 98.71)\n",
      "Test: [135/450]\tTime  0.395 ( 0.383)\tLoss 3.7831e-01 (4.3215e-01)\tAcc@1  90.62 ( 87.27)\tAcc@5 100.00 ( 98.76)\n",
      "Test: [140/450]\tTime  0.389 ( 0.384)\tLoss 3.0191e-01 (4.2944e-01)\tAcc@1  90.62 ( 87.43)\tAcc@5 100.00 ( 98.69)\n",
      "Test: [145/450]\tTime  0.388 ( 0.383)\tLoss 3.7452e-01 (4.2486e-01)\tAcc@1  87.50 ( 87.56)\tAcc@5 100.00 ( 98.69)\n",
      "Test: [150/450]\tTime  0.395 ( 0.383)\tLoss 5.7075e-02 (4.1893e-01)\tAcc@1 100.00 ( 87.73)\tAcc@5 100.00 ( 98.74)\n",
      "Test: [155/450]\tTime  0.391 ( 0.383)\tLoss 3.1559e-01 (4.1628e-01)\tAcc@1  84.38 ( 87.82)\tAcc@5 100.00 ( 98.72)\n",
      "Test: [160/450]\tTime  0.371 ( 0.383)\tLoss 6.4536e-01 (4.1533e-01)\tAcc@1  81.25 ( 87.87)\tAcc@5  96.88 ( 98.74)\n",
      "Test: [165/450]\tTime  0.395 ( 0.384)\tLoss 4.3131e-01 (4.1141e-01)\tAcc@1  84.38 ( 88.03)\tAcc@5 100.00 ( 98.76)\n",
      "Test: [170/450]\tTime  0.370 ( 0.384)\tLoss 1.6631e-01 (4.0451e-01)\tAcc@1  96.88 ( 88.27)\tAcc@5 100.00 ( 98.78)\n",
      "Test: [175/450]\tTime  0.355 ( 0.383)\tLoss 3.5456e-02 (4.0252e-01)\tAcc@1 100.00 ( 88.32)\tAcc@5 100.00 ( 98.81)\n",
      "Test: [180/450]\tTime  0.360 ( 0.383)\tLoss 8.5164e-01 (4.0708e-01)\tAcc@1  56.25 ( 88.00)\tAcc@5  96.88 ( 98.79)\n",
      "Test: [185/450]\tTime  0.377 ( 0.383)\tLoss 3.8836e-01 (4.0789e-01)\tAcc@1  87.50 ( 87.92)\tAcc@5 100.00 ( 98.81)\n",
      "Test: [190/450]\tTime  0.377 ( 0.383)\tLoss 4.2393e-01 (4.0802e-01)\tAcc@1  87.50 ( 87.94)\tAcc@5  96.88 ( 98.81)\n",
      "Test: [195/450]\tTime  0.396 ( 0.384)\tLoss 1.9085e-01 (4.0756e-01)\tAcc@1  93.75 ( 87.96)\tAcc@5 100.00 ( 98.84)\n",
      "Test: [200/450]\tTime  0.396 ( 0.384)\tLoss 5.0944e-01 (4.0938e-01)\tAcc@1  81.25 ( 87.87)\tAcc@5  96.88 ( 98.83)\n",
      "Test: [205/450]\tTime  0.358 ( 0.384)\tLoss 6.9509e-01 (4.1067e-01)\tAcc@1  71.88 ( 87.77)\tAcc@5 100.00 ( 98.83)\n",
      "Test: [210/450]\tTime  0.379 ( 0.384)\tLoss 6.9823e-01 (4.0931e-01)\tAcc@1  78.12 ( 87.86)\tAcc@5 100.00 ( 98.84)\n",
      "Test: [215/450]\tTime  0.354 ( 0.383)\tLoss 6.3150e-01 (4.1472e-01)\tAcc@1  75.00 ( 87.63)\tAcc@5 100.00 ( 98.84)\n",
      "Test: [220/450]\tTime  0.393 ( 0.383)\tLoss 2.0592e-01 (4.2254e-01)\tAcc@1  93.75 ( 87.02)\tAcc@5 100.00 ( 98.85)\n",
      "Test: [225/450]\tTime  0.356 ( 0.383)\tLoss 8.0260e-02 (4.1705e-01)\tAcc@1  96.88 ( 87.20)\tAcc@5 100.00 ( 98.85)\n",
      "Test: [230/450]\tTime  0.372 ( 0.383)\tLoss 7.0772e-02 (4.1059e-01)\tAcc@1 100.00 ( 87.42)\tAcc@5 100.00 ( 98.88)\n",
      "Test: [235/450]\tTime  0.356 ( 0.383)\tLoss 5.3265e-01 (4.1268e-01)\tAcc@1  81.25 ( 87.41)\tAcc@5 100.00 ( 98.90)\n",
      "Test: [240/450]\tTime  0.363 ( 0.383)\tLoss 5.7527e-02 (4.0870e-01)\tAcc@1 100.00 ( 87.53)\tAcc@5 100.00 ( 98.91)\n",
      "Test: [245/450]\tTime  0.371 ( 0.383)\tLoss 5.1280e-02 (4.0486e-01)\tAcc@1 100.00 ( 87.67)\tAcc@5 100.00 ( 98.92)\n",
      "Test: [250/450]\tTime  0.354 ( 0.382)\tLoss 3.6306e-01 (3.9939e-01)\tAcc@1  93.75 ( 87.85)\tAcc@5 100.00 ( 98.94)\n",
      "Test: [255/450]\tTime  0.387 ( 0.382)\tLoss 2.8758e-01 (3.9907e-01)\tAcc@1  96.88 ( 87.87)\tAcc@5 100.00 ( 98.95)\n",
      "Test: [260/450]\tTime  0.356 ( 0.382)\tLoss 3.6075e-01 (4.0580e-01)\tAcc@1  87.50 ( 87.56)\tAcc@5 100.00 ( 98.95)\n",
      "Test: [265/450]\tTime  0.385 ( 0.382)\tLoss 1.8354e-01 (4.0448e-01)\tAcc@1  96.88 ( 87.66)\tAcc@5 100.00 ( 98.95)\n",
      "Test: [270/450]\tTime  0.354 ( 0.382)\tLoss 7.3122e-01 (4.0633e-01)\tAcc@1  87.50 ( 87.73)\tAcc@5  96.88 ( 98.92)\n",
      "Test: [275/450]\tTime  0.398 ( 0.382)\tLoss 9.8621e-01 (4.1241e-01)\tAcc@1  84.38 ( 87.66)\tAcc@5  90.62 ( 98.88)\n",
      "Test: [280/450]\tTime  0.395 ( 0.382)\tLoss 6.4391e-01 (4.1832e-01)\tAcc@1  84.38 ( 87.62)\tAcc@5  93.75 ( 98.78)\n",
      "Test: [285/450]\tTime  0.398 ( 0.382)\tLoss 9.3598e-01 (4.2218e-01)\tAcc@1  65.62 ( 87.60)\tAcc@5 100.00 ( 98.77)\n",
      "Test: [290/450]\tTime  0.398 ( 0.382)\tLoss 1.0625e+00 (4.3377e-01)\tAcc@1  75.00 ( 87.25)\tAcc@5  96.88 ( 98.66)\n",
      "Test: [295/450]\tTime  0.398 ( 0.383)\tLoss 9.4365e-01 (4.4456e-01)\tAcc@1  84.38 ( 86.98)\tAcc@5  93.75 ( 98.59)\n",
      "Test: [300/450]\tTime  0.398 ( 0.383)\tLoss 1.6174e+00 (4.5221e-01)\tAcc@1  53.12 ( 86.83)\tAcc@5  90.62 ( 98.56)\n",
      "Test: [305/450]\tTime  0.398 ( 0.383)\tLoss 8.3076e-01 (4.6552e-01)\tAcc@1  87.50 ( 86.52)\tAcc@5 100.00 ( 98.45)\n",
      "Test: [310/450]\tTime  0.399 ( 0.383)\tLoss 1.5719e+00 (4.7004e-01)\tAcc@1  43.75 ( 86.43)\tAcc@5  90.62 ( 98.42)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test: [315/450]\tTime  0.399 ( 0.384)\tLoss 4.4801e-01 (4.7014e-01)\tAcc@1  90.62 ( 86.50)\tAcc@5  96.88 ( 98.44)\n",
      "Test: [320/450]\tTime  0.399 ( 0.384)\tLoss 1.3555e+00 (4.7764e-01)\tAcc@1  53.12 ( 86.23)\tAcc@5  96.88 ( 98.41)\n",
      "Test: [325/450]\tTime  0.403 ( 0.384)\tLoss 1.1880e+00 (4.8745e-01)\tAcc@1  75.00 ( 85.97)\tAcc@5  96.88 ( 98.32)\n",
      "Test: [330/450]\tTime  0.399 ( 0.384)\tLoss 1.9772e+00 (4.9537e-01)\tAcc@1  50.00 ( 85.72)\tAcc@5  75.00 ( 98.27)\n",
      "Test: [335/450]\tTime  0.398 ( 0.385)\tLoss 4.4967e-01 (4.9560e-01)\tAcc@1  90.62 ( 85.75)\tAcc@5 100.00 ( 98.25)\n",
      "Test: [340/450]\tTime  0.399 ( 0.385)\tLoss 1.1825e+00 (5.0087e-01)\tAcc@1  56.25 ( 85.67)\tAcc@5  90.62 ( 98.20)\n",
      "Test: [345/450]\tTime  0.399 ( 0.385)\tLoss 5.5134e-01 (5.0258e-01)\tAcc@1  90.62 ( 85.68)\tAcc@5  93.75 ( 98.18)\n",
      "Test: [350/450]\tTime  0.399 ( 0.385)\tLoss 4.8815e-01 (5.0632e-01)\tAcc@1  93.75 ( 85.74)\tAcc@5 100.00 ( 98.13)\n",
      "Test: [355/450]\tTime  0.399 ( 0.385)\tLoss 1.1177e+00 (5.1289e-01)\tAcc@1  84.38 ( 85.69)\tAcc@5  87.50 ( 98.03)\n",
      "Test: [360/450]\tTime  0.399 ( 0.386)\tLoss 1.4904e+00 (5.1911e-01)\tAcc@1  68.75 ( 85.58)\tAcc@5  90.62 ( 98.00)\n",
      "Test: [365/450]\tTime  0.398 ( 0.386)\tLoss 4.9207e-01 (5.2403e-01)\tAcc@1  93.75 ( 85.48)\tAcc@5  96.88 ( 97.93)\n",
      "Test: [370/450]\tTime  0.399 ( 0.386)\tLoss 1.6210e+00 (5.3219e-01)\tAcc@1  59.38 ( 85.24)\tAcc@5  93.75 ( 97.93)\n",
      "Test: [375/450]\tTime  0.399 ( 0.386)\tLoss 1.3713e+00 (5.4642e-01)\tAcc@1  68.75 ( 84.87)\tAcc@5  93.75 ( 97.78)\n",
      "Test: [380/450]\tTime  0.398 ( 0.386)\tLoss 1.3604e+00 (5.5394e-01)\tAcc@1  68.75 ( 84.74)\tAcc@5  87.50 ( 97.75)\n",
      "Test: [385/450]\tTime  0.398 ( 0.386)\tLoss 1.1113e+00 (5.6323e-01)\tAcc@1  78.12 ( 84.58)\tAcc@5  93.75 ( 97.68)\n",
      "Test: [390/450]\tTime  0.399 ( 0.387)\tLoss 1.0447e+00 (5.6757e-01)\tAcc@1  78.12 ( 84.53)\tAcc@5 100.00 ( 97.64)\n",
      "Test: [395/450]\tTime  0.397 ( 0.387)\tLoss 1.7585e+00 (5.7246e-01)\tAcc@1  53.12 ( 84.49)\tAcc@5  75.00 ( 97.55)\n",
      "Test: [400/450]\tTime  0.355 ( 0.386)\tLoss 4.7682e-01 (5.7894e-01)\tAcc@1  93.75 ( 84.28)\tAcc@5  96.88 ( 97.55)\n",
      "Test: [405/450]\tTime  0.360 ( 0.386)\tLoss 9.8827e-01 (5.8201e-01)\tAcc@1  81.25 ( 84.28)\tAcc@5  93.75 ( 97.50)\n",
      "Test: [410/450]\tTime  0.400 ( 0.386)\tLoss 4.4460e-01 (5.8746e-01)\tAcc@1 100.00 ( 84.20)\tAcc@5 100.00 ( 97.46)\n",
      "Test: [415/450]\tTime  0.397 ( 0.386)\tLoss 6.6641e-01 (5.9018e-01)\tAcc@1  90.62 ( 84.19)\tAcc@5  96.88 ( 97.47)\n",
      "Test: [420/450]\tTime  0.398 ( 0.386)\tLoss 6.4819e-01 (5.9279e-01)\tAcc@1  93.75 ( 84.23)\tAcc@5  96.88 ( 97.42)\n",
      "Test: [425/450]\tTime  0.395 ( 0.387)\tLoss 1.6696e+00 (6.0151e-01)\tAcc@1  62.50 ( 84.02)\tAcc@5  84.38 ( 97.34)\n",
      "Test: [430/450]\tTime  0.409 ( 0.387)\tLoss 8.0881e-01 (6.0554e-01)\tAcc@1  81.25 ( 84.00)\tAcc@5  96.88 ( 97.31)\n",
      "Test: [435/450]\tTime  0.360 ( 0.386)\tLoss 5.5723e-01 (6.0716e-01)\tAcc@1  84.38 ( 84.00)\tAcc@5 100.00 ( 97.32)\n",
      "Test: [440/450]\tTime  0.357 ( 0.386)\tLoss 2.7257e-01 (6.0539e-01)\tAcc@1  96.88 ( 84.11)\tAcc@5  96.88 ( 97.34)\n",
      "Test: [445/450]\tTime  0.398 ( 0.386)\tLoss 1.2850e+00 (6.0975e-01)\tAcc@1  68.75 ( 84.04)\tAcc@5  93.75 ( 97.30)\n",
      " * Acc@1 84.068 Acc@5 97.294\n"
     ]
    }
   ],
   "source": [
    "train_model(epochs, train_loader, val_loader, test_loader, optimizer, criterion, model, 'cait', is_train=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0baf32f9",
   "metadata": {},
   "source": [
    "**Best Top1 val accuracy of cait_xxs24_384 increased with gradient-boosting loss from  82.67%  to 83.83% and best top1 test accuracy increased with gradient-boosting loss from 82.59% to 84.07%!!!** "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d509ca9a",
   "metadata": {},
   "source": [
    "**So  gradient-boosting loss improved the accuracy of both baseline models.Number of negative classes(k) to take into consideration is a hyperparameter for this Loss. We experimented with different values and found k=25 works best on this dataset.**\n",
    "\n",
    "Now we will try to work on a hybrid model of resnetv2 and cait_xxs_24_384. We will pass image size of 384x384 to the hybrid model. Before using the hybrid model , let's check the individual accuracy on resnetv2-384 and cait_xxs_24_384."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa41ec80",
   "metadata": {},
   "source": [
    "## Resnetv2-384"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6e1b2e56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test: [0/8]\tTime  2.172 ( 2.172)\tLoss 6.3603e-01 (6.3603e-01)\tAcc@1  83.20 ( 83.20)\tAcc@5  98.44 ( 98.44)\n",
      "Test: [5/8]\tTime  1.260 ( 1.371)\tLoss 6.1622e-01 (6.5223e-01)\tAcc@1  83.59 ( 82.23)\tAcc@5  97.66 ( 97.59)\n",
      " * Acc@1 82.167 Acc@5 97.444\n",
      "Test: [ 0/57]\tTime  1.799 ( 1.799)\tLoss 6.5389e-01 (6.5389e-01)\tAcc@1  83.98 ( 83.98)\tAcc@5  95.70 ( 95.70)\n",
      "Test: [ 5/57]\tTime  1.222 ( 1.325)\tLoss 8.7307e-01 (6.8449e-01)\tAcc@1  73.83 ( 81.18)\tAcc@5  98.05 ( 97.07)\n",
      "Test: [10/57]\tTime  1.207 ( 1.285)\tLoss 7.5338e-01 (6.8190e-01)\tAcc@1  83.98 ( 82.03)\tAcc@5  96.48 ( 97.12)\n",
      "Test: [15/57]\tTime  1.234 ( 1.261)\tLoss 1.1194e+00 (7.3886e-01)\tAcc@1  73.05 ( 80.64)\tAcc@5  95.31 ( 97.00)\n",
      "Test: [20/57]\tTime  1.331 ( 1.259)\tLoss 5.6061e-01 (6.7746e-01)\tAcc@1  85.55 ( 81.85)\tAcc@5  98.05 ( 97.36)\n",
      "Test: [25/57]\tTime  1.273 ( 1.262)\tLoss 7.1457e-01 (6.7772e-01)\tAcc@1  80.86 ( 81.64)\tAcc@5  95.70 ( 97.31)\n",
      "Test: [30/57]\tTime  1.235 ( 1.260)\tLoss 1.8646e-01 (6.5292e-01)\tAcc@1  94.14 ( 81.99)\tAcc@5  99.61 ( 97.54)\n",
      "Test: [35/57]\tTime  1.472 ( 1.270)\tLoss 6.7254e-01 (6.5311e-01)\tAcc@1  81.64 ( 82.04)\tAcc@5  95.70 ( 97.45)\n",
      "Test: [40/57]\tTime  1.429 ( 1.291)\tLoss 1.0054e+00 (6.7730e-01)\tAcc@1  67.58 ( 81.18)\tAcc@5  96.48 ( 97.21)\n",
      "Test: [45/57]\tTime  1.464 ( 1.309)\tLoss 7.3381e-01 (6.6653e-01)\tAcc@1  78.91 ( 81.56)\tAcc@5  94.92 ( 97.06)\n",
      "Test: [50/57]\tTime  1.465 ( 1.322)\tLoss 5.4022e-01 (6.8718e-01)\tAcc@1  85.55 ( 81.03)\tAcc@5  98.05 ( 96.84)\n",
      "Test: [55/57]\tTime  1.510 ( 1.335)\tLoss 6.3488e-01 (6.7656e-01)\tAcc@1  83.98 ( 81.58)\tAcc@5  96.09 ( 96.85)\n",
      " * Acc@1 81.613 Acc@5 96.862\n"
     ]
    }
   ],
   "source": [
    "epochs = 50\n",
    "batch_size = 256\n",
    "test_transform=transforms.Compose([\n",
    "                    transforms.Resize((384, 384)),\n",
    "                    transforms.ToTensor(),\n",
    "                    transforms.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225))\n",
    "                ])\n",
    "transform = transforms.Compose([ \n",
    "        transforms.Resize((384, 384)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=mean, std=std)\n",
    "    ])\n",
    "# Load Data\n",
    "train_loader, val_loader,test_loader = cub_and_dogs(bs=batch_size, data_transform = transform, test_transform=test_transform)\n",
    "# This one uses a Multi GPU (nn.DataParallel) for training, thus for testing too\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "model = myresnetv2_task2(num_classes=320)\n",
    "\n",
    "\n",
    "model = torch.nn.DataParallel(model)\n",
    "model = model.to(device)\n",
    "\n",
    "path = \"/home/ikboljonsobirov/cv/ass1/Week5/datasets/model_resnetv2_cubs_and_dogs_noaug_best.pth.tar\"\n",
    "checkpoint = torch.load(path, map_location='cpu')\n",
    "\n",
    "model.load_state_dict(checkpoint['state_dict'])\n",
    "\n",
    "optimizer = model.parameters([\n",
    "                {'params': 0.99, 'lr': 0.0001, 'betas': (0.5, 0.999)},\n",
    "                {'params': 0.99, 'lr': 0.00001, 'betas': (0.5, 0.999)}])\n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "train_model(30, train_loader, val_loader, test_loader, optimizer, criterion, model, f'resnetv2_fusion_{1}', is_train=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5b3111e",
   "metadata": {},
   "source": [
    "Reached top1 validation accuracy of 82.167% and top1 test accuracy of 81.613%"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66d09ec1",
   "metadata": {},
   "source": [
    "## Cait_xxs_24_384"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1d158137",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_transform=transforms.Compose([\n",
    "                    transforms.Resize((384, 384)),\n",
    "                    transforms.ToTensor(),\n",
    "                    transforms.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225))\n",
    "                ])\n",
    "\n",
    "data_transform = transforms.Compose([  #\n",
    "\n",
    "       transforms.Resize((384, 384)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=mean, std=std)\n",
    "    ])\n",
    "\n",
    "# Load Data\n",
    "train_loader, val_loader,test_loader = cub_and_dogs(bs=batch_size, data_transform=data_transform, test_transform=test_transform)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else 'cpu')\n",
    "model = timm.create_model(\"cait_xxs24_384\", pretrained=True)\n",
    "model.head = torch.nn.Linear(in_features=model.head.in_features, out_features=320)  # dogs dataset has 120 classes\n",
    "\n",
    "model = torch.nn.DataParallel(model)\n",
    "model = model.to(device)\n",
    "\n",
    "\n",
    "path = \"/home/hashmat.malik/Fall 2021/CV703 Lab/Week5/datasets/Submission/Task2/Exp7/model_cait_cubs_and_dogs_noaug_best.pth.tar\"\n",
    "checkpoint = torch.load(path, map_location='cpu')\n",
    "model.load_state_dict(checkpoint['state_dict'])\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001, betas=(0.5, 0.999))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4b9e3b62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test: [ 0/57]\tTime  0.861 ( 0.861)\tLoss 3.6663e+00 (3.6663e+00)\tAcc@1  43.75 ( 43.75)\tAcc@5  59.38 ( 59.38)\n",
      "Test: [ 5/57]\tTime  0.348 ( 0.442)\tLoss 3.0913e+00 (3.3674e+00)\tAcc@1  59.38 ( 56.25)\tAcc@5  68.75 ( 64.58)\n",
      "Test: [10/57]\tTime  0.348 ( 0.401)\tLoss 4.7401e+00 (3.3411e+00)\tAcc@1  37.50 ( 56.25)\tAcc@5  46.88 ( 64.20)\n",
      "Test: [15/57]\tTime  0.349 ( 0.386)\tLoss 2.8415e+00 (3.3730e+00)\tAcc@1  56.25 ( 55.47)\tAcc@5  71.88 ( 63.48)\n",
      "Test: [20/57]\tTime  0.348 ( 0.379)\tLoss 3.2785e+00 (3.2950e+00)\tAcc@1  50.00 ( 56.55)\tAcc@5  65.62 ( 64.58)\n",
      "Test: [25/57]\tTime  0.350 ( 0.376)\tLoss 4.3219e+00 (3.3283e+00)\tAcc@1  40.62 ( 55.53)\tAcc@5  56.25 ( 64.42)\n",
      "Test: [30/57]\tTime  0.392 ( 0.374)\tLoss 3.2525e+00 (3.3463e+00)\tAcc@1  59.38 ( 55.65)\tAcc@5  62.50 ( 64.31)\n",
      "Test: [35/57]\tTime  0.395 ( 0.377)\tLoss 2.3772e+00 (3.3527e+00)\tAcc@1  71.88 ( 55.30)\tAcc@5  75.00 ( 64.24)\n",
      "Test: [40/57]\tTime  0.358 ( 0.379)\tLoss 5.3952e+00 (3.2942e+00)\tAcc@1  37.50 ( 56.17)\tAcc@5  43.75 ( 65.09)\n",
      "Test: [45/57]\tTime  0.393 ( 0.379)\tLoss 2.8341e+00 (3.2248e+00)\tAcc@1  59.38 ( 57.13)\tAcc@5  71.88 ( 65.90)\n",
      "Test: [50/57]\tTime  0.394 ( 0.381)\tLoss 3.2119e+00 (3.2278e+00)\tAcc@1  53.12 ( 56.92)\tAcc@5  65.62 ( 65.87)\n",
      "Test: [55/57]\tTime  0.395 ( 0.382)\tLoss 2.8436e+00 (3.1873e+00)\tAcc@1  65.62 ( 57.31)\tAcc@5  68.75 ( 66.24)\n",
      " * Acc@1 57.278 Acc@5 66.222\n",
      "Test: [  0/450]\tTime  0.750 ( 0.750)\tLoss 5.1364e-01 (5.1364e-01)\tAcc@1  90.62 ( 90.62)\tAcc@5 100.00 (100.00)\n",
      "Test: [  5/450]\tTime  0.353 ( 0.423)\tLoss 4.3712e-01 (4.8210e-01)\tAcc@1  90.62 ( 87.50)\tAcc@5 100.00 ( 98.96)\n",
      "Test: [ 10/450]\tTime  0.351 ( 0.391)\tLoss 7.2846e-01 (5.1001e-01)\tAcc@1  78.12 ( 87.22)\tAcc@5  96.88 ( 98.86)\n",
      "Test: [ 15/450]\tTime  0.353 ( 0.379)\tLoss 1.5477e-01 (5.1955e-01)\tAcc@1  93.75 ( 85.35)\tAcc@5 100.00 ( 98.83)\n",
      "Test: [ 20/450]\tTime  0.355 ( 0.375)\tLoss 4.7896e-01 (4.6551e-01)\tAcc@1  87.50 ( 87.05)\tAcc@5 100.00 ( 99.11)\n",
      "Test: [ 25/450]\tTime  0.354 ( 0.371)\tLoss 8.7271e-02 (4.7241e-01)\tAcc@1 100.00 ( 87.26)\tAcc@5 100.00 ( 98.92)\n",
      "Test: [ 30/450]\tTime  0.354 ( 0.368)\tLoss 3.4639e-01 (4.4613e-01)\tAcc@1  90.62 ( 88.31)\tAcc@5 100.00 ( 98.89)\n",
      "Test: [ 35/450]\tTime  0.357 ( 0.366)\tLoss 5.8609e-01 (4.5731e-01)\tAcc@1  87.50 ( 87.93)\tAcc@5  96.88 ( 98.96)\n",
      "Test: [ 40/450]\tTime  0.366 ( 0.367)\tLoss 4.4245e-01 (4.4858e-01)\tAcc@1  87.50 ( 88.19)\tAcc@5 100.00 ( 98.86)\n",
      "Test: [ 45/450]\tTime  0.397 ( 0.368)\tLoss 3.5104e-01 (4.7569e-01)\tAcc@1  90.62 ( 86.82)\tAcc@5 100.00 ( 98.91)\n",
      "Test: [ 50/450]\tTime  0.354 ( 0.368)\tLoss 7.1655e-01 (4.7761e-01)\tAcc@1  81.25 ( 86.89)\tAcc@5  93.75 ( 98.77)\n",
      "Test: [ 55/450]\tTime  0.397 ( 0.368)\tLoss 5.5444e-01 (4.9070e-01)\tAcc@1  84.38 ( 86.33)\tAcc@5  96.88 ( 98.66)\n",
      "Test: [ 60/450]\tTime  0.398 ( 0.369)\tLoss 2.3935e-01 (4.6792e-01)\tAcc@1  96.88 ( 87.14)\tAcc@5 100.00 ( 98.72)\n",
      "Test: [ 65/450]\tTime  0.356 ( 0.369)\tLoss 2.4734e-01 (4.5563e-01)\tAcc@1  96.88 ( 87.69)\tAcc@5 100.00 ( 98.82)\n",
      "Test: [ 70/450]\tTime  0.354 ( 0.370)\tLoss 5.7832e-01 (4.6124e-01)\tAcc@1  78.12 ( 87.28)\tAcc@5 100.00 ( 98.86)\n",
      "Test: [ 75/450]\tTime  0.356 ( 0.369)\tLoss 1.0441e+00 (4.7899e-01)\tAcc@1  65.62 ( 86.60)\tAcc@5  96.88 ( 98.89)\n",
      "Test: [ 80/450]\tTime  0.355 ( 0.368)\tLoss 5.1122e-01 (4.6632e-01)\tAcc@1  93.75 ( 87.15)\tAcc@5  96.88 ( 98.92)\n",
      "Test: [ 85/450]\tTime  0.356 ( 0.368)\tLoss 5.1103e-01 (4.6829e-01)\tAcc@1  87.50 ( 87.17)\tAcc@5 100.00 ( 98.84)\n",
      "Test: [ 90/450]\tTime  0.356 ( 0.367)\tLoss 5.0776e-01 (4.7835e-01)\tAcc@1  81.25 ( 86.92)\tAcc@5  96.88 ( 98.76)\n",
      "Test: [ 95/450]\tTime  0.356 ( 0.367)\tLoss 6.5265e-01 (4.8914e-01)\tAcc@1  81.25 ( 86.69)\tAcc@5  96.88 ( 98.73)\n",
      "Test: [100/450]\tTime  0.357 ( 0.367)\tLoss 3.9877e-01 (4.8461e-01)\tAcc@1  87.50 ( 86.82)\tAcc@5  96.88 ( 98.76)\n",
      "Test: [105/450]\tTime  0.355 ( 0.366)\tLoss 5.1505e-01 (4.8524e-01)\tAcc@1  90.62 ( 86.79)\tAcc@5  96.88 ( 98.79)\n",
      "Test: [110/450]\tTime  0.357 ( 0.366)\tLoss 1.7520e-01 (4.8552e-01)\tAcc@1  96.88 ( 86.85)\tAcc@5 100.00 ( 98.82)\n",
      "Test: [115/450]\tTime  0.357 ( 0.366)\tLoss 8.1979e-01 (4.8456e-01)\tAcc@1  75.00 ( 86.88)\tAcc@5 100.00 ( 98.81)\n",
      "Test: [120/450]\tTime  0.355 ( 0.366)\tLoss 8.2662e-01 (4.9587e-01)\tAcc@1  75.00 ( 86.52)\tAcc@5 100.00 ( 98.86)\n",
      "Test: [125/450]\tTime  0.357 ( 0.366)\tLoss 6.2796e-01 (5.0465e-01)\tAcc@1  75.00 ( 86.24)\tAcc@5 100.00 ( 98.78)\n",
      "Test: [130/450]\tTime  0.355 ( 0.365)\tLoss 3.3463e-01 (5.1192e-01)\tAcc@1  93.75 ( 85.85)\tAcc@5  96.88 ( 98.71)\n",
      "Test: [135/450]\tTime  0.357 ( 0.365)\tLoss 4.6646e-01 (5.1427e-01)\tAcc@1  87.50 ( 85.71)\tAcc@5 100.00 ( 98.76)\n",
      "Test: [140/450]\tTime  0.357 ( 0.365)\tLoss 3.1122e-01 (5.1119e-01)\tAcc@1  96.88 ( 85.93)\tAcc@5 100.00 ( 98.69)\n",
      "Test: [145/450]\tTime  0.356 ( 0.365)\tLoss 4.3070e-01 (5.0735e-01)\tAcc@1  87.50 ( 86.04)\tAcc@5 100.00 ( 98.69)\n",
      "Test: [150/450]\tTime  0.394 ( 0.365)\tLoss 1.3277e-01 (5.0060e-01)\tAcc@1 100.00 ( 86.28)\tAcc@5 100.00 ( 98.74)\n",
      "Test: [155/450]\tTime  0.358 ( 0.365)\tLoss 2.5332e-01 (4.9795e-01)\tAcc@1  93.75 ( 86.40)\tAcc@5 100.00 ( 98.74)\n",
      "Test: [160/450]\tTime  0.357 ( 0.365)\tLoss 5.9733e-01 (4.9570e-01)\tAcc@1  81.25 ( 86.49)\tAcc@5  96.88 ( 98.76)\n",
      "Test: [165/450]\tTime  0.358 ( 0.365)\tLoss 5.0814e-01 (4.9235e-01)\tAcc@1  84.38 ( 86.58)\tAcc@5 100.00 ( 98.76)\n",
      "Test: [170/450]\tTime  0.356 ( 0.365)\tLoss 2.9615e-01 (4.8568e-01)\tAcc@1  90.62 ( 86.79)\tAcc@5 100.00 ( 98.78)\n",
      "Test: [175/450]\tTime  0.358 ( 0.364)\tLoss 9.6659e-02 (4.8519e-01)\tAcc@1 100.00 ( 86.84)\tAcc@5 100.00 ( 98.76)\n",
      "Test: [180/450]\tTime  0.357 ( 0.364)\tLoss 8.8557e-01 (4.8904e-01)\tAcc@1  56.25 ( 86.53)\tAcc@5  96.88 ( 98.74)\n",
      "Test: [185/450]\tTime  0.357 ( 0.364)\tLoss 3.1711e-01 (4.8861e-01)\tAcc@1  90.62 ( 86.61)\tAcc@5 100.00 ( 98.72)\n",
      "Test: [190/450]\tTime  0.358 ( 0.364)\tLoss 6.1486e-01 (4.8971e-01)\tAcc@1  78.12 ( 86.55)\tAcc@5  93.75 ( 98.69)\n",
      "Test: [195/450]\tTime  0.355 ( 0.364)\tLoss 3.0414e-01 (4.8774e-01)\tAcc@1  90.62 ( 86.65)\tAcc@5 100.00 ( 98.72)\n",
      "Test: [200/450]\tTime  0.360 ( 0.364)\tLoss 7.3688e-01 (4.9110e-01)\tAcc@1  78.12 ( 86.54)\tAcc@5  96.88 ( 98.71)\n",
      "Test: [205/450]\tTime  0.404 ( 0.365)\tLoss 8.8190e-01 (4.9326e-01)\tAcc@1  62.50 ( 86.36)\tAcc@5 100.00 ( 98.71)\n",
      "Test: [210/450]\tTime  0.374 ( 0.365)\tLoss 6.5721e-01 (4.9156e-01)\tAcc@1  78.12 ( 86.40)\tAcc@5 100.00 ( 98.73)\n",
      "Test: [215/450]\tTime  0.396 ( 0.366)\tLoss 5.2155e-01 (4.9722e-01)\tAcc@1  81.25 ( 86.11)\tAcc@5 100.00 ( 98.73)\n",
      "Test: [220/450]\tTime  0.358 ( 0.366)\tLoss 4.0672e-01 (5.0398e-01)\tAcc@1  90.62 ( 85.70)\tAcc@5 100.00 ( 98.74)\n",
      "Test: [225/450]\tTime  0.363 ( 0.366)\tLoss 2.2817e-01 (4.9853e-01)\tAcc@1  93.75 ( 85.85)\tAcc@5 100.00 ( 98.77)\n",
      "Test: [230/450]\tTime  0.356 ( 0.365)\tLoss 1.3375e-01 (4.9239e-01)\tAcc@1 100.00 ( 86.07)\tAcc@5 100.00 ( 98.80)\n",
      "Test: [235/450]\tTime  0.361 ( 0.365)\tLoss 4.6341e-01 (4.9289e-01)\tAcc@1  81.25 ( 86.11)\tAcc@5 100.00 ( 98.81)\n",
      "Test: [240/450]\tTime  0.356 ( 0.365)\tLoss 2.4356e-01 (4.9059e-01)\tAcc@1  96.88 ( 86.22)\tAcc@5 100.00 ( 98.79)\n",
      "Test: [245/450]\tTime  0.358 ( 0.365)\tLoss 1.0931e-01 (4.8660e-01)\tAcc@1 100.00 ( 86.34)\tAcc@5 100.00 ( 98.82)\n",
      "Test: [250/450]\tTime  0.358 ( 0.365)\tLoss 3.2599e-01 (4.8055e-01)\tAcc@1  93.75 ( 86.55)\tAcc@5 100.00 ( 98.83)\n",
      "Test: [255/450]\tTime  0.356 ( 0.365)\tLoss 4.9569e-01 (4.8012e-01)\tAcc@1  84.38 ( 86.58)\tAcc@5 100.00 ( 98.84)\n",
      "Test: [260/450]\tTime  0.402 ( 0.365)\tLoss 3.9963e-01 (4.8808e-01)\tAcc@1  90.62 ( 86.23)\tAcc@5 100.00 ( 98.81)\n",
      "Test: [265/450]\tTime  0.400 ( 0.366)\tLoss 2.6703e-01 (4.8503e-01)\tAcc@1  93.75 ( 86.36)\tAcc@5 100.00 ( 98.81)\n",
      "Test: [270/450]\tTime  0.399 ( 0.367)\tLoss 9.9369e+00 (5.7538e-01)\tAcc@1   0.00 ( 85.54)\tAcc@5   0.00 ( 97.76)\n",
      "Test: [275/450]\tTime  0.363 ( 0.367)\tLoss 9.1273e+00 (7.1948e-01)\tAcc@1   0.00 ( 83.99)\tAcc@5   0.00 ( 95.99)\n",
      "Test: [280/450]\tTime  0.403 ( 0.367)\tLoss 6.3231e+00 (8.4413e-01)\tAcc@1   0.00 ( 82.50)\tAcc@5  12.50 ( 94.58)\n",
      "Test: [285/450]\tTime  0.377 ( 0.368)\tLoss 8.4933e+00 (9.6398e-01)\tAcc@1   0.00 ( 81.05)\tAcc@5   0.00 ( 92.99)\n",
      "Test: [290/450]\tTime  0.401 ( 0.368)\tLoss 8.7651e+00 (1.0874e+00)\tAcc@1   0.00 ( 79.66)\tAcc@5   0.00 ( 91.40)\n",
      "Test: [295/450]\tTime  0.401 ( 0.369)\tLoss 6.9560e+00 (1.1952e+00)\tAcc@1   0.00 ( 78.32)\tAcc@5   0.00 ( 89.85)\n",
      "Test: [300/450]\tTime  0.357 ( 0.369)\tLoss 6.9918e+00 (1.3061e+00)\tAcc@1   3.12 ( 77.02)\tAcc@5   3.12 ( 88.37)\n",
      "Test: [305/450]\tTime  0.364 ( 0.369)\tLoss 8.9301e+00 (1.4182e+00)\tAcc@1   0.00 ( 75.77)\tAcc@5   0.00 ( 86.93)\n",
      "Test: [310/450]\tTime  0.358 ( 0.369)\tLoss 8.0974e+00 (1.5104e+00)\tAcc@1   0.00 ( 74.55)\tAcc@5   0.00 ( 85.67)\n",
      "Test: [315/450]\tTime  0.401 ( 0.369)\tLoss 7.1103e+00 (1.6223e+00)\tAcc@1   0.00 ( 73.37)\tAcc@5   6.25 ( 84.34)\n",
      "Test: [320/450]\tTime  0.401 ( 0.370)\tLoss 8.9186e+00 (1.7236e+00)\tAcc@1   0.00 ( 72.23)\tAcc@5   0.00 ( 83.02)\n",
      "Test: [325/450]\tTime  0.357 ( 0.370)\tLoss 8.5916e+00 (1.8335e+00)\tAcc@1   0.00 ( 71.12)\tAcc@5   0.00 ( 81.75)\n",
      "Test: [330/450]\tTime  0.359 ( 0.370)\tLoss 8.1645e+00 (1.9283e+00)\tAcc@1   0.00 ( 70.04)\tAcc@5   0.00 ( 80.51)\n",
      "Test: [335/450]\tTime  0.401 ( 0.370)\tLoss 7.6165e+00 (2.0127e+00)\tAcc@1   0.00 ( 69.00)\tAcc@5   0.00 ( 79.32)\n",
      "Test: [340/450]\tTime  0.358 ( 0.370)\tLoss 1.0052e+01 (2.1067e+00)\tAcc@1   0.00 ( 68.00)\tAcc@5   0.00 ( 78.17)\n",
      "Test: [345/450]\tTime  0.388 ( 0.370)\tLoss 9.5265e+00 (2.2123e+00)\tAcc@1   0.00 ( 67.02)\tAcc@5   0.00 ( 77.04)\n",
      "Test: [350/450]\tTime  0.408 ( 0.370)\tLoss 1.0017e+01 (2.3193e+00)\tAcc@1   0.00 ( 66.06)\tAcc@5   0.00 ( 75.94)\n",
      "Test: [355/450]\tTime  0.401 ( 0.371)\tLoss 1.0080e+01 (2.4217e+00)\tAcc@1   0.00 ( 65.13)\tAcc@5   0.00 ( 74.88)\n",
      "Test: [360/450]\tTime  0.398 ( 0.371)\tLoss 8.8034e+00 (2.5203e+00)\tAcc@1   0.00 ( 64.23)\tAcc@5   0.00 ( 73.84)\n",
      "Test: [365/450]\tTime  0.382 ( 0.371)\tLoss 9.3959e+00 (2.6137e+00)\tAcc@1   0.00 ( 63.35)\tAcc@5   0.00 ( 72.83)\n",
      "Test: [370/450]\tTime  0.360 ( 0.372)\tLoss 9.1078e+00 (2.7011e+00)\tAcc@1   0.00 ( 62.50)\tAcc@5   0.00 ( 71.85)\n",
      "Test: [375/450]\tTime  0.357 ( 0.372)\tLoss 9.2535e+00 (2.7910e+00)\tAcc@1   0.00 ( 61.67)\tAcc@5   0.00 ( 70.89)\n",
      "Test: [380/450]\tTime  0.358 ( 0.371)\tLoss 9.0486e+00 (2.8746e+00)\tAcc@1   0.00 ( 60.86)\tAcc@5   0.00 ( 69.96)\n",
      "Test: [385/450]\tTime  0.359 ( 0.371)\tLoss 9.7531e+00 (2.9577e+00)\tAcc@1   0.00 ( 60.07)\tAcc@5   0.00 ( 69.06)\n",
      "Test: [390/450]\tTime  0.357 ( 0.371)\tLoss 9.2869e+00 (3.0368e+00)\tAcc@1   0.00 ( 59.30)\tAcc@5   0.00 ( 68.17)\n",
      "Test: [395/450]\tTime  0.367 ( 0.371)\tLoss 9.1859e+00 (3.1125e+00)\tAcc@1   0.00 ( 58.55)\tAcc@5   0.00 ( 67.31)\n",
      "Test: [400/450]\tTime  0.401 ( 0.371)\tLoss 9.0545e+00 (3.1877e+00)\tAcc@1   0.00 ( 57.82)\tAcc@5   0.00 ( 66.47)\n",
      "Test: [405/450]\tTime  0.398 ( 0.371)\tLoss 9.2055e+00 (3.2625e+00)\tAcc@1   0.00 ( 57.11)\tAcc@5   0.00 ( 65.66)\n",
      "Test: [410/450]\tTime  0.380 ( 0.371)\tLoss 9.6314e+00 (3.3358e+00)\tAcc@1   0.00 ( 56.42)\tAcc@5   0.00 ( 64.86)\n",
      "Test: [415/450]\tTime  0.389 ( 0.372)\tLoss 9.5160e+00 (3.4032e+00)\tAcc@1   0.00 ( 55.74)\tAcc@5   0.00 ( 64.08)\n",
      "Test: [420/450]\tTime  0.385 ( 0.372)\tLoss 9.6849e+00 (3.4726e+00)\tAcc@1   0.00 ( 55.08)\tAcc@5   0.00 ( 63.32)\n",
      "Test: [425/450]\tTime  0.364 ( 0.372)\tLoss 8.5773e+00 (3.5370e+00)\tAcc@1   0.00 ( 54.43)\tAcc@5   0.00 ( 62.57)\n",
      "Test: [430/450]\tTime  0.398 ( 0.372)\tLoss 8.9241e+00 (3.5982e+00)\tAcc@1   0.00 ( 53.80)\tAcc@5   0.00 ( 61.85)\n",
      "Test: [435/450]\tTime  0.364 ( 0.372)\tLoss 8.5410e+00 (3.6574e+00)\tAcc@1   0.00 ( 53.18)\tAcc@5   0.00 ( 61.14)\n",
      "Test: [440/450]\tTime  0.369 ( 0.372)\tLoss 9.2040e+00 (3.7160e+00)\tAcc@1   0.00 ( 52.58)\tAcc@5   0.00 ( 60.45)\n",
      "Test: [445/450]\tTime  0.359 ( 0.372)\tLoss 9.0224e+00 (3.7732e+00)\tAcc@1   0.00 ( 51.99)\tAcc@5   0.00 ( 59.77)\n",
      " * Acc@1 51.621 Acc@5 59.343\n"
     ]
    }
   ],
   "source": [
    "train_model(30, train_loader, val_loader, test_loader, optimizer, criterion, model, f'resnetv2_fusion_{1}', is_train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bd4e24d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "model = torch.nn.DataParallel(model)\n",
    "model = model.to(device)\n",
    "\n",
    "path = \"/home/ikboljonsobirov/cv/ass1/Week5/datasets/model_resnetv2_cubs_and_dogs_noaug_best.pth.tar\"\n",
    "checkpoint = torch.load(path, map_location='cpu')\n",
    "\n",
    "model.load_state_dict(checkpoint['state_dict'])\n",
    "\n",
    "optimizer = model.parameters([\n",
    "                {'params': 0.99, 'lr': 0.0001, 'betas': (0.5, 0.999)},\n",
    "                {'params': 0.99, 'lr': 0.00001, 'betas': (0.5, 0.999)}])\n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "train_model(30, train_loader, val_loader, test_loader, optimizer, criterion, model, f'resnetv2_fusion_{1}', is_train=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f26ae185",
   "metadata": {},
   "source": [
    "## Fusion Model\n",
    "In this experiment we tried to combine the trasformer model (in our case cait_xxs_24_384) with a CNN model (in our case resnetv2). **The implementation of the model is in the models folder (bilinear_model.py)**. We extract features from the the third block of resnet backbone. For transformers, we combine all the patch token coming out of the encoder to form a feature map. Then we combine both of the feature maps using a transfusion module block in hope that it will be able to integrate the learned features from both of the backbones and give a more powerful feature representation.\n",
    "\n",
    "For comparison , we are only showing models trained without any data augmentation (just resize and normalisation) for the sake of clarity. Training on larger resolution images gives a boost to the accuracy, as can be seen in using resnetv2 with $448\\times 448$ image size. However to reduce computation and for a fair comparison with the Fusion model which uses $384 \\times 384$ for both backbones, we will compare it with the accuracy of resnetv2_384 (top1 test Accuracy $81.61 \\%$) and cait_384 (top1 test Accuracy $79.89 \\%$)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5b0f0e86",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_transform=transforms.Compose([\n",
    "                    transforms.Resize((384, 384)),\n",
    "                    transforms.ToTensor(),\n",
    "                    transforms.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225))\n",
    "                ])\n",
    "\n",
    "data_transform = transforms.Compose([ \n",
    "\n",
    "        transforms.Resize((384, 384)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=mean, std=std)\n",
    "    ])\n",
    "\n",
    "train_loader, val_loader, test_loader = cub_and_dogs(bs=batch_size, data_transform=data_transform, test_transform=test_transform)\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9eb303a",
   "metadata": {},
   "source": [
    "Here both backbones on pretrained on ImageNet. The bacbones are frozen, only the transfusion block and final layers are trained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4eb1df02",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = bilinear_model.TransFuse_S(num_classes=320, pretrained=True)\n",
    "model = model.to(device)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "path = \"/home/hashmat.malik/Fall 2021/CV703 Lab/Week5/datasets/modelresnetv2_fusion_4_best.pth.tar\"\n",
    "checkpoint = torch.load(path)\n",
    "model.load_state_dict(checkpoint['state_dict'])\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001, betas=(0.5, 0.999))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0fd4165a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test: [ 0/57]\tTime  1.020 ( 1.020)\tLoss 7.4345e-01 (7.4345e-01)\tAcc@1  75.00 ( 75.00)\tAcc@5  96.88 ( 96.88)\n",
      "Test: [ 5/57]\tTime  0.452 ( 0.559)\tLoss 5.1658e-01 (6.4955e-01)\tAcc@1  81.25 ( 78.12)\tAcc@5 100.00 ( 97.92)\n",
      "Test: [10/57]\tTime  0.452 ( 0.513)\tLoss 8.8987e-01 (7.5851e-01)\tAcc@1  71.88 ( 76.42)\tAcc@5 100.00 ( 97.44)\n",
      "Test: [15/57]\tTime  0.451 ( 0.496)\tLoss 9.9967e-01 (8.0272e-01)\tAcc@1  68.75 ( 75.98)\tAcc@5  90.62 ( 96.48)\n",
      "Test: [20/57]\tTime  0.454 ( 0.487)\tLoss 6.0313e-01 (7.6953e-01)\tAcc@1  84.38 ( 77.23)\tAcc@5  93.75 ( 96.28)\n",
      "Test: [25/57]\tTime  0.453 ( 0.481)\tLoss 5.9471e-01 (7.4037e-01)\tAcc@1  75.00 ( 78.12)\tAcc@5 100.00 ( 96.63)\n",
      "Test: [30/57]\tTime  0.454 ( 0.478)\tLoss 1.1169e+00 (7.4522e-01)\tAcc@1  71.88 ( 77.92)\tAcc@5  96.88 ( 96.67)\n",
      "Test: [35/57]\tTime  0.455 ( 0.476)\tLoss 8.5409e-01 (7.1897e-01)\tAcc@1  75.00 ( 78.99)\tAcc@5  93.75 ( 96.88)\n",
      "Test: [40/57]\tTime  0.453 ( 0.474)\tLoss 9.0299e-01 (7.1328e-01)\tAcc@1  71.88 ( 78.81)\tAcc@5 100.00 ( 97.18)\n",
      "Test: [45/57]\tTime  0.455 ( 0.472)\tLoss 3.9612e-01 (7.1453e-01)\tAcc@1  90.62 ( 78.74)\tAcc@5  96.88 ( 97.15)\n",
      "Test: [50/57]\tTime  0.455 ( 0.471)\tLoss 3.7388e-01 (7.2934e-01)\tAcc@1  87.50 ( 78.25)\tAcc@5 100.00 ( 97.06)\n",
      "Test: [55/57]\tTime  0.453 ( 0.470)\tLoss 8.8112e-01 (7.2283e-01)\tAcc@1  78.12 ( 78.24)\tAcc@5  93.75 ( 97.10)\n",
      " * Acc@1 78.278 Acc@5 97.111\n",
      "Test: [  0/450]\tTime  0.914 ( 0.914)\tLoss 1.5454e+00 (1.5454e+00)\tAcc@1  56.25 ( 56.25)\tAcc@5  90.62 ( 90.62)\n",
      "Test: [  5/450]\tTime  0.456 ( 0.540)\tLoss 2.1156e+00 (1.2370e+00)\tAcc@1  53.12 ( 68.23)\tAcc@5  84.38 ( 92.71)\n",
      "Test: [ 10/450]\tTime  0.458 ( 0.505)\tLoss 8.9695e-01 (1.1848e+00)\tAcc@1  78.12 ( 71.88)\tAcc@5 100.00 ( 92.90)\n",
      "Test: [ 15/450]\tTime  0.458 ( 0.492)\tLoss 2.0916e-01 (1.0271e+00)\tAcc@1  87.50 ( 73.05)\tAcc@5 100.00 ( 94.53)\n",
      "Test: [ 20/450]\tTime  0.460 ( 0.485)\tLoss 5.5222e-01 (8.5125e-01)\tAcc@1  87.50 ( 77.53)\tAcc@5 100.00 ( 95.83)\n",
      "Test: [ 25/450]\tTime  0.460 ( 0.481)\tLoss 8.8568e-03 (8.1012e-01)\tAcc@1 100.00 ( 78.37)\tAcc@5 100.00 ( 96.39)\n",
      "Test: [ 30/450]\tTime  0.459 ( 0.478)\tLoss 2.7683e-01 (7.1018e-01)\tAcc@1  90.62 ( 80.54)\tAcc@5 100.00 ( 96.88)\n",
      "Test: [ 35/450]\tTime  0.463 ( 0.477)\tLoss 4.2129e-01 (7.2865e-01)\tAcc@1  93.75 ( 80.03)\tAcc@5  93.75 ( 96.96)\n",
      "Test: [ 40/450]\tTime  0.460 ( 0.475)\tLoss 6.3082e-01 (7.0606e-01)\tAcc@1  81.25 ( 81.02)\tAcc@5 100.00 ( 97.03)\n",
      "Test: [ 45/450]\tTime  0.458 ( 0.474)\tLoss 7.5376e-01 (7.2494e-01)\tAcc@1  75.00 ( 79.76)\tAcc@5  96.88 ( 97.15)\n",
      "Test: [ 50/450]\tTime  0.460 ( 0.473)\tLoss 1.2620e+00 (7.2084e-01)\tAcc@1  65.62 ( 79.78)\tAcc@5  96.88 ( 97.30)\n",
      "Test: [ 55/450]\tTime  0.463 ( 0.473)\tLoss 6.0710e-01 (7.3062e-01)\tAcc@1  78.12 ( 79.74)\tAcc@5 100.00 ( 97.27)\n",
      "Test: [ 60/450]\tTime  0.460 ( 0.472)\tLoss 1.8370e-01 (7.0995e-01)\tAcc@1  90.62 ( 80.43)\tAcc@5 100.00 ( 97.34)\n",
      "Test: [ 65/450]\tTime  0.461 ( 0.472)\tLoss 1.4841e-01 (6.6956e-01)\tAcc@1  96.88 ( 81.53)\tAcc@5 100.00 ( 97.54)\n",
      "Test: [ 70/450]\tTime  0.462 ( 0.472)\tLoss 3.6672e-01 (6.4489e-01)\tAcc@1  84.38 ( 82.09)\tAcc@5 100.00 ( 97.67)\n",
      "Test: [ 75/450]\tTime  0.459 ( 0.472)\tLoss 1.6244e+00 (6.7255e-01)\tAcc@1  59.38 ( 81.21)\tAcc@5  93.75 ( 97.57)\n",
      "Test: [ 80/450]\tTime  0.463 ( 0.472)\tLoss 6.7106e-01 (6.5096e-01)\tAcc@1  90.62 ( 81.79)\tAcc@5  96.88 ( 97.65)\n",
      "Test: [ 85/450]\tTime  0.463 ( 0.471)\tLoss 5.7127e-01 (6.4112e-01)\tAcc@1  87.50 ( 82.12)\tAcc@5 100.00 ( 97.67)\n",
      "Test: [ 90/450]\tTime  0.462 ( 0.471)\tLoss 6.8607e-01 (6.5291e-01)\tAcc@1  78.12 ( 82.04)\tAcc@5 100.00 ( 97.70)\n",
      "Test: [ 95/450]\tTime  0.463 ( 0.471)\tLoss 6.3092e-01 (6.8259e-01)\tAcc@1  78.12 ( 81.09)\tAcc@5 100.00 ( 97.72)\n",
      "Test: [100/450]\tTime  0.511 ( 0.471)\tLoss 4.5180e-01 (6.7664e-01)\tAcc@1  93.75 ( 81.25)\tAcc@5  93.75 ( 97.65)\n",
      "Test: [105/450]\tTime  0.461 ( 0.471)\tLoss 6.9070e-01 (6.6089e-01)\tAcc@1  84.38 ( 81.69)\tAcc@5  93.75 ( 97.70)\n",
      "Test: [110/450]\tTime  0.465 ( 0.471)\tLoss 1.3391e-01 (6.6282e-01)\tAcc@1  93.75 ( 81.45)\tAcc@5 100.00 ( 97.75)\n",
      "Test: [115/450]\tTime  0.462 ( 0.471)\tLoss 1.1250e+00 (6.5382e-01)\tAcc@1  65.62 ( 81.65)\tAcc@5  93.75 ( 97.79)\n",
      "Test: [120/450]\tTime  0.501 ( 0.471)\tLoss 1.1136e+00 (6.6026e-01)\tAcc@1  81.25 ( 81.46)\tAcc@5  90.62 ( 97.78)\n",
      "Test: [125/450]\tTime  0.461 ( 0.471)\tLoss 1.0099e+00 (6.6913e-01)\tAcc@1  59.38 ( 81.18)\tAcc@5  96.88 ( 97.79)\n",
      "Test: [130/450]\tTime  0.464 ( 0.471)\tLoss 4.9964e-01 (6.6871e-01)\tAcc@1  87.50 ( 81.20)\tAcc@5 100.00 ( 97.81)\n",
      "Test: [135/450]\tTime  0.464 ( 0.471)\tLoss 1.1664e+00 (6.7298e-01)\tAcc@1  68.75 ( 80.81)\tAcc@5  93.75 ( 97.82)\n",
      "Test: [140/450]\tTime  0.463 ( 0.471)\tLoss 1.3394e+00 (6.8290e-01)\tAcc@1  59.38 ( 80.65)\tAcc@5  96.88 ( 97.74)\n",
      "Test: [145/450]\tTime  0.463 ( 0.471)\tLoss 1.0373e-01 (6.7517e-01)\tAcc@1  93.75 ( 80.82)\tAcc@5 100.00 ( 97.77)\n",
      "Test: [150/450]\tTime  0.465 ( 0.471)\tLoss 1.2787e-01 (6.6440e-01)\tAcc@1  93.75 ( 81.06)\tAcc@5 100.00 ( 97.83)\n",
      "Test: [155/450]\tTime  0.467 ( 0.471)\tLoss 2.5942e-01 (6.5894e-01)\tAcc@1  90.62 ( 81.23)\tAcc@5 100.00 ( 97.84)\n",
      "Test: [160/450]\tTime  0.463 ( 0.471)\tLoss 5.9706e-01 (6.4797e-01)\tAcc@1  90.62 ( 81.56)\tAcc@5  96.88 ( 97.88)\n",
      "Test: [165/450]\tTime  0.475 ( 0.471)\tLoss 3.6549e-01 (6.4200e-01)\tAcc@1  90.62 ( 81.72)\tAcc@5 100.00 ( 97.91)\n",
      "Test: [170/450]\tTime  0.463 ( 0.471)\tLoss 1.5255e-01 (6.2976e-01)\tAcc@1  93.75 ( 82.05)\tAcc@5 100.00 ( 97.97)\n",
      "Test: [175/450]\tTime  0.465 ( 0.471)\tLoss 1.8139e-01 (6.2379e-01)\tAcc@1  90.62 ( 82.17)\tAcc@5 100.00 ( 97.96)\n",
      "Test: [180/450]\tTime  0.465 ( 0.471)\tLoss 9.9812e-01 (6.2554e-01)\tAcc@1  65.62 ( 82.11)\tAcc@5  96.88 ( 98.00)\n",
      "Test: [185/450]\tTime  0.465 ( 0.471)\tLoss 4.1780e-01 (6.2309e-01)\tAcc@1  87.50 ( 82.17)\tAcc@5 100.00 ( 97.98)\n",
      "Test: [190/450]\tTime  0.465 ( 0.471)\tLoss 4.2242e-01 (6.2471e-01)\tAcc@1  87.50 ( 82.26)\tAcc@5 100.00 ( 97.95)\n",
      "Test: [195/450]\tTime  0.496 ( 0.471)\tLoss 1.4684e-01 (6.1741e-01)\tAcc@1  90.62 ( 82.46)\tAcc@5 100.00 ( 98.01)\n",
      "Test: [200/450]\tTime  0.464 ( 0.471)\tLoss 6.6839e-01 (6.1687e-01)\tAcc@1  75.00 ( 82.34)\tAcc@5  96.88 ( 98.04)\n",
      "Test: [205/450]\tTime  0.465 ( 0.472)\tLoss 8.2938e-01 (6.1825e-01)\tAcc@1  75.00 ( 82.28)\tAcc@5 100.00 ( 98.07)\n",
      "Test: [210/450]\tTime  0.465 ( 0.472)\tLoss 9.9122e-01 (6.1345e-01)\tAcc@1  78.12 ( 82.45)\tAcc@5  93.75 ( 98.07)\n",
      "Test: [215/450]\tTime  0.465 ( 0.471)\tLoss 1.7113e+00 (6.2267e-01)\tAcc@1  53.12 ( 82.09)\tAcc@5 100.00 ( 98.10)\n",
      "Test: [220/450]\tTime  0.468 ( 0.471)\tLoss 6.9777e-01 (6.2970e-01)\tAcc@1  81.25 ( 81.79)\tAcc@5 100.00 ( 98.12)\n",
      "Test: [225/450]\tTime  0.466 ( 0.471)\tLoss 1.6173e-01 (6.2079e-01)\tAcc@1  93.75 ( 82.02)\tAcc@5 100.00 ( 98.15)\n",
      "Test: [230/450]\tTime  0.464 ( 0.471)\tLoss 5.3255e-02 (6.1013e-01)\tAcc@1  96.88 ( 82.31)\tAcc@5 100.00 ( 98.19)\n",
      "Test: [235/450]\tTime  0.466 ( 0.471)\tLoss 5.1508e-01 (6.0741e-01)\tAcc@1  84.38 ( 82.38)\tAcc@5  96.88 ( 98.20)\n",
      "Test: [240/450]\tTime  0.466 ( 0.471)\tLoss 1.2232e-01 (6.0180e-01)\tAcc@1  96.88 ( 82.51)\tAcc@5 100.00 ( 98.21)\n",
      "Test: [245/450]\tTime  0.464 ( 0.471)\tLoss 1.6187e-01 (5.9726e-01)\tAcc@1  93.75 ( 82.66)\tAcc@5 100.00 ( 98.21)\n",
      "Test: [250/450]\tTime  0.464 ( 0.471)\tLoss 4.2572e-01 (5.8860e-01)\tAcc@1  93.75 ( 82.93)\tAcc@5 100.00 ( 98.24)\n",
      "Test: [255/450]\tTime  0.468 ( 0.471)\tLoss 2.8083e-01 (5.9003e-01)\tAcc@1  81.25 ( 82.79)\tAcc@5 100.00 ( 98.25)\n",
      "Test: [260/450]\tTime  0.465 ( 0.471)\tLoss 4.9285e-01 (5.9961e-01)\tAcc@1  78.12 ( 82.46)\tAcc@5 100.00 ( 98.24)\n",
      "Test: [265/450]\tTime  0.466 ( 0.471)\tLoss 3.4622e-01 (5.9684e-01)\tAcc@1  90.62 ( 82.58)\tAcc@5  96.88 ( 98.23)\n",
      "Test: [270/450]\tTime  0.466 ( 0.471)\tLoss 1.7081e+00 (5.9789e-01)\tAcc@1  40.62 ( 82.56)\tAcc@5 100.00 ( 98.20)\n",
      "Test: [275/450]\tTime  0.464 ( 0.471)\tLoss 1.9509e+00 (6.1207e-01)\tAcc@1  40.62 ( 82.13)\tAcc@5  81.25 ( 98.03)\n",
      "Test: [280/450]\tTime  0.468 ( 0.471)\tLoss 7.9834e-01 (6.1638e-01)\tAcc@1  87.50 ( 82.13)\tAcc@5  93.75 ( 97.96)\n",
      "Test: [285/450]\tTime  0.466 ( 0.471)\tLoss 5.9876e-01 (6.1760e-01)\tAcc@1  81.25 ( 82.12)\tAcc@5 100.00 ( 97.93)\n",
      "Test: [290/450]\tTime  0.466 ( 0.471)\tLoss 9.5925e-01 (6.2926e-01)\tAcc@1  78.12 ( 81.74)\tAcc@5  90.62 ( 97.82)\n",
      "Test: [295/450]\tTime  0.466 ( 0.471)\tLoss 7.6791e-01 (6.4231e-01)\tAcc@1  81.25 ( 81.32)\tAcc@5  96.88 ( 97.74)\n",
      "Test: [300/450]\tTime  0.466 ( 0.471)\tLoss 1.8619e+00 (6.4997e-01)\tAcc@1  59.38 ( 81.16)\tAcc@5  84.38 ( 97.62)\n",
      "Test: [305/450]\tTime  0.467 ( 0.471)\tLoss 9.3479e-01 (6.5967e-01)\tAcc@1  71.88 ( 80.90)\tAcc@5  93.75 ( 97.51)\n",
      "Test: [310/450]\tTime  0.464 ( 0.471)\tLoss 8.5626e-01 (6.5985e-01)\tAcc@1  75.00 ( 80.93)\tAcc@5 100.00 ( 97.49)\n",
      "Test: [315/450]\tTime  0.465 ( 0.471)\tLoss 6.9104e-01 (6.5879e-01)\tAcc@1  78.12 ( 80.96)\tAcc@5  93.75 ( 97.48)\n",
      "Test: [320/450]\tTime  0.467 ( 0.471)\tLoss 1.8913e+00 (6.7221e-01)\tAcc@1  40.62 ( 80.56)\tAcc@5  93.75 ( 97.34)\n",
      "Test: [325/450]\tTime  0.466 ( 0.471)\tLoss 1.1613e+00 (6.8110e-01)\tAcc@1  65.62 ( 80.24)\tAcc@5  93.75 ( 97.25)\n",
      "Test: [330/450]\tTime  0.464 ( 0.471)\tLoss 1.7752e+00 (6.8543e-01)\tAcc@1  40.62 ( 80.07)\tAcc@5  87.50 ( 97.22)\n",
      "Test: [335/450]\tTime  0.468 ( 0.471)\tLoss 9.4993e-01 (6.8660e-01)\tAcc@1  75.00 ( 80.01)\tAcc@5  93.75 ( 97.19)\n",
      "Test: [340/450]\tTime  0.465 ( 0.471)\tLoss 8.6385e-01 (6.8553e-01)\tAcc@1  71.88 ( 80.09)\tAcc@5  93.75 ( 97.19)\n",
      "Test: [345/450]\tTime  0.466 ( 0.471)\tLoss 1.0148e+00 (6.8698e-01)\tAcc@1  78.12 ( 80.05)\tAcc@5  87.50 ( 97.14)\n",
      "Test: [350/450]\tTime  0.470 ( 0.471)\tLoss 1.8649e-01 (6.8754e-01)\tAcc@1  93.75 ( 80.07)\tAcc@5 100.00 ( 97.08)\n",
      "Test: [355/450]\tTime  0.469 ( 0.471)\tLoss 1.1940e+00 (6.9152e-01)\tAcc@1  78.12 ( 80.00)\tAcc@5  90.62 ( 97.02)\n",
      "Test: [360/450]\tTime  0.468 ( 0.471)\tLoss 3.0181e+00 (7.0214e-01)\tAcc@1  37.50 ( 79.78)\tAcc@5  65.62 ( 96.88)\n",
      "Test: [365/450]\tTime  0.467 ( 0.471)\tLoss 4.8456e-01 (7.0552e-01)\tAcc@1  90.62 ( 79.67)\tAcc@5  96.88 ( 96.87)\n",
      "Test: [370/450]\tTime  0.467 ( 0.471)\tLoss 1.5224e+00 (7.0946e-01)\tAcc@1  50.00 ( 79.51)\tAcc@5  84.38 ( 96.81)\n",
      "Test: [375/450]\tTime  0.467 ( 0.471)\tLoss 3.2763e+00 (7.2854e-01)\tAcc@1  28.12 ( 79.10)\tAcc@5  75.00 ( 96.59)\n",
      "Test: [380/450]\tTime  0.467 ( 0.471)\tLoss 1.8198e+00 (7.4020e-01)\tAcc@1  37.50 ( 78.78)\tAcc@5  84.38 ( 96.44)\n",
      "Test: [385/450]\tTime  0.465 ( 0.471)\tLoss 1.6040e+00 (7.5535e-01)\tAcc@1  56.25 ( 78.40)\tAcc@5  87.50 ( 96.32)\n",
      "Test: [390/450]\tTime  0.480 ( 0.472)\tLoss 1.6903e+00 (7.6153e-01)\tAcc@1  43.75 ( 78.21)\tAcc@5  93.75 ( 96.28)\n",
      "Test: [395/450]\tTime  0.467 ( 0.472)\tLoss 2.3526e+00 (7.6539e-01)\tAcc@1  40.62 ( 78.13)\tAcc@5  78.12 ( 96.23)\n",
      "Test: [400/450]\tTime  0.467 ( 0.472)\tLoss 1.4838e+00 (7.7619e-01)\tAcc@1  56.25 ( 77.69)\tAcc@5  93.75 ( 96.21)\n",
      "Test: [405/450]\tTime  0.467 ( 0.472)\tLoss 1.9920e+00 (7.7923e-01)\tAcc@1  40.62 ( 77.61)\tAcc@5  87.50 ( 96.17)\n",
      "Test: [410/450]\tTime  0.465 ( 0.472)\tLoss 4.7586e-01 (7.8832e-01)\tAcc@1  87.50 ( 77.40)\tAcc@5 100.00 ( 96.06)\n",
      "Test: [415/450]\tTime  0.480 ( 0.472)\tLoss 5.7249e-01 (7.8758e-01)\tAcc@1  75.00 ( 77.42)\tAcc@5 100.00 ( 96.08)\n",
      "Test: [420/450]\tTime  0.496 ( 0.472)\tLoss 8.8308e-01 (7.9137e-01)\tAcc@1  75.00 ( 77.31)\tAcc@5  93.75 ( 96.02)\n",
      "Test: [425/450]\tTime  0.467 ( 0.472)\tLoss 2.1780e+00 (8.0386e-01)\tAcc@1  53.12 ( 77.10)\tAcc@5  81.25 ( 95.88)\n",
      "Test: [430/450]\tTime  0.465 ( 0.472)\tLoss 7.8560e-01 (8.0548e-01)\tAcc@1  81.25 ( 77.10)\tAcc@5  96.88 ( 95.85)\n",
      "Test: [435/450]\tTime  0.467 ( 0.472)\tLoss 5.2905e-01 (8.0534e-01)\tAcc@1  84.38 ( 77.05)\tAcc@5  96.88 ( 95.86)\n",
      "Test: [440/450]\tTime  0.467 ( 0.472)\tLoss 3.2455e-01 (8.0017e-01)\tAcc@1  90.62 ( 77.20)\tAcc@5 100.00 ( 95.90)\n",
      "Test: [445/450]\tTime  0.468 ( 0.472)\tLoss 1.5991e+00 (8.0186e-01)\tAcc@1  53.12 ( 77.15)\tAcc@5  93.75 ( 95.89)\n",
      " * Acc@1 77.153 Acc@5 95.874\n"
     ]
    }
   ],
   "source": [
    "train_model(30, train_loader, val_loader, test_loader, optimizer, criterion, model, f'resnetv2_fusion_{1}', is_train=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c77bbfdd",
   "metadata": {},
   "source": [
    "Reached top1 validation accuracy of $78.28\\%$ and top1 test accuracy of $77.153\\%$. This is less than the individual accuracy of both resnetv2-384 as well as cait_384. We also tried to fine tune the whole by unfreezing the backbones. However, it led to decrease in the accuracy which we believe is because loss of pretrained learned representation. Results can be seen in the excel sheet. While data augmentation increased the accuracy, it still was less than the accuracy achieved by resnetv2 and cait separately."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
