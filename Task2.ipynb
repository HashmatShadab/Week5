{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e8b86ea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import dog_dataset, cub_dataset, food_dataset, cub_and_dogs\n",
    "from models.models_to_finetune import deit_small_patch16_224, myresnetv2_task1, myresnetv2_task2, myresnetv2_for_c_loss\n",
    "import PIL\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from torchvision import transforms\n",
    "import config\n",
    "import sys\n",
    "import math\n",
    "from loss import CenterLoss\n",
    "from run_center_loss import train_model_with_closs\n",
    "from vit.vit_pytorch.nest import NesT\n",
    "import timm\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "82bf5877",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 50\n",
    "batch_size = 32\n",
    "mean = (0.485, 0.456, 0.406)\n",
    "std = (0.229, 0.224, 0.225)\n",
    "test_transform=transforms.Compose([\n",
    "                    transforms.Resize((448, 448)),\n",
    "                    transforms.ToTensor(),\n",
    "                    transforms.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225))\n",
    "                ])\n",
    "\n",
    "data_transform4 = transforms.Compose([  #\n",
    "\n",
    "        transforms.Resize((448, 448)),\n",
    "        transforms.RandomRotation(20),\n",
    "        transforms.GaussianBlur(3, sigma=(0.1, 2.0)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=mean, std=std)\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fa7901a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader, val_loader, test_loader = cub_and_dogs(bs=batch_size, data_transform=data_transform4, test_transform=test_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a755ab8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hashmat.malik/Fall 2021/CV703 Lab/Week5/loss.py:38: UserWarning: This overload of addmm_ is deprecated:\n",
      "\taddmm_(Number beta, Number alpha, Tensor mat1, Tensor mat2)\n",
      "Consider using one of the following signatures instead:\n",
      "\taddmm_(Tensor mat1, Tensor mat2, *, Number beta, Number alpha) (Triggered internally at  /opt/conda/conda-bld/pytorch_1614378124864/work/torch/csrc/utils/python_arg_parser.cpp:1005.)\n",
      "  distmat.addmm_(1, -2, x, self.centers.t())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test: [ 0/57]\tTime  1.552 ( 1.552)\tent_Loss 4.3390e-01 (4.3390e-01)\tcenter_loss 2.5113e+03 (2.5113e+03)\tloss 7.9678e+00 (7.9678e+00)\tAcc@1  87.50 ( 87.50)\tAcc@5  96.88 ( 96.88)\n",
      "Test: [ 5/57]\tTime  0.996 ( 1.024)\tent_Loss 4.0481e-01 (5.0927e-01)\tcenter_loss 2.3015e+03 (2.3159e+03)\tloss 7.3093e+00 (7.4569e+00)\tAcc@1  93.75 ( 85.42)\tAcc@5  96.88 ( 96.35)\n",
      "Test: [10/57]\tTime  0.992 ( 1.012)\tent_Loss 6.7870e-01 (5.8212e-01)\tcenter_loss 2.3938e+03 (2.3344e+03)\tloss 7.8602e+00 (7.5852e+00)\tAcc@1  75.00 ( 82.39)\tAcc@5 100.00 ( 97.16)\n",
      "Test: [15/57]\tTime  1.023 ( 0.997)\tent_Loss 6.2946e-01 (5.9904e-01)\tcenter_loss 2.4535e+03 (2.3481e+03)\tloss 7.9899e+00 (7.6434e+00)\tAcc@1  87.50 ( 82.81)\tAcc@5  96.88 ( 97.46)\n",
      "Test: [20/57]\tTime  0.936 ( 0.992)\tent_Loss 5.5113e-01 (5.9357e-01)\tcenter_loss 2.2764e+03 (2.3293e+03)\tloss 7.3804e+00 (7.5815e+00)\tAcc@1  75.00 ( 82.59)\tAcc@5 100.00 ( 97.92)\n",
      "Test: [25/57]\tTime  0.928 ( 0.986)\tent_Loss 7.3436e-01 (6.0949e-01)\tcenter_loss 2.2519e+03 (2.3437e+03)\tloss 7.4901e+00 (7.6406e+00)\tAcc@1  81.25 ( 82.09)\tAcc@5  93.75 ( 97.60)\n",
      "Test: [30/57]\tTime  0.972 ( 0.982)\tent_Loss 6.5976e-01 (6.0273e-01)\tcenter_loss 2.1488e+03 (2.3422e+03)\tloss 7.1063e+00 (7.6293e+00)\tAcc@1  87.50 ( 82.86)\tAcc@5 100.00 ( 97.48)\n",
      "Test: [35/57]\tTime  0.919 ( 0.980)\tent_Loss 9.6906e-01 (6.0597e-01)\tcenter_loss 2.3225e+03 (2.3413e+03)\tloss 7.9366e+00 (7.6300e+00)\tAcc@1  75.00 ( 82.99)\tAcc@5  93.75 ( 97.40)\n",
      "Test: [40/57]\tTime  0.941 ( 0.974)\tent_Loss 4.9350e-01 (5.9973e-01)\tcenter_loss 2.3179e+03 (2.3391e+03)\tloss 7.4473e+00 (7.6172e+00)\tAcc@1  84.38 ( 83.23)\tAcc@5  96.88 ( 97.26)\n",
      "Test: [45/57]\tTime  0.938 ( 0.970)\tent_Loss 8.5237e-01 (6.0748e-01)\tcenter_loss 2.4127e+03 (2.3413e+03)\tloss 8.0904e+00 (7.6313e+00)\tAcc@1  84.38 ( 83.29)\tAcc@5  93.75 ( 97.35)\n",
      "Test: [50/57]\tTime  0.917 ( 0.966)\tent_Loss 6.7120e-01 (6.1084e-01)\tcenter_loss 2.3806e+03 (2.3418e+03)\tloss 7.8129e+00 (7.6362e+00)\tAcc@1  78.12 ( 83.21)\tAcc@5 100.00 ( 97.37)\n",
      "Test: [55/57]\tTime  0.926 ( 0.963)\tent_Loss 3.5699e-01 (6.0643e-01)\tcenter_loss 2.3811e+03 (2.3480e+03)\tloss 7.5002e+00 (7.6505e+00)\tAcc@1  87.50 ( 83.15)\tAcc@5 100.00 ( 97.49)\n",
      " * Acc@1 83.167 Acc@5 97.500\n",
      "Test: [  0/450]\tTime  0.581 ( 0.581)\tent_Loss 6.6751e-01 (6.6751e-01)\tcenter_loss 1.8532e+03 (1.8532e+03)\tloss 6.2271e+00 (6.2271e+00)\tAcc@1  78.12 ( 78.12)\tAcc@5  93.75 ( 93.75)\n",
      "Test: [  5/450]\tTime  0.308 ( 0.355)\tent_Loss 4.9314e-01 (6.4180e-01)\tcenter_loss 2.0825e+03 (2.0545e+03)\tloss 6.7407e+00 (6.8054e+00)\tAcc@1  87.50 ( 83.33)\tAcc@5 100.00 ( 95.31)\n",
      "Test: [ 10/450]\tTime  0.294 ( 0.330)\tent_Loss 7.6836e-01 (6.0548e-01)\tcenter_loss 2.0789e+03 (2.0699e+03)\tloss 7.0050e+00 (6.8151e+00)\tAcc@1  75.00 ( 83.52)\tAcc@5  96.88 ( 96.59)\n",
      "Test: [ 15/450]\tTime  0.287 ( 0.321)\tent_Loss 3.4636e-01 (6.5915e-01)\tcenter_loss 1.9747e+03 (2.0650e+03)\tloss 6.2706e+00 (6.8540e+00)\tAcc@1  90.62 ( 81.64)\tAcc@5 100.00 ( 96.68)\n",
      "Test: [ 20/450]\tTime  0.293 ( 0.317)\tent_Loss 5.6024e-01 (5.7170e-01)\tcenter_loss 2.0423e+03 (2.0494e+03)\tloss 6.6871e+00 (6.7198e+00)\tAcc@1  84.38 ( 83.93)\tAcc@5 100.00 ( 97.47)\n",
      "Test: [ 25/450]\tTime  0.318 ( 0.319)\tent_Loss 1.2543e-01 (6.2432e-01)\tcenter_loss 1.7964e+03 (2.0277e+03)\tloss 5.5146e+00 (6.7075e+00)\tAcc@1  96.88 ( 83.05)\tAcc@5 100.00 ( 96.75)\n",
      "Test: [ 30/450]\tTime  0.373 ( 0.322)\tent_Loss 3.9722e-01 (5.9694e-01)\tcenter_loss 1.9316e+03 (1.9993e+03)\tloss 6.1921e+00 (6.5947e+00)\tAcc@1  84.38 ( 83.77)\tAcc@5  96.88 ( 96.77)\n",
      "Test: [ 35/450]\tTime  0.312 ( 0.319)\tent_Loss 6.7441e-01 (5.9454e-01)\tcenter_loss 1.8239e+03 (1.9837e+03)\tloss 6.1460e+00 (6.5457e+00)\tAcc@1  81.25 ( 83.68)\tAcc@5  93.75 ( 96.88)\n",
      "Test: [ 40/450]\tTime  0.285 ( 0.318)\tent_Loss 3.8687e-01 (5.8308e-01)\tcenter_loss 1.9133e+03 (1.9770e+03)\tloss 6.1267e+00 (6.5141e+00)\tAcc@1  87.50 ( 83.99)\tAcc@5 100.00 ( 97.03)\n",
      "Test: [ 45/450]\tTime  0.324 ( 0.320)\tent_Loss 5.2172e-01 (6.1741e-01)\tcenter_loss 1.9434e+03 (1.9740e+03)\tloss 6.3518e+00 (6.5393e+00)\tAcc@1  78.12 ( 82.61)\tAcc@5 100.00 ( 97.15)\n",
      "Test: [ 50/450]\tTime  0.311 ( 0.320)\tent_Loss 8.4525e-01 (6.1255e-01)\tcenter_loss 1.9932e+03 (1.9707e+03)\tloss 6.8249e+00 (6.5247e+00)\tAcc@1  68.75 ( 82.54)\tAcc@5 100.00 ( 97.37)\n",
      "Test: [ 55/450]\tTime  0.312 ( 0.319)\tent_Loss 4.8666e-01 (6.2075e-01)\tcenter_loss 2.0799e+03 (1.9767e+03)\tloss 6.7265e+00 (6.5508e+00)\tAcc@1  84.38 ( 82.48)\tAcc@5  96.88 ( 97.15)\n",
      "Test: [ 60/450]\tTime  0.298 ( 0.319)\tent_Loss 1.0529e-01 (5.9635e-01)\tcenter_loss 2.1220e+03 (1.9729e+03)\tloss 6.4712e+00 (6.5152e+00)\tAcc@1  96.88 ( 83.20)\tAcc@5 100.00 ( 97.28)\n",
      "Test: [ 65/450]\tTime  0.301 ( 0.317)\tent_Loss 3.5633e-01 (5.7517e-01)\tcenter_loss 1.7975e+03 (1.9680e+03)\tloss 5.7489e+00 (6.4793e+00)\tAcc@1  93.75 ( 83.85)\tAcc@5 100.00 ( 97.49)\n",
      "Test: [ 70/450]\tTime  0.318 ( 0.317)\tent_Loss 1.0979e+00 (5.8287e-01)\tcenter_loss 2.0147e+03 (1.9689e+03)\tloss 7.1419e+00 (6.4895e+00)\tAcc@1  71.88 ( 83.71)\tAcc@5  84.38 ( 97.23)\n",
      "Test: [ 75/450]\tTime  0.302 ( 0.317)\tent_Loss 1.2974e+00 (6.1105e-01)\tcenter_loss 1.9876e+03 (1.9738e+03)\tloss 7.2603e+00 (6.5323e+00)\tAcc@1  62.50 ( 83.10)\tAcc@5  93.75 ( 97.00)\n",
      "Test: [ 80/450]\tTime  0.310 ( 0.318)\tent_Loss 4.8376e-01 (5.9021e-01)\tcenter_loss 2.0171e+03 (1.9799e+03)\tloss 6.5350e+00 (6.5299e+00)\tAcc@1  90.62 ( 83.68)\tAcc@5  96.88 ( 97.15)\n",
      "Test: [ 85/450]\tTime  0.296 ( 0.317)\tent_Loss 6.3766e-01 (5.8840e-01)\tcenter_loss 1.9805e+03 (1.9875e+03)\tloss 6.5793e+00 (6.5509e+00)\tAcc@1  84.38 ( 83.87)\tAcc@5 100.00 ( 97.13)\n",
      "Test: [ 90/450]\tTime  0.292 ( 0.316)\tent_Loss 1.1435e+00 (6.1708e-01)\tcenter_loss 2.0626e+03 (1.9899e+03)\tloss 7.3312e+00 (6.5869e+00)\tAcc@1  75.00 ( 83.28)\tAcc@5  93.75 ( 96.94)\n",
      "Test: [ 95/450]\tTime  0.287 ( 0.316)\tent_Loss 1.0343e+00 (6.3081e-01)\tcenter_loss 2.0787e+03 (1.9940e+03)\tloss 7.2706e+00 (6.6129e+00)\tAcc@1  68.75 ( 82.75)\tAcc@5  96.88 ( 97.04)\n",
      "Test: [100/450]\tTime  0.316 ( 0.315)\tent_Loss 4.7880e-01 (6.3419e-01)\tcenter_loss 2.0923e+03 (1.9995e+03)\tloss 6.7558e+00 (6.6327e+00)\tAcc@1  87.50 ( 82.70)\tAcc@5  93.75 ( 96.97)\n",
      "Test: [105/450]\tTime  0.304 ( 0.316)\tent_Loss 4.9733e-01 (6.2995e-01)\tcenter_loss 1.9142e+03 (1.9995e+03)\tloss 6.2399e+00 (6.6286e+00)\tAcc@1  84.38 ( 82.75)\tAcc@5 100.00 ( 97.02)\n",
      "Test: [110/450]\tTime  0.295 ( 0.315)\tent_Loss 3.6035e-01 (6.3192e-01)\tcenter_loss 1.8638e+03 (2.0019e+03)\tloss 5.9518e+00 (6.6376e+00)\tAcc@1  87.50 ( 82.52)\tAcc@5 100.00 ( 97.13)\n",
      "Test: [115/450]\tTime  0.300 ( 0.315)\tent_Loss 8.4033e-01 (6.2681e-01)\tcenter_loss 2.0353e+03 (2.0043e+03)\tloss 6.9464e+00 (6.6397e+00)\tAcc@1  78.12 ( 82.73)\tAcc@5  93.75 ( 97.09)\n",
      "Test: [120/450]\tTime  0.325 ( 0.315)\tent_Loss 7.5641e-01 (6.2997e-01)\tcenter_loss 1.8952e+03 (2.0025e+03)\tloss 6.4421e+00 (6.6374e+00)\tAcc@1  87.50 ( 82.62)\tAcc@5 100.00 ( 97.18)\n",
      "Test: [125/450]\tTime  0.319 ( 0.315)\tent_Loss 6.9933e-01 (6.4113e-01)\tcenter_loss 1.9490e+03 (1.9963e+03)\tloss 6.5463e+00 (6.6300e+00)\tAcc@1  71.88 ( 82.29)\tAcc@5  96.88 ( 97.07)\n",
      "Test: [130/450]\tTime  0.285 ( 0.315)\tent_Loss 2.5263e-01 (6.4498e-01)\tcenter_loss 2.0740e+03 (1.9951e+03)\tloss 6.4747e+00 (6.6302e+00)\tAcc@1  93.75 ( 82.11)\tAcc@5 100.00 ( 97.11)\n",
      "Test: [135/450]\tTime  0.306 ( 0.316)\tent_Loss 6.1037e-01 (6.4338e-01)\tcenter_loss 1.7485e+03 (1.9939e+03)\tloss 5.8558e+00 (6.6252e+00)\tAcc@1  84.38 ( 82.10)\tAcc@5  96.88 ( 97.20)\n",
      "Test: [140/450]\tTime  0.314 ( 0.316)\tent_Loss 2.7929e-01 (6.3631e-01)\tcenter_loss 1.7855e+03 (1.9901e+03)\tloss 5.6359e+00 (6.6067e+00)\tAcc@1  93.75 ( 82.36)\tAcc@5 100.00 ( 97.19)\n",
      "Test: [145/450]\tTime  0.373 ( 0.316)\tent_Loss 1.8357e-01 (6.2833e-01)\tcenter_loss 2.1474e+03 (1.9878e+03)\tloss 6.6258e+00 (6.5919e+00)\tAcc@1  96.88 ( 82.64)\tAcc@5 100.00 ( 97.24)\n",
      "Test: [150/450]\tTime  0.284 ( 0.316)\tent_Loss 5.6379e-02 (6.1814e-01)\tcenter_loss 1.9511e+03 (1.9885e+03)\tloss 5.9096e+00 (6.5835e+00)\tAcc@1 100.00 ( 82.97)\tAcc@5 100.00 ( 97.27)\n",
      "Test: [155/450]\tTime  0.312 ( 0.315)\tent_Loss 2.5062e-01 (6.1048e-01)\tcenter_loss 1.8940e+03 (1.9865e+03)\tloss 5.9327e+00 (6.5700e+00)\tAcc@1  90.62 ( 83.13)\tAcc@5 100.00 ( 97.30)\n",
      "Test: [160/450]\tTime  0.300 ( 0.315)\tent_Loss 1.1614e+00 (6.0799e-01)\tcenter_loss 1.8937e+03 (1.9855e+03)\tloss 6.8423e+00 (6.5644e+00)\tAcc@1  68.75 ( 83.17)\tAcc@5  90.62 ( 97.30)\n",
      "Test: [165/450]\tTime  0.309 ( 0.317)\tent_Loss 8.1604e-01 (6.0853e-01)\tcenter_loss 1.9770e+03 (1.9839e+03)\tloss 6.7470e+00 (6.5602e+00)\tAcc@1  71.88 ( 83.09)\tAcc@5  93.75 ( 97.27)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test: [170/450]\tTime  0.300 ( 0.317)\tent_Loss 3.6976e-01 (6.0112e-01)\tcenter_loss 1.9859e+03 (1.9842e+03)\tloss 6.3276e+00 (6.5537e+00)\tAcc@1  87.50 ( 83.33)\tAcc@5 100.00 ( 97.28)\n",
      "Test: [175/450]\tTime  0.316 ( 0.317)\tent_Loss 1.7920e-01 (5.9848e-01)\tcenter_loss 1.6815e+03 (1.9785e+03)\tloss 5.2236e+00 (6.5339e+00)\tAcc@1  96.88 ( 83.38)\tAcc@5 100.00 ( 97.28)\n",
      "Test: [180/450]\tTime  0.292 ( 0.317)\tent_Loss 1.0581e+00 (6.0164e-01)\tcenter_loss 1.9655e+03 (1.9755e+03)\tloss 6.9545e+00 (6.5282e+00)\tAcc@1  59.38 ( 83.17)\tAcc@5  96.88 ( 97.31)\n",
      "Test: [185/450]\tTime  0.310 ( 0.318)\tent_Loss 3.7077e-01 (6.0265e-01)\tcenter_loss 1.9732e+03 (1.9772e+03)\tloss 6.2903e+00 (6.5342e+00)\tAcc@1  84.38 ( 83.01)\tAcc@5 100.00 ( 97.28)\n",
      "Test: [190/450]\tTime  0.327 ( 0.318)\tent_Loss 5.8647e-01 (6.0532e-01)\tcenter_loss 1.8543e+03 (1.9750e+03)\tloss 6.1492e+00 (6.5304e+00)\tAcc@1  84.38 ( 82.94)\tAcc@5 100.00 ( 97.28)\n",
      "Test: [195/450]\tTime  0.312 ( 0.318)\tent_Loss 1.8766e-01 (6.0043e-01)\tcenter_loss 2.1877e+03 (1.9793e+03)\tloss 6.7508e+00 (6.5383e+00)\tAcc@1  96.88 ( 83.04)\tAcc@5 100.00 ( 97.34)\n",
      "Test: [200/450]\tTime  0.313 ( 0.318)\tent_Loss 6.8683e-01 (6.0042e-01)\tcenter_loss 2.1388e+03 (1.9819e+03)\tloss 7.1031e+00 (6.5460e+00)\tAcc@1  78.12 ( 82.98)\tAcc@5  96.88 ( 97.37)\n",
      "Test: [205/450]\tTime  0.376 ( 0.318)\tent_Loss 1.2401e+00 (6.0416e-01)\tcenter_loss 1.9315e+03 (1.9828e+03)\tloss 7.0345e+00 (6.5527e+00)\tAcc@1  71.88 ( 82.89)\tAcc@5  93.75 ( 97.35)\n",
      "Test: [210/450]\tTime  0.326 ( 0.319)\tent_Loss 6.7234e-01 (6.0129e-01)\tcenter_loss 1.8366e+03 (1.9819e+03)\tloss 6.1822e+00 (6.5470e+00)\tAcc@1  81.25 ( 82.97)\tAcc@5 100.00 ( 97.38)\n",
      "Test: [215/450]\tTime  0.300 ( 0.319)\tent_Loss 9.5646e-01 (6.1164e-01)\tcenter_loss 2.4306e+03 (1.9853e+03)\tloss 8.2482e+00 (6.5674e+00)\tAcc@1  59.38 ( 82.60)\tAcc@5 100.00 ( 97.40)\n",
      "Test: [220/450]\tTime  0.279 ( 0.319)\tent_Loss 8.1031e-01 (6.2692e-01)\tcenter_loss 2.1027e+03 (1.9922e+03)\tloss 7.1183e+00 (6.6036e+00)\tAcc@1  71.88 ( 82.06)\tAcc@5  96.88 ( 97.40)\n",
      "Test: [225/450]\tTime  0.335 ( 0.319)\tent_Loss 4.7566e-01 (6.2204e-01)\tcenter_loss 2.1305e+03 (1.9904e+03)\tloss 6.8673e+00 (6.5932e+00)\tAcc@1  87.50 ( 82.20)\tAcc@5  96.88 ( 97.44)\n",
      "Test: [230/450]\tTime  0.296 ( 0.319)\tent_Loss 1.3996e-01 (6.1314e-01)\tcenter_loss 1.8191e+03 (1.9891e+03)\tloss 5.5973e+00 (6.5804e+00)\tAcc@1  93.75 ( 82.45)\tAcc@5 100.00 ( 97.48)\n",
      "Test: [235/450]\tTime  0.311 ( 0.319)\tent_Loss 6.3065e-01 (6.1252e-01)\tcenter_loss 1.8988e+03 (1.9880e+03)\tloss 6.3271e+00 (6.5764e+00)\tAcc@1  78.12 ( 82.49)\tAcc@5  96.88 ( 97.48)\n",
      "Test: [240/450]\tTime  0.301 ( 0.318)\tent_Loss 6.2491e-02 (6.0550e-01)\tcenter_loss 1.9404e+03 (1.9866e+03)\tloss 5.8838e+00 (6.5653e+00)\tAcc@1 100.00 ( 82.73)\tAcc@5 100.00 ( 97.52)\n",
      "Test: [245/450]\tTime  0.313 ( 0.318)\tent_Loss 2.6620e-01 (5.9938e-01)\tcenter_loss 2.0552e+03 (1.9872e+03)\tloss 6.4316e+00 (6.5611e+00)\tAcc@1  90.62 ( 82.93)\tAcc@5 100.00 ( 97.56)\n",
      "Test: [250/450]\tTime  0.301 ( 0.318)\tent_Loss 4.8666e-01 (5.9120e-01)\tcenter_loss 2.0368e+03 (1.9895e+03)\tloss 6.5972e+00 (6.5597e+00)\tAcc@1  90.62 ( 83.20)\tAcc@5  96.88 ( 97.60)\n",
      "Test: [255/450]\tTime  0.307 ( 0.318)\tent_Loss 4.4191e-01 (5.9127e-01)\tcenter_loss 2.1192e+03 (1.9912e+03)\tloss 6.7995e+00 (6.5648e+00)\tAcc@1  90.62 ( 83.15)\tAcc@5 100.00 ( 97.62)\n",
      "Test: [260/450]\tTime  0.302 ( 0.318)\tent_Loss 8.9623e-01 (6.0442e-01)\tcenter_loss 1.9517e+03 (1.9915e+03)\tloss 6.7513e+00 (6.5789e+00)\tAcc@1  68.75 ( 82.82)\tAcc@5  96.88 ( 97.51)\n",
      "Test: [265/450]\tTime  0.339 ( 0.318)\tent_Loss 2.9194e-01 (6.0302e-01)\tcenter_loss 2.0824e+03 (1.9913e+03)\tloss 6.5392e+00 (6.5769e+00)\tAcc@1  93.75 ( 82.91)\tAcc@5 100.00 ( 97.51)\n",
      "Test: [270/450]\tTime  0.334 ( 0.318)\tent_Loss 2.2135e-01 (5.9751e-01)\tcenter_loss 2.6933e+03 (2.0007e+03)\tloss 8.3014e+00 (6.5995e+00)\tAcc@1  93.75 ( 83.07)\tAcc@5 100.00 ( 97.53)\n",
      "Test: [275/450]\tTime  0.341 ( 0.319)\tent_Loss 6.9022e-01 (5.9581e-01)\tcenter_loss 2.7657e+03 (2.0196e+03)\tloss 8.9873e+00 (6.6545e+00)\tAcc@1  87.50 ( 83.14)\tAcc@5  93.75 ( 97.52)\n",
      "Test: [280/450]\tTime  0.382 ( 0.320)\tent_Loss 3.9616e-01 (5.9222e-01)\tcenter_loss 2.8718e+03 (2.0351e+03)\tloss 9.0115e+00 (6.6974e+00)\tAcc@1  90.62 ( 83.29)\tAcc@5  96.88 ( 97.53)\n",
      "Test: [285/450]\tTime  0.348 ( 0.321)\tent_Loss 6.6951e-01 (5.8709e-01)\tcenter_loss 2.8029e+03 (2.0497e+03)\tloss 9.0782e+00 (6.7361e+00)\tAcc@1  71.88 ( 83.42)\tAcc@5 100.00 ( 97.55)\n",
      "Test: [290/450]\tTime  0.370 ( 0.321)\tent_Loss 7.4305e-01 (5.9079e-01)\tcenter_loss 3.1483e+03 (2.0671e+03)\tloss 1.0188e+01 (6.7921e+00)\tAcc@1  87.50 ( 83.33)\tAcc@5  96.88 ( 97.54)\n",
      "Test: [295/450]\tTime  0.390 ( 0.322)\tent_Loss 2.9777e-01 (5.9428e-01)\tcenter_loss 2.9066e+03 (2.0842e+03)\tloss 9.0175e+00 (6.8469e+00)\tAcc@1  93.75 ( 83.16)\tAcc@5 100.00 ( 97.55)\n",
      "Test: [300/450]\tTime  0.386 ( 0.323)\tent_Loss 1.1535e+00 (5.9397e-01)\tcenter_loss 3.1591e+03 (2.0997e+03)\tloss 1.0631e+01 (6.8930e+00)\tAcc@1  78.12 ( 83.17)\tAcc@5  93.75 ( 97.55)\n",
      "Test: [305/450]\tTime  0.331 ( 0.323)\tent_Loss 2.8402e-01 (5.9794e-01)\tcenter_loss 3.1348e+03 (2.1170e+03)\tloss 9.6883e+00 (6.9488e+00)\tAcc@1  93.75 ( 83.11)\tAcc@5 100.00 ( 97.52)\n",
      "Test: [310/450]\tTime  0.348 ( 0.323)\tent_Loss 1.1677e+00 (5.9534e-01)\tcenter_loss 2.9928e+03 (2.1327e+03)\tloss 1.0146e+01 (6.9936e+00)\tAcc@1  68.75 ( 83.20)\tAcc@5  96.88 ( 97.54)\n",
      "Test: [315/450]\tTime  0.364 ( 0.324)\tent_Loss 2.4004e-01 (5.9162e-01)\tcenter_loss 2.8968e+03 (2.1467e+03)\tloss 8.9306e+00 (7.0316e+00)\tAcc@1  96.88 ( 83.35)\tAcc@5 100.00 ( 97.58)\n",
      "Test: [320/450]\tTime  0.341 ( 0.324)\tent_Loss 1.2736e+00 (5.9365e-01)\tcenter_loss 3.4246e+03 (2.1611e+03)\tloss 1.1548e+01 (7.0769e+00)\tAcc@1  56.25 ( 83.25)\tAcc@5  93.75 ( 97.59)\n",
      "Test: [325/450]\tTime  0.348 ( 0.325)\tent_Loss 9.4379e-01 (5.9778e-01)\tcenter_loss 3.6472e+03 (2.1807e+03)\tloss 1.1885e+01 (7.1398e+00)\tAcc@1  50.00 ( 83.04)\tAcc@5 100.00 ( 97.58)\n",
      "Test: [330/450]\tTime  0.312 ( 0.325)\tent_Loss 1.0655e+00 (5.9913e-01)\tcenter_loss 3.1649e+03 (2.1932e+03)\tloss 1.0560e+01 (7.1788e+00)\tAcc@1  68.75 ( 82.98)\tAcc@5  96.88 ( 97.60)\n",
      "Test: [335/450]\tTime  0.393 ( 0.326)\tent_Loss 3.3821e-01 (5.9509e-01)\tcenter_loss 3.0943e+03 (2.2035e+03)\tloss 9.6211e+00 (7.2057e+00)\tAcc@1  90.62 ( 83.12)\tAcc@5 100.00 ( 97.62)\n",
      "Test: [340/450]\tTime  0.348 ( 0.326)\tent_Loss 5.5431e-01 (5.9155e-01)\tcenter_loss 2.9616e+03 (2.2143e+03)\tloss 9.4392e+00 (7.2345e+00)\tAcc@1  87.50 ( 83.28)\tAcc@5 100.00 ( 97.64)\n",
      "Test: [345/450]\tTime  0.384 ( 0.326)\tent_Loss 2.4377e-01 (5.8706e-01)\tcenter_loss 2.7725e+03 (2.2235e+03)\tloss 8.5613e+00 (7.2574e+00)\tAcc@1  90.62 ( 83.43)\tAcc@5 100.00 ( 97.65)\n",
      "Test: [350/450]\tTime  0.348 ( 0.327)\tent_Loss 5.7759e-02 (5.8264e-01)\tcenter_loss 2.8677e+03 (2.2333e+03)\tloss 8.6610e+00 (7.2825e+00)\tAcc@1 100.00 ( 83.58)\tAcc@5 100.00 ( 97.68)\n",
      "Test: [355/450]\tTime  0.352 ( 0.327)\tent_Loss 6.9025e-01 (5.8199e-01)\tcenter_loss 3.1839e+03 (2.2427e+03)\tloss 1.0242e+01 (7.3100e+00)\tAcc@1  87.50 ( 83.66)\tAcc@5  93.75 ( 97.66)\n",
      "Test: [360/450]\tTime  0.363 ( 0.327)\tent_Loss 6.7216e-01 (5.8244e-01)\tcenter_loss 3.2676e+03 (2.2543e+03)\tloss 1.0475e+01 (7.3455e+00)\tAcc@1  81.25 ( 83.62)\tAcc@5  96.88 ( 97.65)\n",
      "Test: [365/450]\tTime  0.346 ( 0.328)\tent_Loss 2.4808e-01 (5.8187e-01)\tcenter_loss 2.8320e+03 (2.2635e+03)\tloss 8.7440e+00 (7.3724e+00)\tAcc@1  96.88 ( 83.65)\tAcc@5  96.88 ( 97.66)\n",
      "Test: [370/450]\tTime  0.338 ( 0.328)\tent_Loss 9.2726e-01 (5.8296e-01)\tcenter_loss 3.1483e+03 (2.2740e+03)\tloss 1.0372e+01 (7.4049e+00)\tAcc@1  78.12 ( 83.60)\tAcc@5  90.62 ( 97.64)\n",
      "Test: [375/450]\tTime  0.360 ( 0.328)\tent_Loss 1.3724e+00 (5.8814e-01)\tcenter_loss 3.1713e+03 (2.2868e+03)\tloss 1.0886e+01 (7.4484e+00)\tAcc@1  68.75 ( 83.46)\tAcc@5  81.25 ( 97.60)\n",
      "Test: [380/450]\tTime  0.360 ( 0.329)\tent_Loss 1.0568e+00 (5.8872e-01)\tcenter_loss 3.4977e+03 (2.3030e+03)\tloss 1.1550e+01 (7.4978e+00)\tAcc@1  78.12 ( 83.49)\tAcc@5  93.75 ( 97.61)\n",
      "Test: [385/450]\tTime  0.358 ( 0.329)\tent_Loss 5.2095e-01 (5.9229e-01)\tcenter_loss 2.9912e+03 (2.3143e+03)\tloss 9.4947e+00 (7.5353e+00)\tAcc@1  87.50 ( 83.44)\tAcc@5  96.88 ( 97.56)\n",
      "Test: [390/450]\tTime  0.361 ( 0.329)\tent_Loss 6.3676e-01 (5.9146e-01)\tcenter_loss 2.7261e+03 (2.3219e+03)\tloss 8.8150e+00 (7.5572e+00)\tAcc@1  81.25 ( 83.50)\tAcc@5 100.00 ( 97.54)\n",
      "Test: [395/450]\tTime  0.329 ( 0.330)\tent_Loss 1.2645e+00 (5.9245e-01)\tcenter_loss 3.2420e+03 (2.3311e+03)\tloss 1.0991e+01 (7.5858e+00)\tAcc@1  56.25 ( 83.46)\tAcc@5  93.75 ( 97.53)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test: [400/450]\tTime  0.352 ( 0.330)\tent_Loss 1.7961e-01 (5.9586e-01)\tcenter_loss 3.2892e+03 (2.3446e+03)\tloss 1.0047e+01 (7.6296e+00)\tAcc@1  93.75 ( 83.30)\tAcc@5 100.00 ( 97.55)\n",
      "Test: [405/450]\tTime  0.331 ( 0.330)\tent_Loss 4.6967e-01 (5.9295e-01)\tcenter_loss 3.4071e+03 (2.3549e+03)\tloss 1.0691e+01 (7.6576e+00)\tAcc@1  87.50 ( 83.41)\tAcc@5 100.00 ( 97.56)\n",
      "Test: [410/450]\tTime  0.340 ( 0.330)\tent_Loss 7.0495e-02 (5.9163e-01)\tcenter_loss 2.7834e+03 (2.3644e+03)\tloss 8.4206e+00 (7.6848e+00)\tAcc@1 100.00 ( 83.48)\tAcc@5 100.00 ( 97.57)\n",
      "Test: [415/450]\tTime  0.310 ( 0.330)\tent_Loss 4.0284e-01 (5.8895e-01)\tcenter_loss 2.8681e+03 (2.3728e+03)\tloss 9.0070e+00 (7.7074e+00)\tAcc@1  90.62 ( 83.59)\tAcc@5  96.88 ( 97.57)\n",
      "Test: [420/450]\tTime  0.367 ( 0.330)\tent_Loss 3.8021e-01 (5.8702e-01)\tcenter_loss 3.2144e+03 (2.3837e+03)\tloss 1.0023e+01 (7.7380e+00)\tAcc@1  90.62 ( 83.67)\tAcc@5 100.00 ( 97.57)\n",
      "Test: [425/450]\tTime  0.350 ( 0.331)\tent_Loss 8.5685e-01 (5.8779e-01)\tcenter_loss 3.3108e+03 (2.3926e+03)\tloss 1.0789e+01 (7.7657e+00)\tAcc@1  90.62 ( 83.74)\tAcc@5  93.75 ( 97.56)\n",
      "Test: [430/450]\tTime  0.333 ( 0.331)\tent_Loss 5.4011e-01 (5.8702e-01)\tcenter_loss 3.1633e+03 (2.4023e+03)\tloss 1.0030e+01 (7.7940e+00)\tAcc@1  87.50 ( 83.77)\tAcc@5  96.88 ( 97.56)\n",
      "Test: [435/450]\tTime  0.351 ( 0.331)\tent_Loss 2.2071e-01 (5.8415e-01)\tcenter_loss 2.9142e+03 (2.4107e+03)\tloss 8.9634e+00 (7.8162e+00)\tAcc@1  87.50 ( 83.85)\tAcc@5 100.00 ( 97.58)\n",
      "Test: [440/450]\tTime  0.410 ( 0.331)\tent_Loss 8.2011e-02 (5.7959e-01)\tcenter_loss 3.0681e+03 (2.4180e+03)\tloss 9.2863e+00 (7.8335e+00)\tAcc@1  96.88 ( 84.01)\tAcc@5 100.00 ( 97.60)\n",
      "Test: [445/450]\tTime  0.352 ( 0.332)\tent_Loss 8.1805e-01 (5.7947e-01)\tcenter_loss 3.0925e+03 (2.4257e+03)\tloss 1.0096e+01 (7.8565e+00)\tAcc@1  75.00 ( 84.02)\tAcc@5 100.00 ( 97.61)\n",
      " * Acc@1 84.062 Acc@5 97.607\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "model = myresnetv2_for_c_loss(num_classes=320)\n",
    "model = model.to(device)\n",
    "\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "my_list = ['head.1.weight', 'head.1.bias','head.3.weight', 'head.3.bias']\n",
    "params = list(filter(lambda kv: kv[0] in my_list, model.named_parameters()))\n",
    "base_params = list(filter(lambda kv: kv[0] not in my_list, model.named_parameters()))\n",
    "\n",
    "crit_entr = torch.nn.CrossEntropyLoss()\n",
    "crit_closs = CenterLoss(num_classes=320, feat_dim=512)\n",
    "path = \"/home/hashmat.malik/Fall 2021/CV703 Lab/Week5/datasets/Task2:cub_and_dogs/Exp1/model_best_resnet_v2_cubs_dogs_4.pth.tar\"\n",
    "checkpoint = torch.load(path)\n",
    "model.load_state_dict(checkpoint['state_dict'])\n",
    "optimizer = optim.Adam([{'params':  [i[1]for i in params], 'lr': 0.0001, 'betas': (0.5, 0.999)},\n",
    "                {'params':  [i[1]for i in base_params], 'lr': 0.00001, 'betas': (0.5, 0.999)},\n",
    "                {'params': crit_closs.parameters(), 'lr': 0.01, 'betas': (0.5, 0.999)}\n",
    "                        ])\n",
    "\n",
    "scheduler = ReduceLROnPlateau(optimizer, 'max')\n",
    "train_model_with_closs(60, train_loader, val_loader, test_loader, optimizer, scheduler, crit_entr, crit_closs, model, f'resnet_v2_closs_new_lr_{0.01}', is_train=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa2e0dcc",
   "metadata": {},
   "source": [
    "Reached top1 accuracy of $83.17\\%$ on the "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
