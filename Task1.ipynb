{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f4a9b0ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import dog_dataset, cub_dataset, food_dataset\n",
    "from models.models_to_finetune import deit_small_patch16_224, myresnetv2_task1, myresnetv2_task2, myresnetv2_for_c_loss\n",
    "import PIL\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from torchvision import transforms\n",
    "import config\n",
    "import sys\n",
    "import math\n",
    "from run import train_model\n",
    "from vit.vit_pytorch.nest import NesT\n",
    "import timm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0d33704f",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = (0.485, 0.456, 0.406)\n",
    "std = (0.229, 0.224, 0.225)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65a7f78f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_transform = transforms.Compose([  # Accuracy:87.622%\n",
    "\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=mean, std=std)\n",
    "    ])\n",
    "data_transform1 = transforms.Compose([ # Accuracy:83.263%\n",
    "\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ColorJitter(brightness=0.2, contrast=0.3, saturation=0.1, hue=0.1),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=mean, std=std)\n",
    "    ])\n",
    "data_transform2 = transforms.Compose([ # Accuracy:85.524%\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.RandomHorizontalFlip(p=0.5),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=mean, std=std)\n",
    "    ])\n",
    "data_transform3 = transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.RandomRotation(20),\n",
    "        transforms.GaussianBlur(3, sigma=(0.1, 2.0)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=mean, std=std)\n",
    "    ])\n",
    "\n",
    "data_transform4 = transforms.Compose([  #\n",
    "\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.RandomRotation(20),\n",
    "        transforms.GaussianBlur(3, sigma=(0.1, 2.0)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=mean, std=std)\n",
    "    ])\n",
    "data_transform5 = transforms.Compose([  #\n",
    "\n",
    "        transforms.CenterCrop(384),\n",
    "        transforms.RandomRotation(20),\n",
    "        transforms.RandomHorizontalFlip(p=0.5),\n",
    "        transforms.GaussianBlur(3, sigma=(0.1, 2.0)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=mean, std=std)\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c6116250",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 50\n",
    "batch_size = 128\n",
    "torch.manual_seed(42)\n",
    "transform = config.data_transform4\n",
    "# Load Data\n",
    "train_loader, val_loader,test_loader = cub_dataset(bs=batch_size, data_transform=transform)\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32127f5a",
   "metadata": {},
   "source": [
    "## Using DieT transformer as the backbone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e84d06b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_IncompatibleKeys(missing_keys=['head.weight', 'head.bias'], unexpected_keys=[])\n"
     ]
    }
   ],
   "source": [
    "model = deit_small_patch16_224(pretrained=True, use_top_n_heads=12, use_patch_outputs=False)\n",
    "model.head = torch.nn.Linear(in_features=model.head.in_features, out_features=200)  # dogs dataset has 120 classes\n",
    "model.head.apply(model._init_weights)\n",
    "model.to(device)\n",
    "path = \"/home/hashmat.malik/Fall 2021/CV703 Lab/Week5/datasets/Task1:cub_dataset_weights/Exp1/modeldiet4_best.pth.tar\"\n",
    "checkpoint = torch.load(path)\n",
    "model.load_state_dict(checkpoint['state_dict'])\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001, betas=(0.5, 0.999))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "83e0b6c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test: [0/4]\tTime  1.651 ( 1.651)\tLoss 8.7371e-01 (8.7371e-01)\tAcc@1  75.78 ( 75.78)\tAcc@5  92.97 ( 92.97)\n",
      " * Acc@1 74.023 Acc@5 92.578\n",
      "Test: [ 0/46]\tTime  1.186 ( 1.186)\tLoss 1.1993e+00 (1.1993e+00)\tAcc@1  68.75 ( 68.75)\tAcc@5  89.06 ( 89.06)\n",
      "Test: [ 5/46]\tTime  1.134 ( 1.136)\tLoss 9.6994e-01 (9.8503e-01)\tAcc@1  77.34 ( 74.87)\tAcc@5  92.97 ( 92.84)\n",
      "Test: [10/46]\tTime  1.107 ( 1.119)\tLoss 6.5334e-01 (9.2885e-01)\tAcc@1  81.25 ( 76.14)\tAcc@5  97.66 ( 93.39)\n",
      "Test: [15/46]\tTime  1.116 ( 1.116)\tLoss 1.0024e+00 (9.3397e-01)\tAcc@1  75.78 ( 75.44)\tAcc@5  90.62 ( 93.12)\n",
      "Test: [20/46]\tTime  1.135 ( 1.119)\tLoss 8.3974e-01 (9.2190e-01)\tAcc@1  74.22 ( 75.41)\tAcc@5  96.09 ( 93.38)\n",
      "Test: [25/46]\tTime  1.139 ( 1.124)\tLoss 1.0838e+00 (9.2694e-01)\tAcc@1  74.22 ( 75.39)\tAcc@5  90.62 ( 93.12)\n",
      "Test: [30/46]\tTime  1.091 ( 1.124)\tLoss 7.0929e-01 (9.2233e-01)\tAcc@1  78.91 ( 75.33)\tAcc@5  96.88 ( 93.20)\n",
      "Test: [35/46]\tTime  1.130 ( 1.120)\tLoss 8.4988e-01 (9.3025e-01)\tAcc@1  71.88 ( 75.13)\tAcc@5  93.75 ( 93.01)\n",
      "Test: [40/46]\tTime  1.009 ( 1.114)\tLoss 8.7677e-01 (9.1413e-01)\tAcc@1  78.12 ( 75.44)\tAcc@5  96.09 ( 93.29)\n",
      "Test: [45/46]\tTime  0.319 ( 1.099)\tLoss 8.2324e-01 (9.1413e-01)\tAcc@1  76.47 ( 75.49)\tAcc@5  94.12 ( 93.37)\n",
      " * Acc@1 75.492 Acc@5 93.372\n"
     ]
    }
   ],
   "source": [
    "train_model(epochs, train_loader, val_loader, test_loader, optimizer, criterion, model, 'resnet', is_train=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8542eda3",
   "metadata": {},
   "source": [
    "Achieved top1 accurcay of 74.023% on validation set and 75.492% on the test set."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d737aa19",
   "metadata": {},
   "source": [
    "## Using CaiT transformer as the backbone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4b1d810c",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = config.data_transform4\n",
    "# Load Data\n",
    "train_loader, val_loader,test_loader = cub_dataset(bs=batch_size, data_transform=transform)\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "model = timm.create_model(\"cait_xxs24_224\", pretrained=True)\n",
    "model.head = torch.nn.Linear(in_features=model.head.in_features, out_features=200)  # dogs dataset has 120 classes\n",
    "model.head.apply(model._init_weights)\n",
    "model.to(device)\n",
    "path = \"/home/hashmat.malik/Fall 2021/CV703 Lab/Week5/datasets/Task1:cub_dataset_weights/Exp2/modelcait4_best.pth.tar\"\n",
    "checkpoint = torch.load(path)\n",
    "model.load_state_dict(checkpoint['state_dict'])\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001, betas=(0.5, 0.999))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5bacd88c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test: [0/4]\tTime  1.734 ( 1.734)\tLoss 1.2184e+00 (1.2184e+00)\tAcc@1  69.53 ( 69.53)\tAcc@5  87.50 ( 87.50)\n",
      " * Acc@1 72.656 Acc@5 92.188\n",
      "Test: [ 0/46]\tTime  1.194 ( 1.194)\tLoss 8.0442e-01 (8.0442e-01)\tAcc@1  78.91 ( 78.91)\tAcc@5  96.88 ( 96.88)\n",
      "Test: [ 5/46]\tTime  1.125 ( 1.172)\tLoss 1.1397e+00 (9.8487e-01)\tAcc@1  70.31 ( 73.83)\tAcc@5  94.53 ( 94.66)\n",
      "Test: [10/46]\tTime  1.187 ( 1.162)\tLoss 1.0279e+00 (9.8428e-01)\tAcc@1  75.00 ( 74.79)\tAcc@5  92.97 ( 93.96)\n",
      "Test: [15/46]\tTime  1.208 ( 1.156)\tLoss 9.3267e-01 (9.6391e-01)\tAcc@1  75.00 ( 75.34)\tAcc@5  94.53 ( 94.14)\n",
      "Test: [20/46]\tTime  1.085 ( 1.138)\tLoss 1.2021e+00 (9.7285e-01)\tAcc@1  71.88 ( 75.37)\tAcc@5  90.62 ( 93.75)\n",
      "Test: [25/46]\tTime  1.104 ( 1.127)\tLoss 8.0677e-01 (9.7281e-01)\tAcc@1  85.16 ( 75.78)\tAcc@5  92.97 ( 93.57)\n",
      "Test: [30/46]\tTime  1.078 ( 1.130)\tLoss 8.7290e-01 (9.7399e-01)\tAcc@1  78.12 ( 75.53)\tAcc@5  94.53 ( 93.65)\n",
      "Test: [35/46]\tTime  1.097 ( 1.121)\tLoss 1.0205e+00 (9.7324e-01)\tAcc@1  72.66 ( 75.35)\tAcc@5  92.97 ( 93.71)\n",
      "Test: [40/46]\tTime  1.101 ( 1.120)\tLoss 1.0276e+00 (9.8013e-01)\tAcc@1  75.00 ( 75.15)\tAcc@5  94.53 ( 93.56)\n",
      "Test: [45/46]\tTime  0.275 ( 1.104)\tLoss 9.5497e-01 (9.7926e-01)\tAcc@1  73.53 ( 74.97)\tAcc@5  97.06 ( 93.60)\n",
      " * Acc@1 74.974 Acc@5 93.597\n"
     ]
    }
   ],
   "source": [
    "train_model(epochs, train_loader, val_loader, test_loader, optimizer, criterion, model, 'resnet', is_train=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "107d660d",
   "metadata": {},
   "source": [
    "Achieved top1 accurcay of 72.656% on validation set and 74.974% on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "be0c1edd",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_transform5 = transforms.Compose([  #\n",
    "\n",
    "        transforms.CenterCrop(384),\n",
    "        transforms.RandomRotation(20),\n",
    "        transforms.RandomHorizontalFlip(p=0.5),\n",
    "        transforms.GaussianBlur(3, sigma=(0.1, 2.0)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=mean, std=std)\n",
    "    ])\n",
    "# Load Data\n",
    "train_loader, val_loader,test_loader = cub_dataset(bs=batch_size, data_transform=data_transform5)\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "model = timm.create_model(\"cait_xxs24_384\", pretrained=True)\n",
    "model.head = torch.nn.Linear(in_features=model.head.in_features, out_features=200)  # dogs dataset has 120 classes\n",
    "model.head.apply(model._init_weights)\n",
    "model.to(device)\n",
    "path = \"/home/hashmat.malik/Fall 2021/CV703 Lab/Week5/datasets/Task1:cub_dataset_weights/Exp3/modelcait_xxs24_3845_best.pth.tar\"\n",
    "checkpoint = torch.load(path)\n",
    "model.load_state_dict(checkpoint['state_dict'])\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001, betas=(0.5, 0.999))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4e7626b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test: [0/4]\tTime  3.909 ( 3.909)\tLoss 6.9312e-01 (6.9312e-01)\tAcc@1  84.38 ( 84.38)\tAcc@5  96.88 ( 96.88)\n",
      " * Acc@1 82.617 Acc@5 96.680\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "Input image size (224*224) doesn't match model (384*384).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_2625565/1689944831.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'resnet'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_train\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Fall 2021/CV703 Lab/Week5/run.py\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(epochs, train_loader, val_loader, test_loader, optimizer, criterion, model, arch, is_train)\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0macc2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalidate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m         \u001b[0macc1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalidate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Fall 2021/CV703 Lab/Week5/run.py\u001b[0m in \u001b[0;36mvalidate\u001b[0;34m(val_loader, model, criterion)\u001b[0m\n\u001b[1;32m    118\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m             \u001b[0;31m# compute output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 120\u001b[0;31m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    121\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m             \u001b[0;31m#acc += torch.sum(output.argmax(dim=-1) == target).item()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/detectron2/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/detectron2/lib/python3.7/site-packages/timm/models/cait.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    299\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    300\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 301\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    302\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    303\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/detectron2/lib/python3.7/site-packages/timm/models/cait.py\u001b[0m in \u001b[0;36mforward_features\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    280\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    281\u001b[0m         \u001b[0mB\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 282\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpatch_embed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    283\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    284\u001b[0m         \u001b[0mcls_tokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcls_token\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mB\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/detectron2/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/detectron2/lib/python3.7/site-packages/timm/models/layers/patch_embed.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0mB\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mC\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mW\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mH\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimg_size\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mW\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimg_size\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m             \u001b[0;34mf\"Input image size ({H}*{W}) doesn't match model ({self.img_size[0]}*{self.img_size[1]}).\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mproj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: Input image size (224*224) doesn't match model (384*384)."
     ]
    }
   ],
   "source": [
    "train_model(epochs, train_loader, val_loader, test_loader, optimizer, criterion, model, 'resnet', is_train=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0339d8cd",
   "metadata": {},
   "source": [
    "Achieved top1 accurcay of 72.656% on validation set and 74.974% on the test set."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
