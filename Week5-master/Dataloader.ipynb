{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6ffa7d5d",
   "metadata": {},
   "source": [
    "# Dataloaders for CUB Birds, Stanford Dogs, Foodx dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f65d3bb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "import copy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d53fbef9",
   "metadata": {},
   "source": [
    "## CUB Birds Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9115884e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CUBDataset(torchvision.datasets.ImageFolder):\n",
    "    \"\"\"\n",
    "    Dataset class for CUB Dataset\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, image_root_path, caption_root_path=None, split=\"train\", *args, **kwargs):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            image_root_path:      path to dir containing images and lists folders\n",
    "            caption_root_path:    path to dir containing captions\n",
    "            split:          train / test\n",
    "            *args:\n",
    "            **kwargs:\n",
    "        \"\"\"\n",
    "        image_info = self.get_file_content(f\"{image_root_path}/images.txt\")\n",
    "        self.image_id_to_name = {y[0]: y[1] for y in [x.strip().split(\" \") for x in image_info]}\n",
    "        split_info = self.get_file_content(f\"{image_root_path}/train_test_split.txt\")\n",
    "        self.split_info = {self.image_id_to_name[y[0]]: y[1] for y in [x.strip().split(\" \") for x in split_info]}\n",
    "        self.split = \"1\" if split == \"train\" else \"0\"\n",
    "        self.caption_root_path = caption_root_path\n",
    "\n",
    "        super(CUBDataset, self).__init__(root=f\"{image_root_path}/images\", is_valid_file=self.is_valid_file,\n",
    "                                         *args, **kwargs)\n",
    "\n",
    "    def is_valid_file(self, x):\n",
    "        return self.split_info[(x[len(self.root) + 1:])] == self.split\n",
    "\n",
    "    @staticmethod\n",
    "    def get_file_content(file_path):\n",
    "        with open(file_path) as fo:\n",
    "            content = fo.readlines()\n",
    "        return content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ef14de8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_root = \"/home/u20020019/TransFG/CUB_200_2011\"\n",
    "\n",
    "mean = (0.485, 0.456, 0.406)\n",
    "std = (0.229, 0.224, 0.225)\n",
    "\n",
    "\n",
    "# write data transform here as per the requirement\n",
    "data_transform = transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=mean, std=std)\n",
    "    ])\n",
    "\n",
    "train_dataset = CUBDataset(image_root_path=f\"{data_root}\", transform=data_transform, split=\"train\")\n",
    "test_dataset = CUBDataset(image_root_path=f\"{data_root}\", transform=data_transform, split=\"test\")\n",
    "\n",
    "\n",
    "# load in into the torch dataloader to get variable batch size, shuffle \n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=32, drop_last=True, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=32, drop_last=False, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20a4d14f",
   "metadata": {},
   "source": [
    "### Use the dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a04fecc1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "(5994, 5794)"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dataset), len(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "71f93745",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "(187, 182)"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_loader), len(test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "99d81b24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 3, 224, 224])\n",
      "tensor([ 19,  72,  89,  50, 104, 166,  99, 197, 140, 114, 117, 122,  66, 193,\n",
      "        176, 136, 191, 155, 101,  36, 171, 102,  45,  16,  99,   2, 150, 130,\n",
      "         92, 157, 121, 104])\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "for i, (inputs, labels) in enumerate(train_loader):\n",
    "    print(inputs.shape)\n",
    "    print(labels)\n",
    "    print('='*50)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72d35e5f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f8fd0303",
   "metadata": {},
   "source": [
    "## Stanford Dog Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ed4d4568",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "import scipy.io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f68ff44b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DOGDataset(torchvision.datasets.ImageFolder):\n",
    "    \"\"\"\n",
    "    Dataset class for DOG Dataset\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, image_root_path, caption_root_path=None, split=\"train\", *args, **kwargs):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            image_root_path:      path to dir containing images and lists folders\n",
    "            caption_root_path:    path to dir containing captions\n",
    "            split:          train / test\n",
    "            *args:\n",
    "            **kwargs:\n",
    "        \"\"\"\n",
    "        image_info = self.get_file_content(f\"{image_root_path}splits/file_list.mat\")\n",
    "        image_files = [o[0][0] for o in image_info]\n",
    "        \n",
    "        split_info = self.get_file_content(f\"{image_root_path}/splits/{split}_list.mat\")\n",
    "        split_files = [o[0][0] for o in split_info]\n",
    "        self.split_info = {}\n",
    "        if split == 'train' :\n",
    "            for image in image_files:\n",
    "                if image in split_files:\n",
    "                    self.split_info[image] = \"1\"\n",
    "                else:\n",
    "                    self.split_info[image] = \"0\"\n",
    "        elif split== 'test' :\n",
    "            for image in image_files:\n",
    "                if image in split_files:\n",
    "                    self.split_info[image] = \"0\"\n",
    "                else:\n",
    "                    self.split_info[image] = \"1\"\n",
    "                    \n",
    "        self.split = \"1\" if split == \"train\" else \"0\"\n",
    "        self.caption_root_path = caption_root_path\n",
    "\n",
    "        super(DOGDataset, self).__init__(root=f\"{image_root_path}Images\", is_valid_file = self.is_valid_file,\n",
    "                                         *args, **kwargs)\n",
    "\n",
    "    def is_valid_file(self, x):\n",
    "        return self.split_info[(x[len(self.root) + 1:])] == self.split\n",
    "\n",
    "    @staticmethod\n",
    "    def get_file_content(file_path):\n",
    "        content =  scipy.io.loadmat(file_path)\n",
    "        return content['file_list']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e716d306",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of train samples: 12000\n",
      "Number of test samples: 8580\n"
     ]
    }
   ],
   "source": [
    "# Set train and test set\n",
    "mean = (0.485, 0.456, 0.406)\n",
    "std = (0.229, 0.224, 0.225)\n",
    "\n",
    "data_transform = transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=mean, std=std)\n",
    "    ])\n",
    "\n",
    "\n",
    "data_root = \"/home/u20020019/Fall 2021/CV703 Lab/Week5/dog/\"\n",
    "\n",
    "\n",
    "train_dataset = DOGDataset(image_root_path=f\"{data_root}\", transform=data_transform, split=\"train\")\n",
    "test_dataset = DOGDataset(image_root_path=f\"{data_root}\", transform=data_transform, split=\"test\")\n",
    "print('Number of train samples:', len(train_dataset))\n",
    "print('Number of test samples:', len(test_dataset))\n",
    "\n",
    "# load in into the torch dataloader to get variable batch size, shuffle \n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=32, drop_last=True, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=32, drop_last=False, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7fea1a7",
   "metadata": {},
   "source": [
    "### Use Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3347d436",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12000, 8580)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dataset), len(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "69b79d36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(375, 269)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_loader), len(test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3705f2ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 3, 224, 224])\n",
      "tensor([ 39,  20,  40,  42,  60,  26,   2,  79,  77, 119, 103,  19,  40, 102,\n",
      "         50,   8,  73,  55,  63, 110,  66, 113,  42,  84, 102,  32,  98,  78,\n",
      "         96, 115,  41,  14])\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "for i, (inputs, labels) in enumerate(test_loader):\n",
    "    print(inputs.shape)\n",
    "    print(labels)\n",
    "    print('='*50)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61e991f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d29efe3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f11878d5",
   "metadata": {},
   "source": [
    "## Food Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9d25034c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from PIL import Image\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b49fb580",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_name</th>\n",
       "      <th>label</th>\n",
       "      <th>path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>img_name</td>\n",
       "      <td>label</td>\n",
       "      <td>/home/u20020019/Fall 2021/CV703 Lab/Week5/food...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>train_101733.jpg</td>\n",
       "      <td>211</td>\n",
       "      <td>/home/u20020019/Fall 2021/CV703 Lab/Week5/food...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>train_101734.jpg</td>\n",
       "      <td>211</td>\n",
       "      <td>/home/u20020019/Fall 2021/CV703 Lab/Week5/food...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>train_101735.jpg</td>\n",
       "      <td>211</td>\n",
       "      <td>/home/u20020019/Fall 2021/CV703 Lab/Week5/food...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>train_101736.jpg</td>\n",
       "      <td>211</td>\n",
       "      <td>/home/u20020019/Fall 2021/CV703 Lab/Week5/food...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118471</th>\n",
       "      <td>train_101728.jpg</td>\n",
       "      <td>123</td>\n",
       "      <td>/home/u20020019/Fall 2021/CV703 Lab/Week5/food...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118472</th>\n",
       "      <td>train_101729.jpg</td>\n",
       "      <td>123</td>\n",
       "      <td>/home/u20020019/Fall 2021/CV703 Lab/Week5/food...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118473</th>\n",
       "      <td>train_101730.jpg</td>\n",
       "      <td>123</td>\n",
       "      <td>/home/u20020019/Fall 2021/CV703 Lab/Week5/food...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118474</th>\n",
       "      <td>train_101731.jpg</td>\n",
       "      <td>123</td>\n",
       "      <td>/home/u20020019/Fall 2021/CV703 Lab/Week5/food...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118475</th>\n",
       "      <td>train_101732.jpg</td>\n",
       "      <td>123</td>\n",
       "      <td>/home/u20020019/Fall 2021/CV703 Lab/Week5/food...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>118476 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              image_name  label  \\\n",
       "0               img_name  label   \n",
       "1       train_101733.jpg    211   \n",
       "2       train_101734.jpg    211   \n",
       "3       train_101735.jpg    211   \n",
       "4       train_101736.jpg    211   \n",
       "...                  ...    ...   \n",
       "118471  train_101728.jpg    123   \n",
       "118472  train_101729.jpg    123   \n",
       "118473  train_101730.jpg    123   \n",
       "118474  train_101731.jpg    123   \n",
       "118475  train_101732.jpg    123   \n",
       "\n",
       "                                                     path  \n",
       "0       /home/u20020019/Fall 2021/CV703 Lab/Week5/food...  \n",
       "1       /home/u20020019/Fall 2021/CV703 Lab/Week5/food...  \n",
       "2       /home/u20020019/Fall 2021/CV703 Lab/Week5/food...  \n",
       "3       /home/u20020019/Fall 2021/CV703 Lab/Week5/food...  \n",
       "4       /home/u20020019/Fall 2021/CV703 Lab/Week5/food...  \n",
       "...                                                   ...  \n",
       "118471  /home/u20020019/Fall 2021/CV703 Lab/Week5/food...  \n",
       "118472  /home/u20020019/Fall 2021/CV703 Lab/Week5/food...  \n",
       "118473  /home/u20020019/Fall 2021/CV703 Lab/Week5/food...  \n",
       "118474  /home/u20020019/Fall 2021/CV703 Lab/Week5/food...  \n",
       "118475  /home/u20020019/Fall 2021/CV703 Lab/Week5/food...  \n",
       "\n",
       "[118476 rows x 3 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dir = \"/home/u20020019/Fall 2021/CV703 Lab/Week5/food_dataset\"\n",
    "\n",
    "split = 'train'\n",
    "train_df = pd.read_csv(f'{data_dir}/{split}_labels.csv', names= ['image_name','label'])\n",
    "train_df['path'] = train_df['image_name'].map(lambda x: os.path.join(f'{data_dir}/{split}_set/', x))\n",
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "863ae99c",
   "metadata": {},
   "outputs": [],
   "source": [
    "split = 'val'\n",
    "val_df = pd.read_csv(f'{data_dir}/{split}_labels.csv', names= ['image_name','label'])\n",
    "val_df['path'] = val_df['image_name'].map(lambda x: os.path.join(f'{data_dir}/{split}_set/', x))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8b262a51",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FOODDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, dataframe):\n",
    "        self.dataframe = dataframe\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataframe)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        row = self.dataframe.iloc[index]\n",
    "        return (\n",
    "            torchvision.transforms.functional.to_tensor(Image.open(row[\"path\"])), row['label']\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2d549e1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = FOODDataset(train_df)\n",
    "val_dataset = FOODDataset(val_df)\n",
    "\n",
    "# load in into the torch dataloader to get variable batch size, shuffle \n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=32, drop_last=True, shuffle=True)\n",
    "val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=32, drop_last=False, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "25fb1889",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(118476, 11995)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dataset), len(val_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ae8ca824",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3702, 375)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_loader), len(val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2bae0af4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 3, 224, 224])\n",
      "tensor([ 35,  39,  46,  24,  88,   3,  16, 105,  57,  98,  32,  79,  43,  19,\n",
      "         57,  81,  59,  77,  44,  95,   6,  15,  39,  21,  12,  78, 102, 102,\n",
      "        102,  92, 104, 107])\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "for i, (inputs, labels) in enumerate(test_loader):\n",
    "    print(inputs.shape)\n",
    "    print(labels)\n",
    "    print('='*50)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca09d91c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3fdb10d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4ba8fb3c",
   "metadata": {},
   "source": [
    "## Concatenate CUB Birds and Stanford Dogs Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "fcfb1476",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_root = \"/home/u20020019/TransFG/CUB_200_2011\"\n",
    "mean = (0.485, 0.456, 0.406)\n",
    "std = (0.229, 0.224, 0.225)\n",
    "\n",
    "\n",
    "# write data transform here as per the requirement\n",
    "data_transform = transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=mean, std=std)\n",
    "    ])\n",
    "\n",
    "train_dataset_cub = CUBDataset(image_root_path=f\"{data_root}\", transform=data_transform, split=\"train\")\n",
    "test_dataset_cub = CUBDataset(image_root_path=f\"{data_root}\", transform=data_transform, split=\"test\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "01d54912",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of train samples: 12000\n",
      "Number of test samples: 8580\n"
     ]
    }
   ],
   "source": [
    "# Set train and test set\n",
    "mean = (0.485, 0.456, 0.406)\n",
    "std = (0.229, 0.224, 0.225)\n",
    "\n",
    "data_transform = transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=mean, std=std)\n",
    "    ])\n",
    "\n",
    "\n",
    "data_root = \"/home/u20020019/Fall 2021/CV703 Lab/Week5/dog/\"\n",
    "\n",
    "train_dataset_dog = DOGDataset(image_root_path=f\"{data_root}\", transform=data_transform, split=\"train\")\n",
    "test_dataset_dog = DOGDataset(image_root_path=f\"{data_root}\", transform=data_transform, split=\"test\")\n",
    "print('Number of train samples:', len(train_dataset_dog))\n",
    "print('Number of test samples:', len(test_dataset_dog))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d729db7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# concatenated dataloader for CUB and DOG\n",
    "\n",
    "train_dataloader = torch.utils.data.DataLoader(\n",
    "             torch.utils.data.ConcatDataset([train_dataset_cub, train_dataset_dog]),\n",
    "             batch_size=1, shuffle=True,\n",
    "             num_workers=1, pin_memory=True)\n",
    "\n",
    "test_dataloader = torch.utils.data.DataLoader(\n",
    "             torch.utils.data.ConcatDataset([test_dataset_cub, test_dataset_dog]),\n",
    "             batch_size=1, shuffle=True,\n",
    "             num_workers=1, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ffa1d026",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5994, 12000, 17994)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dataset_cub), len(train_dataset_dog), len(train_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1acc1f08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5794, 8580, 14374)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_dataset_cub), len(test_dataset_dog), len(test_dataloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "305ca458",
   "metadata": {},
   "source": [
    "### Iterate Concatenated dataloader images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "cc9df8ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image ::  torch.Size([1, 3, 224, 224])\n",
      "tensor([46])\n"
     ]
    }
   ],
   "source": [
    "for i, (inputs, targets) in enumerate(train_dataloader):\n",
    "\n",
    "    print('image :: ', inputs.shape)\n",
    "    print(targets)\n",
    "    break\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c2fe773",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}